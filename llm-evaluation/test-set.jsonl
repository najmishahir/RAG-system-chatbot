{"id":"870f48c0-b11b-4ab4-9b53-8a23229349a8","question":"What is the maximum number of marks one can earn for a research proposal report in this module?","reference_answer":"The maximum number of marks one can earn for a research proposal report in this module is 60.","reference_context":"Document 582: and methodology, and Appendix: these are most important, and are triple-weighted, so get mark in range 0-18.  In your research proposal report, we will assess:  Background (0-6 marks) Contribution to knowledge (0-6 marks) Importance (0-6 marks) Research hypothesis and objectives (0-6 marks) Programme and methodology, including workplan diagram (0-18 marks) Appendix: use of data mining and text analytics tools in developing your Report (0-18 marks) TOTAL: up to 60 marks  Return of marks and feedback will be via Minerva grade center, approximately 3 weeks after submission.\n\nDocument 586: In your research proposal report, we will assess: Background (0-6 marks) Contribution to knowledge (0-6 marks) Importance (0-6 marks) Research hypothesis and objectives (0-6 marks) Programme and methodology, including workplan diagram (0-18 marks) Appendix: use of data mining and text analytics tools in developing your Report (0-18 marks) TOTAL: up to 60 marks\n\nDocument 581: two data mining and\/or text analytics methods, tools or techniques introduced in the module (eg SketchEngine, Weka, ChatGPT) 1-page workplan diagram must match the written description of the research work programme, showing start, end and duration of each phase or work-package.   EPSRC Evaluation Criteria: When a research project proposal is submitted to EPSRC, they check it meets the requirements, then send the proposal to several independent experts for Peer Review. These peer reviewers then give written feedback on strengths and weaknesses of the proposal, and marks or scores in the range 0-6.   4. Assessment criteria and marking process The mark scheme for your report will reflect the EPSRC grading scheme with marks in the range 0-6 for each criterion, EXCEPT the sections on Programme and methodology, and Appendix: these are most important, and are triple-weighted, so get mark in range 0-18.  In your research proposal report, we will assess:  Background (0-6 marks) Contribution to","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":582,"topic":"Academic Research Proposal Guidance"}}
{"id":"c3fd1838-28a0-43a2-a98f-fe5fe84cdfdc","question":"What is the GDEX function and when was it added to the Sketch Engine?","reference_answer":"The Good Dictionary Examples (GDEX) function was added to the Sketch Engine in 2008. It is a tool that sorts a concordance, so the corpus lines judged best by the algorithm are shown first, which helps lexicographers find good examples for dictionary entries.","reference_context":"Document 542: 6.2 GDEX\nDictionary users like examples. This is a clear \ufb01nding of dictionary user research\n(Frankenberg Garcia 2014 ). Where the dictionary is to be published on paper, not\nmany examples can be offered owing to space limitations. With electronicdictionaries, that constraint disappears. The constraint becomes, rather the editorialtime needed to prepare them. There are already compelling linguistic reasons for\ntaking examples from corpora rather than inventing them (Hanks 2012 ): could the\ncorpus software not merely \ufb01nd the examples for a word, but automatically \ufb01nd thegood ones, for using as dictionary examples?\nA Good Dictionary Examples (GDEX) function was added to the Sketch Engine\nin 2008 and has had many enthusiastic users. It was originally applied to English(Kilgarriff et al. 2008 ) and has since been used for a number of languages including\nSlovene (Kosem et al. 2011 ). It works by sorting a concordance, so the corpus lines\n\nDocument 543: Slovene (Kosem et al. 2011 ). It works by sorting a concordance, so the corpus lines\njudged best by the algorithm are shown \ufb01rst. Then the lexicographer should not\nhave to read many of them before \ufb01nding a good one. The same core technique has\nalso been used to score documents and to exclude low-scoring documents from acorpus entirely.\nThe critical outstanding question, for dictionary publishers, is this: can GDEX\nwork well enough, so that example sentences can be added to dictionary entrieswithout an editor needing to check them \ufb01rst? This is a goal, but a number ofobstacles stand in the way. First the corpus needs to be very big, to provide plenty ofexamples for the algorithm to choose amongst, and usually the only way to get a\nvery large corpus is from the web. But web corpora contain web spam, which\nsometimes makes it past all other \ufb01lters and makes bad dictionary examples.\nSecond: parsnips. Parsnips is an acronym for the potentially offensive topics","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":542,"topic":"Corpus Linguistics Software"}}
{"id":"11a0287b-1718-472b-9d32-6bb7382af202","question":"What is the expected future of language machines in the next 20 years?","reference_answer":"Over the next 20 years, the drawbacks of speech and language technology are likely to be overcome or surmounted, allowing the language machine to make a more significant impact. Personal computing technology will continue to drop in price and increase in power, making it accessible to an ever-widening community. The language machine will be a core component in this new technology. It won't rely on keyboard input and screen-display output, and speech input\/output seems the most likely replacement. The language machine will also get better, with a lower error-rate. However, precise predictions are difficult as the rate of progress in language machine development is uncertain.","reference_context":"Document 211: The next 20 years \nOver the next 20 years, we can assume that the drawbacks\nof speech and language technology are likely to be\novercome or surmounted, allowing the language machine\nto make a more significant impact. Bearing in mind the\ndifficulty inherent in predicting future technological\ndevelopment and adoption, this section explores a number\nof possible future scenarios.\nScenario 1\nIT and language machines will be all-pervasive \nIT industry futurologists . agree that personal computing\ntechnology will continue to drop in price and increase in\npower, making it accessible to an ever-widening comm-\nunity. Personal computing will become as everyday as\nwristwatches and telephones; indeed, it will be integrated\ninto wristwatches and telephones.\nThe language machine will be a core component in this\nnew technology: wristwatch or telephone computing will\nnot be able to rely on keyboard input and screen-display\noutput, and speech input\/output seems the most likely\n\nDocument 212: new technology: wristwatch or telephone computing will\nnot be able to rely on keyboard input and screen-display\noutput, and speech input\/output seems the most likely\nreplacement. Today\u0091s students may each have their own\nwristwatches; in ten or 20 years\u0091 time, they may carry their\npersonal computing around with them as an everyday tool\nor fashion accessory. Software for this consumer market\nwill be made available: prime suppliers may be the\nlanguage teaching business alongside IT industries. \nScenario 2\nThe language machine will get better \nAt the moment, it is easy to ridicule the language machineby showing examples of its fallibility. Most applications\nhave a threshold of acceptability: a system that makes too\nmany mistakes will not be used, although users will put up\nwith it if the error-rate is low enough. Many computer-\nliterate professionals have learnt to touch-type at speeds of\n100 words per minute or more; speech recognition software\n\nDocument 48: demand in the marketplace for language teachers and\nlanguage-based professions in the foreseeable future.\nIt may help to define what constitutes \u0090the foreseeable\nfuture\u0091. The Future of English?  (Graddol, 1997) contains\nprojections for as far ahead as 2050; the BT Technology\nCalendar (page 12) includes predictions to 2045. The\ndevelopments alluded to in this book are based on an\narbitrary forward look of approximately 20 years. \nPrecise predictions are of course, dangerous: nobody\nknows for sure what the rate of progress will be in\nlanguage machine development. Yet what we can be sure\nabout is that personal computing technology is developing\n\u0097 at an almost alarming rate. We need only to look around\nto see that many applications which once seemed\nimpossible or fantastical, are possible today.\nThe impact?\nThe question, \u0090What will it all mean?\u0091 is a fundamental one,and is addressed at many points throughout this book.\nHere, it may be easier or preferable to explain by example.\n\nDocument 223: learning \u0090taught\u0091 in a classroom environment and those\n\u0090learnt\u0091 autonomously by students equipped with their own\npersonal language machines may also prove significant to\ncurricula and educational decisions. The teaching\nprofessions need to ensure that they are in a position to\nexploit the language machine to best advantage.the language machine\n53\n.Ownership of personal\ncomputers continues to rise in the\nUK \u0097 but will access to new\ntechnology become a new form of\ndiscrimination, social stratification,\nor inequality? Questions to help\nforward the debate on the impact\nof the language machine are listed\non page 64.\nScenario 1: the must-haves \u0097 handbag, lippy, wristwatch translator\nAlready, thanks to discreet ear-pieces that allow mobile-phone users to converse on the phone hands-free \u0097often with the phone out of sight \u0097 we are becoming used to seeing solitary speaking. The future begins:","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":211,"topic":"Others"}}
{"id":"564ac6d9-f128-4e81-b572-4c60e47b147e","question":"What is the service provided by the email amalgam-tagger@scs.leeds.ac.uk?","reference_answer":"The service provided by the email amalgam-tagger@scs.leeds.ac.uk is to receive English text and return the same text, with each word annotated with the 'parts of speech'.","reference_context":"Document 205: yourself greeted in your own language or dialect \u0087 pick\nup a phone and talk to Chaucer \/Shakespeare \/Churchill.educational\n48resources\nHave a go? Language\ntechnology by email\nAdd a twist to a language class:\nemail English text to:\namalgam-tagger@scs.leeds.ac.uk\nYou\u0091ll receive back the same text,\nwith each word annotated with\nthe \u0090parts of speech\u0091. The\nfollowing sentence was emailed,\nand the parts of speech returned:\nRemote access over the Internet,\nvia WWW or email is an\nincreasingly popular alternative.\nRemote  \u0097adjective\naccess \u0097noun, singular, common\nover \u0097preposition\nthe \u0097article, singular or plural\nInternet \u0097noun, singular, proper\n, \u0097comma\nvia \u0097preposition\nWWW \u0097noun, singular, proper\nor \u0097conjunction, coordinating\nemail \u0097noun, singular, common \nis \u0097verb \u0090to be\u0091, \npresent tense\n3rd person singular\nan \u0097article, singular\nincreasingly \u0097adverb\npopular \u0097adjective\nalternative \u0097noun \nsingular, common\n. \u0097full stop\nThe text is annotated according to","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":205,"topic":"Artificial Intelligence in Language Learning"}}
{"id":"b02e82ac-cf74-4df3-bd51-a6f377d353ee","question":"What are Professor Eric Atwell's areas of research?","reference_answer":"Professor Eric Atwell's research areas include Corpus linguistics, artificial intelligence for language, religious text analytics, Arabic and Islamic corpus linguistics, and chat bots and AI for university education.","reference_context":"Document 1: specification, both of which should be available in Minerva. So this is me. I'm Eric Atwell. I'm \nProfessor of Artificial Intelligence for Language in the School of Computing at Leeds University. \nAnd there's my web page, or just Google Eric Atwell. I fixed it with Google so that I should be the \nfirst hit-  the top most hit for Eric Atwell. My research is in Corpus linguistics and artificial \nintelligence for language, and in particular religious text analytics and Arabic and Islamic corpus \nlinguistics, and also chat bots and AI for university education. And maybe we'll see some of this \ncoming up in the course. And there's a picture of me, or rather an icon of me from the language \nmachine book. I must be one of the few professors w ho has an icon specially drawn for them by \nthe British Council.  \nOK so what's coming up in the overall module-  well if you look at the Minerva page, you'll find","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":1,"topic":"Others"}}
{"id":"5793158c-c0f8-4fd5-87da-262d82bc78f2","question":"What were the predictions made for AI and robots in 2007 and 2012?","reference_answer":"In 2007, it was predicted that there would be domestic robots, small attractive robots everywhere in all homes. However, this did not happen as expected. In 2012, it was predicted that robots will be available for almost any job at home or in hospitals, but this also did not occur.","reference_context":"Document 32: able to type in a document to get your CV, but there are jobs around where it's not necessary. By \n2005, they thought there'd be full voice interaction with machines. Well, OK, you can talk to \ncomputers for some purposes. But most of the time when you use the computer, you're actually \nprobably using a touch screen or a keyboard. You're not talking to it. So that didn't really take off.  \nThey said by 2007, there'd be domestic robots, small attractive robots everywhere in all homes. \nWell, OK, some homes have got a robot vacuum cleaner, but it tends to be not very good. I mean, \nit doesn't actually pick up much dust. It's not very intelligent. It's not very functional.  \nSo again, robots did not take off. And this is partly because domestic duties are-  they thought that \nthe easy things could be done by robots - was actually it's very complicated to clean a house or to \ncook a meal. And it's far too complicated for robots to learn. Robots can do things like building\n\nDocument 33: the easy things could be done by robots - was actually it's very complicated to clean a house or to \ncook a meal. And it's far too complicated for robots to learn. Robots can do things like building \ncars. I used to work in a car factory making V auxhall cars, and that job is now gone. The robots \nhave taken over. In fact, if by 2012 robots will be available for almost any job at home or in \nhospitals. Again hospital cleaners and hospital nurses, again that hasn't happened. Those are \nactually for AI,  the difficult things. They may be semi -skilled or not valued for human labor, but it's \nfar too difficult for robots to do this.  \nThey thought by 2018 AI would be imitating thinking process of the brain. Well, we know what that \nmeant. So we don't know if that's true or not. But certainly by 2025, they thought that thought \nrecognition would be useful for input output. You wouldn't need to type, or use a touch screen, or","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":32,"topic":"Language and Speech Technology"}}
{"id":"9f6139b6-5ea8-4edb-9c02-7d103dc2fd3d","question":"What is the Association of the Computational Linguistics Special Interest Group on Web As Corpus?","reference_answer":"The Association of the Computational Linguistics Special Interest Group on Web As Corpus is a source of information that has meetings or conferences pretty much every year or every other year sometimes.","reference_context":"Document 481: rather than just a small sample corpus that you're looking at.  \nOK. Let's go back to page here. What've we got? Next thing I w ant to look at is the Special Interest \nGroup. Whoops. Can I click on this? We'll open the web page for the Association of the \nComputational Linguistics Special Interest Group on Web As Corpus. And the reason for doing \nthis is just to point out this is a ve ry good source of information because they have meetings or \nconferences pretty much every year or every other year sometimes.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":481,"topic":"Corpus Linguistics and Lexicography"}}
{"id":"a9992634-937d-44c2-9499-ae2317084f92","question":"How does the size of the vocabulary grow as the number of word tokens grows, according to Heaps Law?","reference_answer":"According to Heaps Law, the vocabulary size grows as the number of word tokens grows, but not as fast as the number of tokens. It's usually greater than the square root of the number of tokens.","reference_context":"Document 314: of a dictionary might extract from that as a set of types, then the s ize of the vocabulary is different \nfrom the number of tokens. And there's a sort of law sometimes called Heaps Law, Herdan's Law. \nIt's not actually a physical law in the same sense, it just says there is a general relationship that \nperhaps more vaguely, the vocabulary size grows as the number of word token grows. And it's \nusually greater than the square root of a number of tokens.  \nSo in a larger -- if you get more and more text, you'll carry on getting obviously more and more \ntokens. But also the number of t ypes will also grow, but not as fast as the number of tokens. And \nwe can see this in a number of examples.  \nSo for example there's a switchboard phone corpus, which is lots of phone conversations in \nAmerica. And they've recorded them and transcribed them. A nd it's 2 and 1\/2 million tokens \naltogether so that one way of measuring the size of a corpus isn't so much in how many bytes or","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":314,"topic":"Others"}}
{"id":"845fd23a-80ee-4d57-b140-244b75747e71","question":"What is one of the challenges faced by language teachers in developing countries?","reference_answer":"In developing countries, teachers in the state sector may not have updated equipment or software easily available to them or even offer the basic computer know-how.","reference_context":"Document 158: of language outside the classroom. It is likely that new\nways of teaching using computers will also spill into\nlanguage teaching from other areas of education.\nHowever the boundaries are redrawn, teachers will need\ntime to learn to use, integrate and exploit the language\nmachine. Schools will need time to see what\u0091s available,\nmake funding plans against staff availability and projected\nstudent numbers, and then plan for maintenance and\nupgrades. In developing countries all this may be an\nunrealistic luxury: teachers in the state sector may not have\nupdated equipment or software easily available to them or\neven offer the basic computer know-how. \nYet it is possibly easier for the state sector to provide\ncomputers than it is to provide smaller classes and trained\nteachers with the resources they need. For example this\nmay be the case in Mexico, where the state ministry \u0097 while\nworking with the British Council to upgrade the skills of its\nteachers \u0097 is keen to introduce new technology.\n\nDocument 145: professions. For example, language teachers who wish to\nuse CALL software incorporating speech recognition tech-\nnology may need to rethink approaches, and decide which\naspects of learning could be achieved more successfully by\nthe individual using the technology alone, and which\nlearning should remain within the classroom as a shared,\ngroup activity. Similarly, whole-school policies \u0097 of funding\nnew equipment, providing new learning spaces, and\nmanaging the politics of departmental resourcing \u0097 may\nneed to come under similar scrutiny if language machine\ntechnology is to be used more widely and successfuly in\neducation. \nProblem 6\nNewcomers need training and time to learn to\nuse the language machine \nOne supposed strength of the language machine is that\ncommunicating with a computer in spoken English is\n\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic\n\nDocument 157: Can problems be overcome?\nTaking a typical application \u0097 language teaching and\nlearning \u0097 can we imagine that the problems described in\nthis section will be overcome?\nClearly, full integration of the language machine is not\nforseeable in the immediate future. At the very least,\nlearners and teachers need to use computers confidently in\neveryday learning contexts. And, in its current state, the\nlanguage machine is not yet appropriate as a replacement\nfor some of the tasks undertaken by the language teacher. .\nYet as language technology improves, the boundary\nbetween tasks that can be delegated to the computer and\nthose that should be done only with a human language\nteacher will shift. The advent of widescale personal\ncomputing may also have an impact in terms of allowing\nstudents to use language machines to learn some aspects\nof language outside the classroom. It is likely that new\nways of teaching using computers will also spill into\nlanguage teaching from other areas of education.\n\nDocument 159: may be the case in Mexico, where the state ministry \u0097 while\nworking with the British Council to upgrade the skills of its\nteachers \u0097 is keen to introduce new technology. \nInterestingly for education, in applications such as\nmachine translation (the focus of the box opposite) and for\npeople working in other professions, . it is clear that the\nlanguage machine is making clear inroads.\nBut do inroads lead to a revolution?determination\n36to succeed\n.One scenario for the ELT\nbusiness is a radical one: what if\nthe language machine brought\nabout the large-scale abandonment\nof language learning? Many people\nlearn English so they can use it to\ncommunicate with native English\nspeakers or as a lingua franca; but\nwhat if, in the future, they find that\nit is possible to communicate via\nmachine translation devices?\nIs this scenario a realistic one?\nImplications for language\nprofessionals are explored on\npages 50\u009757.\nHal \u0097 the \ntalking computer\nmade evil\nSee page 35.Searching for Extra Terrestrials?","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":158,"topic":"Artificial Intelligence in Language Learning"}}
{"id":"cd8d8d5d-9ddf-49ba-91f5-1453dee9355d","question":"What is the significance of multilingualism for Lernout and Hauspie?","reference_answer":"The company has risen in a multilingual environment which may have assisted the development and take-up of products.","reference_context":"Document 175: nology, which it is likely to use in\ndeveloping the next generation of\nvoice-enabled computing for the\nMicrosoft Windows platform.\nLernout and Hauspie\u0091s market\nposition highlights several points:\nthe trend to build in products; the\nlikely mass-consumer markets\nahead, supported by the major\nplayers \u0097 and the significance of\nmultilingualism. The company has\nrisen in a multilingual environment\nwhich may have assisted the\ndevelopment and take-up of\nproducts. This latter point may\nserve as a cautionary note to\nthose companies operating in a\nmonolingual context.SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":175,"topic":"Others"}}
{"id":"9d21c307-7aa5-4968-bb79-bb688f97f14b","question":"What is the most likely input\/output method for future language machines integrated into everyday devices like wristwatches and telephones?","reference_answer":"Speech input\/output seems the most likely.","reference_context":"Document 47: Surveying the territory\nLanguage machines \u0097 machines that in some sense\nsimulate human language and human language behaviour\n\u0097 are used daily around us. Indeed, such machines already\nhave a long history, and have acquired a place in our\nculture and our expectations.\nThis book provides a survey of the current state of\nspeech and language technology, focusing particularly on\nmachine translation and speech recognition, highlighting\nthe histories and academic disciplines contributing to their\ndevelopment; it examines the components and tech-\nnologies; possible pitfalls; main developers; current and\npotential uses; predicted developments; and paints some\nlikely scenarios for the future impact of the language\nmachine. Finally, this book focuses on current and\nprospective developments that could have an impact on\ndemand in the marketplace for language teachers and\nlanguage-based professions in the foreseeable future.\nIt may help to define what constitutes \u0090the foreseeable\n\nDocument 274: Preface 5\nProgress and Prospects 5\nThe language machine 6\nSurveying the territory 6The impact? 6What\u0091s in a name? 7\nDescribing words: the technology 8What makes a language machine? 8Is it a language machine? 8\n... So is it SALT? 9\nTelling histories: 1791\u00972020 10Dreaming of speaking machines 10From Turing\u0091s child-machine to a 25 thousand dollar race 10\nWhen destiny calls, have the confidence to answer 11\nSeeing futures emerging 12To 2045: the BT Technology Calendar 12A widespread expectation 12* the wildcards? 13\nResearch labs to desk-tops 14\nAn academic heritage 14Where languages meet computer science 14Creating popular markets 16A use for everyone? 16The language of language processing 16\nTurning theory into practice 18\nWhy create language machines? 18What\u0091s involved: input to output 20Defining shared approaches 20Listen, analyse, understand 22full contents\n66click to goSITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 211: The next 20 years \nOver the next 20 years, we can assume that the drawbacks\nof speech and language technology are likely to be\novercome or surmounted, allowing the language machine\nto make a more significant impact. Bearing in mind the\ndifficulty inherent in predicting future technological\ndevelopment and adoption, this section explores a number\nof possible future scenarios.\nScenario 1\nIT and language machines will be all-pervasive \nIT industry futurologists . agree that personal computing\ntechnology will continue to drop in price and increase in\npower, making it accessible to an ever-widening comm-\nunity. Personal computing will become as everyday as\nwristwatches and telephones; indeed, it will be integrated\ninto wristwatches and telephones.\nThe language machine will be a core component in this\nnew technology: wristwatch or telephone computing will\nnot be able to rely on keyboard input and screen-display\noutput, and speech input\/output seems the most likely\n\nDocument 48: demand in the marketplace for language teachers and\nlanguage-based professions in the foreseeable future.\nIt may help to define what constitutes \u0090the foreseeable\nfuture\u0091. The Future of English?  (Graddol, 1997) contains\nprojections for as far ahead as 2050; the BT Technology\nCalendar (page 12) includes predictions to 2045. The\ndevelopments alluded to in this book are based on an\narbitrary forward look of approximately 20 years. \nPrecise predictions are of course, dangerous: nobody\nknows for sure what the rate of progress will be in\nlanguage machine development. Yet what we can be sure\nabout is that personal computing technology is developing\n\u0097 at an almost alarming rate. We need only to look around\nto see that many applications which once seemed\nimpossible or fantastical, are possible today.\nThe impact?\nThe question, \u0090What will it all mean?\u0091 is a fundamental one,and is addressed at many points throughout this book.\nHere, it may be easier or preferable to explain by example.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":47,"topic":"Language Technology and Machine Translation"}}
{"id":"f09375a2-e0dd-4330-992f-eb515ed1d1cc","question":"What is the purpose of the LINGUANET project?","reference_answer":"LINGUANET is a project aimed at Communicating Through the Language Barrier.","reference_context":"Document 263: http:\/\/www.linglink.lu\/le\/projects\/select\nSPEAK (Supported Prototype Easy-Access Authoring Keys): http:\/\/www.linglink.lu\/le\/projects\/speak\nPublic Interest Projects\nAVENTINUS (Advanced Information System for Multilingual Drug Enforcement):\nhttp:\/\/www.linglink.lu\/le\/projects\/aventinus\nLINGUANET (Communicating Through the Language Barrier):\nhttp:\/\/www.linglink.lu\/le\/projects\/linguanet\nMIETTA (Multilingual Information Extraction for Tourism and Travel Assistance):\nhttp:\/\/www.linglink.lu\/le\/projects\/mietta\nSENSUS (LE for police and emergency service communications and information systems):\nhttp:\/\/www.linglink.lu\/le\/projects\/sensus\nInternational Business Support Projects\nDOCSTEP (Product DOCumentation Creation and Management using STEP):\nhttp:\/\/www.linglink.lu\/le\/projects\/docstep\nMABLE (Multilingual Authoring of Business Letters): http:\/\/www.linglink.lu\/le\/projects\/mable\nOTELO (Common Access to Translation Systems): http:\/\/www.linglink.lu\/le\/projects\/otelo\n\nDocument 262: Web information\n62cyber-sites\nEU Telematics Applications programmes\nGeneral information: http:\/\/www.echo.lu\/telematics\/\nInformation Services Projects\nEUROSEARCH (Multilingual European Federated Search Service):\nhttp:\/\/www.linglink.lu\/le\/projects\/access \nMAY (Multilingual Access to Yellow Pages): http:\/\/www.linglink.lu\/le\/projects\/may \nMULINEX (Multilingual Indexing Navigation and Editing Extensions for the World Wide Web):\nhttp:\/\/www.linglink.lu\/le\/projects\/mulinex\nEducation and Training Projects\nISLE (Interactive Spoken Language Education): http:\/\/www.linglink.lu\/le\/projects\/isle\nLETRAC (Language Engineering for Translator Curricula): http:\/\/www.linglink.lu\/le\/projects\/letrac\nRECALL (Repairing Errors in Computer-Aided Language Learning):\nhttp:\/\/www.linglink.lu\/le\/projects\/recall\nSELECT (Strategies for European LE-Enhanced Communication Training):\nhttp:\/\/www.linglink.lu\/le\/projects\/select\nSPEAK (Supported Prototype Easy-Access Authoring Keys): http:\/\/www.linglink.lu\/le\/projects\/speak\n\nDocument 266: Infrastructure and Support Projects\nDIET (Diagnostic and Evaluation Tools for Natural Language Applications):http:\/\/www.linglink.lu\/le\/projects\/dietEAGLES Expert Advisory Group on Language Engineering Standards):http:\/\/www.linglink.lu\/le\/projects\/eaglesELRA (European Language Resources Association): http:\/\/www.linglink.lu\/le\/projects\/elraELSE (Evaluation in Language and Speech Engineering): http:\/\/www.linglink.lu\/le\/projects\/else\/ELSNET (European Speech Language and Speech Network of excellence): www.elsnet.orgEUROMAP\/EUROMAP II (European Opportunity Mapping):http:\/\/www.linglink.lu\/le\/projects\/euromap\/LINGLINK (Promotion and Support for Language Engineering in Europe):http:\/\/www.linglink.lu\/le\/projects\/linglink\/MATE (Multi-Level Annotation Tools Engineering): http:\/\/www.linglink.lu\/le\/projects\/mate\/\nNews, Technology Culture\n\nDocument 265: the language machine\n63\nLanguage Resources Projects\nEUROWORDNET (Building a multilingual wordnet database with semantic relations between words): http:\/\/www.linglink.lu\/le\/projects\/eurowordnetPAROLE (Preparatory Action for linguistic Resources Organisation for Language Engineering):http:\/\/www.linglink.lu\/le\/projects\/le-paroleSIMPLE (Semantic Information for Multifunctional Plurilingual Lexica):http:\/\/www.linglink.lu\/le\/projects\/simpleSPEECHDAT (Speech Databases for Creation of Voice Driven Teleservices):http:\/\/www.linglink.lu\/le\/projects\/speechdat\nInfrastructure and Support Projects","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":263,"topic":"European Language Technology Projects"}}
{"id":"33606a16-4d4e-48cd-8c9d-040bd7a43744","question":"What technique does ELIZA use to mimic a Rogerian psychotherapist?","reference_answer":"ELIZA uses pattern matching to recognize phrases and translate them into suitable outputs.","reference_context":"Document 343: a Rogerian psychotherapist (Weizenbaum, 1966). ELIZA is a surprisingly simple\nprogram that uses pattern matching to recognize phrases like \u201cI need X\u201d and translate\nthem into suitable outputs like \u201cWhat would it mean to you if you got X?\u201d. This\nsimple technique succeeds in this domain because ELIZA doesn\u2019t actually need to\nknow anything to mimic a Rogerian psychotherapist. As Weizenbaum notes, this is\none of the few dialogue genres where listeners can act as if they know nothing of the\nworld. Eliza\u2019s mimicry of human conversation was remarkably successful: many\npeople who interacted with ELIZA came to believe that it really understood them\nand their problems, many continued to believe in ELIZA\u2019s abilities even after the\nprogram\u2019s operation was explained to them (Weizenbaum, 1976), and even today\nsuch chatbots are a fun diversion. chatbots\nOf course modern conversational agents are much more than a diversion; they\n\nDocument 376: bots like ELIZA (Weizenbaum, 1966). Recall that ELIZA simulates a Rogerian\npsychologist by carrying on conversations like the following:\nUser 1: Men are all alike.\nELIZA 1:IN WHAT WAY\nUser 2: They\u2019re always bugging us about something or other.\nELIZA 2:CAN YOU THINK OF A SPECIFIC EXAMPLE\nUser 3: Well, my boyfriend made me come here.\nELIZA 3:YOUR BOYFRIEND MADE YOU COME HERE\nUser 4: He says I\u2019m depressed much of the time.\nELIZA 4:I AM SORRY TO HEAR YOU ARE DEPRESSED\nELIZA works by having a series or cascade of regular expression substitutions\neach of which matches and changes some part of the input lines. Input lines are","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":343,"topic":"Others"}}
{"id":"5d8efaa9-c37d-49fe-9c03-64d467016cce","question":"What is the required length of the research proposal for the data mining and text analytics project?","reference_answer":"The research proposal for the data mining and text analytics project should be six pages long.","reference_context":"Document 8: \u00a9 University of Leeds   3 of 10  of your choice. So you have to decide what do you want to use data mining text analytics for, and \nthen write a research proposal.  \nYou could look at the Engineering and Physical Sciences Research Council guidance on how to \nwrite research project proposals, and there's a web link which should be in Minerva too. And I'll be \ntelling you more about this later on. For now, you just have to think  about what would be a useful \napplication of data mining and text analytics, and how would you go about implementing that. So \nwhat's the objective of your research proposal? And what's the work plan for your research \nproposal?  \nYou have to write well, six pages of English text. Obviously, you have to have a clear idea of what \nis the research hypothesis and objectives of what are you trying to achieve. And you have to have \na program of methodology. How do you achieve this? What's the work? It could be over si x\n\nDocument 576: online learning resources will include examples of data mining and text analytics methods, techniques, resources, and applications. You can also include other tools and techniques in your research proposal, as appropriate.  You should work in a TEAM of 4-6 students: choose your partners, choose a team name, then write your TEAM NAME next to YOUR NAME on the Class List, a shared file linked from Minerva. If you don\u2019t have partners, look at the Class List or post to the discussion forum to find others without a team, and ask them to join you. If you cannot work in a team and need to work alone, you can do so, but you must let the lecturer know: email e.s.atwell@leeds.ac.uk Each team must collaborate in developing a research project proposal, and produce a joint team report; all partners get the same grade. Every student must also take the individual tests 1 and 2.   When writing an applied data mining and text analytics research proposal, you can learn from advice provided by the","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":8,"topic":"Data Mining Course Assessment"}}
{"id":"01a84a65-eaa8-495c-abca-181146cd1400","question":"What benefits can language machines provide for the visually impaired?","reference_answer":"For the visually impaired, independent access to information has always been a barrier, and ICT offers the greatest liberation since Braille and audio-cassettes. Language machines can help disabled people to more easily access technology.","reference_context":"Document 236: to provide thought-provoking ideas.\u0091\nSimilarly, this book, The Language Machine , aims to\nprovide background information and fuel for ideas. How\nmight we develop the language machine? Can it be\nexploited for commercial benefit? What practical uses will it\nhave for people . whoever they are? Here we identify ways\nforward to continue the debate.leading the way\n56the next steps\nVerdicts on\nmachine translation\nSee page 37\n.Future development of language\nmachine technology must include\npeople who actively use the\nproducts for ordinary tasks \u0097 as\nhighlighted here by Derek Child,\nAssistant Director Equal Oppor-\ntunities, The Open University.\n\u0090For the visually impaired, indepen-\ndent access to information has\nalways been a barrier, and ICT\noffers the greatest liberation since\nBraille and audio-cassettes. But\ncompared to older text-based\nsystems, the visually-oriented\nGraphic User Interfaces can raise\nnew barriers.\nThe conventions set out by RNIB\nmight inform future software\n\nDocument 228: difficult to believe that its overall command of English will\nmatch (let alone exceed) that of an advanced learner of\nEnglish, even in 20 years\u0091 time. Translators and teachers \u0097\ncapable of judging social language, multiple meanings,\nnuance, subtle forms, and language complexities \u0097 do not\nneed therefore to fear they will be easily replaced!\nMore probably, machine translation will be used\nalongside good teaching and translation. It is used alreadyquestioning\n54the future\nThe digital\nhelping hand\nLanguage machines can help\ndisabled people to more easily\naccess technology: the following\nindicates some present activities.\nThe Royal National Institute for\nthe Blind (www.rnib.org.uk) offers\nextensive information on speech\nsynthesis packages and suppliers.\nThe EU\u0091s ISEAUS project aims to\nuse language engineering in\nspeech education and rehabil ita-\ntion for adults with lifelong or\nacquired deafness (see page 63).\nThe funding body EPSRC actively\nencourages researchers to work\n\nDocument 88: Machine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\nto plan and integrate the future use of language machines,\nwhether as a substitute for conventional human-to-human\ninteraction, or for the delivery of language teaching.the language machine\n17\n.Algorithms \u0087 Natural-language\nlearning \u0087 Hidden Markov Models\n\u0087 neural networks?\nSee Glossary, pages 58\u009759\nToo expensive\nto be useful? See page 28.English language teachers and\nlearners, according to a report on a\nsurvey of user requirements for\nthe ISLE project (ISLE, 1999)\ndesired, above all, a \u0090conversation\npractice machine\u0091 as an aid to\nlearning: with such a system a\nlearner could \u0090chat\u0091 in ordinary\nspoken English to practise every-\nday conversational language skills.\n.Natural-language learning\nsystems often use sophisticated\nstatistical pattern-matching models\n(for example Hidden Markov","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":236,"topic":"Language Machine Translation"}}
{"id":"19ea232d-a6ce-4ff9-9a6a-6ece7108167c","question":"What is the reward for the most human-like approximation to Turing's definition according to the Loebner Prize competition?","reference_answer":"Each year $2000 and a bronze medal goes to the most human-like approximation to Turing's definition, thanks to the Loebner Prize competition.","reference_context":"Document 62: more than 70% chance of making the right identification [as between human and computer] after five minutes\nof questioning\u0095. He predicted this 70% level for around 2000. \u0087\nEach year $2000 and a bronze medal goes to the most human-like approximation to Turing\u0091s definition, thanks\nto the Loebner Prize competition \u0087 $25,000 is up for grabs if the program\u0091s chance of being rumbled gets\nbelow Turing\u0091s 70%. This year\u0091s Loebner winner scored 89%. \u0087\nTuring\u0091s prescription was: stage one, build an educable system; stage two, educate it. (Educable means that\nprofessional teachers can take over without further help from implementers.) Turing called instances of stage\none \u0090child machines\u0091. They could be achieved today by an integration of new conversational agent\ntechnologies with state-of-the-art machine learning.\u0091 (The Guardian, June 24 1999.)Getting to grips\nwith basics\nSee pages 8 & 9\n1791 Kempelen\u0091s speaking machine\n1863 Bell\u0091s \u0090talking head\u0091\n1872 Edison invents electric typewriter","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":62,"topic":"Others"}}
{"id":"c627f316-6834-4ab2-b973-e6606ab29e50","question":"What factors might have contributed to the success of Lernout and Hauspie in the market?","reference_answer":"Lernout and Hauspie's success can be attributed to the trend to build in products, the likely mass-consumer markets ahead, supported by major players, and the significance of multilingualism. Operating in a multilingual environment may have assisted the development and take-up of products.","reference_context":"Document 175: nology, which it is likely to use in\ndeveloping the next generation of\nvoice-enabled computing for the\nMicrosoft Windows platform.\nLernout and Hauspie\u0091s market\nposition highlights several points:\nthe trend to build in products; the\nlikely mass-consumer markets\nahead, supported by the major\nplayers \u0097 and the significance of\nmultilingualism. The company has\nrisen in a multilingual environment\nwhich may have assisted the\ndevelopment and take-up of\nproducts. This latter point may\nserve as a cautionary note to\nthose companies operating in a\nmonolingual context.SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":175,"topic":"Others"}}
{"id":"e2054ac5-5d0e-4b23-854b-c44859f621f2","question":"Why was the term 'dynamic programming' chosen?","reference_answer":"The term 'dynamic programming' was chosen to get across the idea that it was dynamic and multi-stage. The word 'dynamic' was chosen specifically because it has a precise meaning and it's impossible to use it in a pejorative sense.","reference_context":"Document 442: the term dynamic programming :\n\u201c...The 1950s were not good years for mathematical research. [the]\nSecretary of Defense ...had a pathological fear and hatred of the word,\nresearch... I decided therefore to use the word, \u201cprogramming\u201d. I\nwanted to get across the idea that this was dynamic, this was multi-\nstage... I thought, let\u2019s ... take a word that has an absolutely precise\nmeaning, namely dynamic... it\u2019s impossible to use the word, dynamic,\nin a pejorative sense. Try thinking of some combination that will pos-\nsibly give it a pejorative meaning. It\u2019s impossible. Thus, I thought\ndynamic programming was a good name. It was something not even a\nCongressman could object to.\u201d","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":442,"topic":"Others"}}
{"id":"0b45213c-fea8-49e2-8ddc-d5d755b9e388","question":"What are the challenges and solutions in recognising handwritten text?","reference_answer":"Handwritten text can present more daunting problems: few people's handwriting is as consistent or as clearly legible as a typeface, and the recognition techniques must also take into account joining strokes and other variables. Language machines need techniques for recognising handwritten script and incorporating optical character recognition (OCR).","reference_context":"Document 104: difficulties by highlighting specific phonemes where the\nlearner deviates from the model.\nWritten or printed language input  Another way to produce\nwritten text \u0097 or, rather, printed text \u0097 is to type it into a\nword processor, email or desktop publishing package. For\nmany people, however, a lack of keyboard skills can make\nusing a computer a daunting, slow or potentially\nembarrassing task. The text may also exist in typed or\nprinted form, but the \u0090electronic\u0091 copy may not be available\nor in a usable file format.\nTo address these scenarios, language machines need\ntechniques for recognising handwritten script and\nincorporating optical character recognition (OCR). In the\ncase of OCR, text is scanned and the image is then\ninterpreted and converted into an Ascii text file. Most OCR\npackages can be trained to recognise particular fonts or\ntypefaces to reduce errors in interpretion: applying a spell-\nchecker to the initial output will often further reduce\ntranscription errors.\n\nDocument 105: packages can be trained to recognise particular fonts or\ntypefaces to reduce errors in interpretion: applying a spell-\nchecker to the initial output will often further reduce\ntranscription errors. \nHandwritten text can present more daunting problems:\nfew people\u0091s handwriting is as consistent \u0097 or as clearly\nlegible \u0097 as a typeface, and the recognition techniques must\nalso take into account joining strokes and other variables.\nLanguage analysis and understanding  Whether language is\ninput as speech, by scanning, in writing or typed via a\nkeyboard, the next stage involves linguistic analysis of the\ncharacter-sequences. \nWords must be first identified in a computer dictionary\nusing a \u0090lemmatiser\u0091, which computes the root (or lemma)\nfor any input word. The dictionary may also be used by a\npart-of-speech tagger (see page 48) , which computes the\ngrammatical word-class of each word, and by a semantic\ntagger, which annotates each input word with a represen-","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":104,"topic":"Others"}}
{"id":"c197063f-10a2-47d0-8e94-2340fc62aeef","question":"What are the three major focus areas identified by Varile for EU projects?","reference_answer":"1. Adding multilinguality to information and communication systems, at all stages of the information cycle, including content generation and maintenance in multiple languages, content and software localisation, automated translation and interpretation, and computer assisted language training; 2. Providing natural interactivity and accessibility of digital services through multimodal dialogues, understanding of messages and communicative acts, unconstrained language input-output and keyboard-less operation.","reference_context":"Document 172: UK involvement across Europe\nMany research groups also participate in European and\ninternational projects and networks as the following shows.\nELSNET: European research Network in Language and\nSpeech This \u0090network of excellence\u0091 is funded by the EU,\naiming to foster collaborative research and dissemination\nof results across Europe. The UK is a major participant, with\n11 industrial and 12 academic sites (including the UK bases\nof several international companies, and many of the\nuniversities hosting EPSRC research). ELSNET organises\nEuropean meetings, publishes a regular ELSNews news-\nletter, and runs an email list and Web site. It also\ncommissions reports and surveys, including a survey of\ntools and techniques for machine translation teaching\n(Balkan et al, 1997). \nICAME: International Computer Archive of Modern and\nMedieval English  Based at Bergen University, Norway,\nICAME started in the early 1970s as an informal grouping of\nuniversity English corpus linguistics researchers, English\n\nDocument 168: What\u0091s happening in the UK?\nAs well as basing research and development laboratories in\nthe UK, the companies involved in developing speech and\nlanguage technology can also collaborate with the many\nuniversity researchers to mutual benefit: indeed UK\nresearchers in universities and industry research centres\nare involved in all the component technologies and sub-\nfields listed on pages 20\u009725. \nThe UK community is also brought into regular contact\nvia a SALT Club  managed by the EPSRC (Engineering and\nPhysical Science Research Council) and the Department for\nTrade and Industry, which organises meetings, newsletters,\nan email bulletin board and Web site (see page 63),\ndesigned for information dissemination and the\nencouragement of commercial applications for speech and\nlanguage technology.\nThe EPSRC also funds a number of research projects at\nuniversities . across the UK; these are reviewed in EPSRC\npublications (EPSRC, 1996) which include summaries of\n\nDocument 170: (Queen\u0091s), Brighton, Cambridge,\nEdinburgh, Essex, Imperial, Keele,\nLeeds, Liverpool, London (SOAS,\nUCL), Manchester, Sheffield,\nSouthampton, Sussex, and York\neach research into language\nmachines. (EPSRC, 1996)\nWhat do EU projects aim to do? \nThe EU is a major force in research, development, funding, collaboration and project support, yet manypeople remain unaware of project aims and achievments. Varile has identified three major focus areas:\n1. adding multilinguality to information and communication systems, at all stages of the information cycle,\nincluding content generation and maintenance in multiple languages, content and software localisation, auto-\nmated translation and interpretation, and computer assisted language training; \n2. providing natural interactivity and accessibility of digital services through multimodal dialogues,\nunderstanding of messages and communicative acts, unconstrained language input-output and keyboard-\nless operation;","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":172,"topic":"Language Technology Research and Development"}}
{"id":"6cc2a5c4-a804-43e6-8df6-b976f5102155","question":"What are some common uses for niche markets for specialist tasks?","reference_answer":"Some common uses for niche markets for specialist tasks include creating commercial documents in the appropriate language, creating multilingual documents, providing translations, and localising technical and instructional manuals.","reference_context":"Document 152: niche markets for specialist tasks.\nWe can also expect to see it in\ncommon use for: creating\ncommercial documents in the\nappropriate language; creating\nmultilingual documents; providing\ntranslations; localising technical\nand instructional manuals.SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":152,"topic":"Others"}}
{"id":"bcc1f2ba-c7b3-4119-aec5-14d9615bad27","question":"What are some potential challenges for the use of language machine technology?","reference_answer":"Some potential challenges include the cost of hardware and software, technophobia, the impact on language-based professions, the need for collaboration between computer scientists and language professionals, and the potential for increased division and inequality. There are also questions about the cultural and social impact if we stop learning languages, whether endangered languages will be saved or neglected, and whether some languages will benefit more than others from these technologies.","reference_context":"Document 281: hearing and sight-impaired stand to gain from these\ntechnologies, but will hardware and software costs or\ntechnophobia become new sources of division and\ninequality?\nHow will technology change our interactions? How will we\nadapt once technology shapes \u0097 and speaks \u0097 the actual\nwords we send and receive? Will speech recognition re-\nemphasise oral skills?\nHow will a greater transparency of information in other\nlanguages affect economies? \nWill customer services be automated further, with personal\ninteraction becoming a premium service in the 21st\ncentury?\nWill the UK be seen as a leader of language machine\ntechnology?\n\nDocument 280: questions\n70for debate\nHow will the language machine affect the language-based\nprofessions? \nHow can computer scientists and language professionals\ncollaborate to mutual benefit?\nHow will practitioners find ways of influencing and\ninforming \u0097 and of staying informed of \u0097 developments\nin technology and best practice? If discussion is needed,\nhow will it be facilitated? \nWill we stop learning languages? And, if we do, what will\nbe the cultural and social impact?\nWill endangered languages be saved by a lesser need to\nlearn a lingua franca, or will software not be developed\nfor languages with smaller, less profitable audiences? \nNot all languages are similarly alphabetic, phonetic or\ntonal. Will some languages benefit more than others?\nHow equally will we benefit? Linguistic minorities and the\nhearing and sight-impaired stand to gain from these\ntechnologies, but will hardware and software costs or\ntechnophobia become new sources of division and\ninequality?","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":281,"topic":"Others"}}
{"id":"5a9ff53a-8746-4813-bf61-2bcfaf347f67","question":"What is the Levenshtein distance between the words 'intention' and 'execution'?","reference_answer":"The Levenshtein distance between 'intention' and 'execution' is 5.","reference_context":"Document 423: seems like useful evidence for deciding that they might be coreferent.\nEdit distance gives us a way to quantify both of these intuitions about string sim-\nilarity. More formally, the minimum edit distance between two strings is de\ufb01nedminimum edit\ndistance\nas the minimum number of editing operations (operations like insertion, deletion,\nsubstitution) needed to transform one string into another.\nThe gap between intention andexecution , for example, is 5 (delete an i, substi-\ntuteeforn, substitute xfort, insertc, substitute uforn). It\u2019s much easier to see\nthis by looking at the most important visualization for string distances, an alignment alignment\nbetween the two strings, shown in Fig. 2.14. Given two sequences, an alignment is\na correspondence between substrings of the two sequences. Thus, we say Ialigns\nwith the empty string, NwithE, and so on. Beneath the aligned strings is another\nrepresentation; a series of symbols expressing an operation list for converting the\n\nDocument 425: 22 CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\nINTE*NTION\n||||||||||\n*EXECUTION\nd s s i s\nFigure 2.14 Representing the minimum edit distance between two strings as an alignment .\nThe \ufb01nal row gives the operation list for converting the top string into the bottom string: d for\ndeletion, s for substitution, i for insertion.\nWe can also assign a particular cost or weight to each of these operations. The\nLevenshtein distance between two sequences is the simplest weighting factor in\nwhich each of the three operations has a cost of 1 (Levenshtein, 1966)\u2014we assume\nthat the substitution of a letter for itself, for example, tfort, has zero cost. The Lev-\nenshtein distance between intention andexecution is 5. Levenshtein also proposed\nan alternative version of his metric in which each insertion or deletion has a cost of\n1 and substitutions are not allowed. (This is equivalent to allowing substitution, but","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":423,"topic":"Minimum Edit Distance Algorithm"}}
{"id":"a2df9143-2b6a-40e7-bb0d-cd91df223fd4","question":"What is the order of operator precedence in regular expressions?","reference_answer":"The order of operator precedence in regular expressions, from highest precedence to lowest precedence, is: Parenthesis (), Counters * + ? {}, Sequences and anchors the \u02c6my end$, Disjunction |.","reference_context":"Document 363: 6CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\n\/(Column\u2423[0-9]+\u2423*)*\/ to match the word Column , followed by a number and\noptional spaces, the whole pattern repeated zero or more times.\nThis idea that one operator may take precedence over another, requiring us to\nsometimes use parentheses to specify what we mean, is formalized by the operator\nprecedence hierarchy for regular expressions. The following table gives the orderoperator\nprecedence\nof RE operator precedence, from highest precedence to lowest precedence.\nParenthesis ()\nCounters * + ? {}\nSequences and anchors the \u02c6my end$\nDisjunction |\nThus, because counters have a higher precedence than sequences,\n\/the*\/ matches theeeee but not thethe . Because sequences have a higher prece-\ndence than disjunction, \/the|any\/ matches theoranybut not thany ortheny .\nPatterns can be ambiguous in another way. Consider the expression \/[a-z]*\/\nwhen matching against the text once upon a time . Since\/[a-z]*\/ matches zero or","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":363,"topic":"Regular Expressions"}}
{"id":"b47924a6-8766-4b56-b6f4-f9ab30d1f394","question":"What is the title of the work by J. Godfrey, E. Holliman, and J. McDaniel published in 1992?","reference_answer":"The title of the work by J. Godfrey, E. Holliman, and J. McDaniel published in 1992 is 'SWITCHBOARD: Telephone speech corpus for research and development.'","reference_context":"Document 447: Bostrom, K. and G. Durrett. 2020. Byte pair encoding is\nsuboptimal for language model pretraining. Findings of\nEMNLP .\nChen, X., Z. Shi, X. Qiu, and X. Huang. 2017. Adversar-\nial multi-criteria learning for Chinese word segmentation.\nACL.\nChurch, K. W. 1994. Unix for Poets. Slides from 2nd EL-\nSNET Summer School and unpublished paper ms.\nClark, H. H. and J. E. Fox Tree. 2002. Using uh and um in\nspontaneous speaking. Cognition , 84:73\u2013111.\nEgghe, L. 2007. Untangling Herdan\u2019s law and Heaps\u2019\nlaw: Mathematical and informetric arguments. JASIST ,\n58(5):702\u2013709.\nGebru, T., J. Morgenstern, B. Vecchione, J. W. Vaughan,\nH. Wallach, H. Daum \u00b4e III, and K. Crawford.\n2020. Datasheets for datasets. ArXiv preprint\narXiv:1803.09010.\nGodfrey, J., E. Holliman, and J. McDaniel. 1992. SWITCH-\nBOARD: Telephone speech corpus for research and de-\nvelopment. ICASSP .\nGus\ufb01eld, D. 1997. Algorithms on Strings, Trees, and Se-\nquences: Computer Science and Computational Biology .\nCambridge University Press.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":447,"topic":"Others"}}
{"id":"71e380ba-850d-40df-a50c-8967cd566d4a","question":"What does the terminology extraction function do in Sketch Engine?","reference_answer":"Terminology extraction in Sketch Engine compares the words in your corpus against the words in a standard English corpus, like the British National Corpus. It finds words which are more frequent, relatively speaking, in your corpus than in the standard corpus.","reference_context":"Document 462: \u00a9 University of Leeds   3 of 8 interface, remembering the paper is now a few years old. But it has the same functionality as we're \nabout to see. So you create a corpus by choosing a name, choosing a language, choosing various \nother parameters.  \nLike, one way  of doing it is by giving a list of URLs. But we don't know in advance what the URLs \nare. But you can give a list of seed words, and seed words are words or phrases that you think are \ngoing to be typical of your topic area and various other parameters.  \nAnd having got your corpus, we have terminology extraction. What this does is it compares the \nwords in your corpus against the words in a standard English corpus, for example, the British \nNational Corpus, and it finds words which are more frequent, relatively  speaking, in your corpus \nthan in the standard corpus. So if, for example, we had a volcanology corpus of volcan terms, then\n\nDocument 463: National Corpus, and it finds words which are more frequent, relatively  speaking, in your corpus \nthan in the standard corpus. So if, for example, we had a volcanology corpus of volcan terms, then \nthese are words which are more common in the volcanology corpus compared to, let's say, the \nBritish National Corpus.  \nOther things y ou can do in Sketch Engine too. You can extract word lists, that is words which are \nparticularly frequent in your corpus. It's not the same thing as the terms we just got out because \nthe word list is just a frequency list from your corpus.  \nWhat really matt ers is how frequent are the words in your corpus compared to a standard corpus? \nSo for that, you have to compare these frequency lists against the frequency lists, for example, for \nthe British National Corpus. And that's what terminology does, whereas you can, if you want to, \njust get out word frequency list from your corpus or multi -word expressions from your corpus.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":462,"topic":"Corpus Linguistics Software"}}
{"id":"187ff1e8-c4a7-47bf-9296-99e0d46af057","question":"What is the main reason for looking at the Leeds Internet Corpora webpage according to the context?","reference_answer":"The main reason for looking at the Leeds Internet Corpora webpage is that it has some information on open source development of large corpora.","reference_context":"Document 478: \u00a9 University of Leeds   7 of 8 OK, I think I've had a quick look at Sketch Engine and used it to collect corpus and extract some \nthings from the corpus. So let's go back to our Po werPoint presentation. So we've had a quick look \nat Sketch Engine. Let's have a look at Leeds Internet Corpora. I won't spend that much time on \nthis. \nBut here is the website, and you can query the corpora in much the same way as Sketch Engine \nqueries the corpora. And you can get a concordance out. And again, most of these things, these \nare things that Sketch Engine could do for you. The real reason for looking at this web page is it \nhas some information on open source development of large corpo ra. So if you want to collect a \nvery large corpus of, let's say, a billion words or half a billion words from the web, then you have to \ncollect not just two or three keywords.  \nYou typically want to have about 500 keywords. And the keywords should be not fo r your","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":478,"topic":"Others"}}
{"id":"13dd1390-1dbe-4745-94ed-54549eccb7fa","question":"What is the maximum number of marks that can be achieved in the 'Programme and methodology' and 'Appendix' sections of the research proposal report?","reference_answer":"The maximum number of marks that can be achieved in the 'Programme and methodology' and 'Appendix' sections of the research proposal report is 18 each.","reference_context":"Document 582: and methodology, and Appendix: these are most important, and are triple-weighted, so get mark in range 0-18.  In your research proposal report, we will assess:  Background (0-6 marks) Contribution to knowledge (0-6 marks) Importance (0-6 marks) Research hypothesis and objectives (0-6 marks) Programme and methodology, including workplan diagram (0-18 marks) Appendix: use of data mining and text analytics tools in developing your Report (0-18 marks) TOTAL: up to 60 marks  Return of marks and feedback will be via Minerva grade center, approximately 3 weeks after submission.\n\nDocument 586: In your research proposal report, we will assess: Background (0-6 marks) Contribution to knowledge (0-6 marks) Importance (0-6 marks) Research hypothesis and objectives (0-6 marks) Programme and methodology, including workplan diagram (0-18 marks) Appendix: use of data mining and text analytics tools in developing your Report (0-18 marks) TOTAL: up to 60 marks\n\nDocument 581: two data mining and\/or text analytics methods, tools or techniques introduced in the module (eg SketchEngine, Weka, ChatGPT) 1-page workplan diagram must match the written description of the research work programme, showing start, end and duration of each phase or work-package.   EPSRC Evaluation Criteria: When a research project proposal is submitted to EPSRC, they check it meets the requirements, then send the proposal to several independent experts for Peer Review. These peer reviewers then give written feedback on strengths and weaknesses of the proposal, and marks or scores in the range 0-6.   4. Assessment criteria and marking process The mark scheme for your report will reflect the EPSRC grading scheme with marks in the range 0-6 for each criterion, EXCEPT the sections on Programme and methodology, and Appendix: these are most important, and are triple-weighted, so get mark in range 0-18.  In your research proposal report, we will assess:  Background (0-6 marks) Contribution to","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":582,"topic":"Academic Research Proposal Guidance"}}
{"id":"e13e0604-f768-40dc-aaaf-e0a16070c314","question":"What issues can affect the accuracy of speech recognition?","reference_answer":"Noisy environments or telecommunication networks can make speech recognition less accurate. Accurate recognition depends on excluding other voices and sounds to prevent the language machine's attempts to decipher them.","reference_context":"Document 151: is a design that many people find distractingly noisy \u0097 sound barriers are already becoming more common \u0097\nand if more of us spend more time talking than typing, barriers may become standard fittings.\nAt present, sound levels remain a problem to routine use in the office \u0097 noisy environments or\ntelecommunication networks can make speech recognition less accurate. Noise-reduction technologies,\nspecialist microphones, signal enhancement, and keyword spotting can all help, but accurate recognition\ndepends on excluding other voices and sounds to prevent the language machine\u0091s attempts to decipher them..Practical applications  for the\nlanguage machine have remained\nlargely hidden from popular view,\nused instead in large-scale, third-\nparty systems. However, the\ntechnology is being adopted in\nniche markets for specialist tasks.\nWe can also expect to see it in\ncommon use for: creating\ncommercial documents in the\nappropriate language; creating\nmultilingual documents; providing","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":151,"topic":"Speech and Language Technology"}}
{"id":"6f85da19-80d1-49ca-a550-58a12afcf2d1","question":"What kind of companies are primarily involved in the development and sale of speech and language technology applications?","reference_answer":"The main companies developing and selling applications in the field of speech and language technology are transnational. They are not solely European or British and many have either American or Japanese parent companies. Some of the mainstream IT big names include IBM, Microsoft, Apple, and DEC-Compaq. Additionally, electronics and telecommunications companies such as Philips, Canon, Sharp, BT, Cellnet are developing and selling related systems. There are also smaller 'niche' companies specialising in speech and language technology.","reference_context":"Document 165: A global interest\nLike other IT systems and products, research and\ndevelopment involves both universities and industry: while\nacademic researchers have generally explored fundamental\ntheory, industry has normally focused on turning theory\ninto products for markets and consumers. \nIn the field of speech and language technology, the main\ncompanies developing and selling applications are trans-\nnational, rather than solely European or British: although\nmany have offices or facilities in Britain, most have either\nAmerican or Japanese parent companies. Much significant\nresearch and development takes place in the parent\ncountries, with UK and European offices concerned with\nlocalisation of software, such as converting on-screen\nprompts and help-files to local languages, or providing\nlocal support and consultancy.\nWhen assessing a country\u0091s productivity, examining\nexport volume alone can therefore be misleading: although\nIreland and the USA, for example, export roughly equal\n\nDocument 166: local support and consultancy.\nWhen assessing a country\u0091s productivity, examining\nexport volume alone can therefore be misleading: although\nIreland and the USA, for example, export roughly equal\ntotal volumes of software, Irish software exports focus on\nlocal, European versions of American products.\nThe EU is now trying to foster more homegrown\nresearch and development, in IT generally and language\nengineering specifically. Clearly, this is an appropriate\nstrategy: there is massive global interest in language\nmachines to merit the commercial investments in time,\nstaffing and funding, and the mainstream IT big names \u0097\nincluding IBM, Microsoft, Apple, and DEC-Compaq \u0097 will all\nhave an interest in seeing the technology used and\naccepted. A number of electronics and telecommunications\ncompanies (such as Philips, Canon, Sharp, BT, Cellnet) are\ndeveloping and selling related systems.\nA third category of language machine players are\nsmaller \u0090niche\u0091 companies specialising in speech and","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":165,"topic":"Language Technology Research and Development"}}
{"id":"b72dbebb-f424-4f79-9087-29013c208936","question":"What are some of the major IT companies interested in language machine technology?","reference_answer":"IBM, Microsoft, Apple, and DEC-Compaq are some of the major IT companies interested in language machine technology.","reference_context":"Document 165: A global interest\nLike other IT systems and products, research and\ndevelopment involves both universities and industry: while\nacademic researchers have generally explored fundamental\ntheory, industry has normally focused on turning theory\ninto products for markets and consumers. \nIn the field of speech and language technology, the main\ncompanies developing and selling applications are trans-\nnational, rather than solely European or British: although\nmany have offices or facilities in Britain, most have either\nAmerican or Japanese parent companies. Much significant\nresearch and development takes place in the parent\ncountries, with UK and European offices concerned with\nlocalisation of software, such as converting on-screen\nprompts and help-files to local languages, or providing\nlocal support and consultancy.\nWhen assessing a country\u0091s productivity, examining\nexport volume alone can therefore be misleading: although\nIreland and the USA, for example, export roughly equal\n\nDocument 166: local support and consultancy.\nWhen assessing a country\u0091s productivity, examining\nexport volume alone can therefore be misleading: although\nIreland and the USA, for example, export roughly equal\ntotal volumes of software, Irish software exports focus on\nlocal, European versions of American products.\nThe EU is now trying to foster more homegrown\nresearch and development, in IT generally and language\nengineering specifically. Clearly, this is an appropriate\nstrategy: there is massive global interest in language\nmachines to merit the commercial investments in time,\nstaffing and funding, and the mainstream IT big names \u0097\nincluding IBM, Microsoft, Apple, and DEC-Compaq \u0097 will all\nhave an interest in seeing the technology used and\naccepted. A number of electronics and telecommunications\ncompanies (such as Philips, Canon, Sharp, BT, Cellnet) are\ndeveloping and selling related systems.\nA third category of language machine players are\nsmaller \u0090niche\u0091 companies specialising in speech and","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":165,"topic":"Language Technology Research and Development"}}
{"id":"eca32e36-e1e8-4700-8628-1742066edfee","question":"What can Word n-gram models be used to predict?","reference_answer":"Word n-gram models can be used to predict Multi-Word Expressions and estimates of sentence probabilities.","reference_context":"Document 590: Semantics,  the study of formal representations of meanings of words and sentences  \nSyntax, the study of words and Multi -Word Expressions  \n5. Question 5  \nWhen using a binary classifier to identify instances of the minority class in a skewed data -\nset, which of the following is the most appropriate evaluation metric?  \nSelect one answer.  \nAccuracy  \nRecall  \nCross -validation  \nPrecision  \n6. Question 6  \nSelect two answers that complete the following statement correctly.  \nWeka stringtowordvector filter is used to convert a string feature to [BLANK].  \na numerical representation  \na sequence of numbers  \na vector of words  \na word feature  \n7. Question 7  \nSelect two answers that complete the following statement correctly.  \nWord n -gram models can be used to predict [BLANK].  \nthe Markov assumption  \nMulti -Word Expressions  \nestimates of sentence probabilities  \nlong distance dependencies  \n8. Question 8  \nAn IBk classifier test run results in the following confusion matrix:","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":590,"topic":"Machine Learning and Text Processing"}}
{"id":"452e62c6-1303-47a6-84f7-50f802f80065","question":"What is the purpose of the WebBootCaT feature in the Sketch Engine tool?","reference_answer":"WebBootCaT within Sketch Engine is used for building a corpus from the web. It starts from a set of 'seed words', makes tuples (typically triples) of the seed words, sends each tuple as a query to a search engine, and then gathers the web pages that the search engine finds. This is an efficient way of discovering the terminology and phraseology of a specialist domain.","reference_context":"Document 536: function, etc.) then it needs to be in the Sketch Engine\u2019s input format, \u2018vertical\u2019 text,\nas documented in the Sketch Engine help pages. The user can then manage theirown corpora, including adding more data, deleting, and processing (see below) aswell as using them for their research via the core Sketch Engine functions (as inSect. 2).\nBootCaT (Baroni and Bernardini 2004 ) is a procedure for building a corpus,\nstarting from a set of \u2018seed words\u2019, by making tuples (typically triples) of the seedwords, sending each tuple as a query to a search engine, and then gathering the web\npages that the search engine \ufb01nds. When applied to a specialist domain, with seed\nwords from that specialist domain, it turns out to be a remarkably ef\ufb01cient way ofdiscovering the terminology and phraseology of that domain. The Sketch Engineincludes an implementation called WebBootCaT. See Fig. 18for the WebBootCaT\n\nDocument 483: you've introduced Sketch Engine as a web tool for corpus linguistics. You've been introduced to \nWebBootCaT within Sketch engine as a way of collecting a corpus from the web. You can use it \nyourself to collect your own corpus  and then to extract a list of terminology from that corpus.  \nMainly the multi -word expressions are the important ones for your domain. You can look at Leeds \ninternet corpora if you ever want to collect a billion word corpus, and this gives you more \ninforma tion about how to go about collecting seed words for this and then using those. Or if you \nwant to do some research in a particular area, then look at the ACL Special Interest Group for that \narea. You should have read or be reading or about to read Adam Kil garriff's paper on the search \nengine because it's got more examples in it. And look at the websites.  \n \n[END]","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":536,"topic":"Corpus Linguistics Software"}}
{"id":"d8be151e-5aa2-4cfd-bcf3-d68efa5babd4","question":"What is the title of the work by Kilgarriff and Rundell presented at the Proc EURALEX in Copenhagen, Denmark?","reference_answer":"The title of the work is 'Lexical Pro\ufb01ling Software and its lexicographic applications: a case study.'","reference_context":"Document 568: Kilgarriff, A., C.R. Huang, P. Rychly \u00b4, S. Smith, and D. Tugwell. 2005. Chinese word sketches. In Proc\nASIALEX 2005: Words in Asian cultural context . Singapore.\nKilgarriff, A., M. Husa \u00b4k, K. McAdam, M. Rundell, and P. Rychly \u00b4. 2008. GDEX: automatically \ufb01nding\ngood dictionary examples in a corpus. In Proc. Euralex . Barcelona\nKilgarriff, A., and I. Renau. 2013. esTenTen, a Vast Web Corpus of Peninsular and American Spanish.\nProcedia Social and Behavioral Sciences 95: 12\u201319.\nKoehn, P. 2005. Europarl: a parallel corpus for statistical machine translation. Proc MT summit 5: 79\u201386.\nKosem, I., M. Husak, and D. McCarthy. 2011. GDEX for Slovene. In Proceedings of eLex , 151\u2013159.\nBled, Slovenia.\nKosem, I., V. Baisa, V. Kova \u00b4r\u02c7, and A. Kilgarriff. 2013. User-friendly interface of error\/correction-\nannotated corpus for both teachers and researchers . Solstrand: Proc Learner Corpus Research.\n\nDocument 566: Jakub\u0131 \u00b4c\u02c7ek, M., A. Kilgarriff, V. Kova \u00b4r\u02c7, P. Rychly \u00b4, and V. Suchomel. 2013. The TenTen corpus family .\nLancaster: In Proc. Int. Conf. on Corpus Linguistics.\nKerswill, P., J. Cheshire, S. Fox, and E. Torgersen. 2013. English as a contact language: the role of\nchildren and adolescents. In English as a Contact Language , 258.\nKilgarriff, A. 2001. Comparing corpora. International Journal of Corpus Linguistics 6(1): 97\u2013133.\nKilgarriff, A. 2007. Googleology is bad science. Computational linguistics 33(1): 147\u2013151.\nKilgarriff, A. 2012. Getting to know your corpus. In Text, Speech and Dialogue , 3\u201315. Berlin Heidelberg:\nSpringer.\nKilgarriff, A. 2013. Terminology \ufb01nding, parallel corpora and bilingual word sketches in the Sketch\nEngine. In Proc ASLIB 35th Translating and the Computer Conference , London.\nKilgarriff, A., and M. Rundell. 2002. Lexical Pro\ufb01ling Software and its lexicographic applications: a case\nstudy. In Proc EURALEX . Copenhagen, Denmark.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":568,"topic":"Corpus Linguistics Software"}}
{"id":"f0cf1e25-ea01-47b2-aa3b-18373611708e","question":"Could you describe some methods to personalize this digital book using the full Acrobat software, including adding web addresses, making notes, and highlighting text?","reference_answer":"With the full Acrobat software, you can annotate the document to customize it for your own use. For example, you can add your favorite web site addresses, make notes in the margins, or highlight text in the same way as you would with a marker pen on conventional paper-based books.","reference_context":"Document 285: accompanying your copy of the Acrobat Reader, as navigation methods can vary betweenversions and operating systems.\nYou can print out a single page, or multiple pages, of this document. (If you do so, please ensureyou conform to the licence conditions.) If you have the full Acrobat software running on yourcomputer, then you can annotate this document to customise it for your own use. For example,you can add your favourite Web site addresses, make notes in the margins, or highlight text inthe same way as you would with a marker pen on conventional paper-based books.\nWe suggest you explore the many different ways of viewing and using this digital book, to\nfind those which are convenient on your own machine.how to read this digital book\nw","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":285,"topic":"Others"}}
{"id":"b000b2c5-cb8d-4000-9ef5-f7f4057d8f57","question":"In the assessment of the COMP2121 Data Mining and Text Analytics module, what is the percentage contribution of the report towards the final grade?","reference_answer":"The report carries a weightage of 60% in the COMP2121 Data Mining module assessment.","reference_context":"Document 575: 1. Assignment guidance You are advised to attempt all three assessments: Test1, Test2, Report. There is no exam.  2. Assessment tasks For Test1 and Test2, each student will take an individual online test in Minerva. The tests will include Multiple Answer Questions: each question has several suggested answers, and for each possible answer you must decide if it is correct or not. If you require special arrangements and\/or extra time due to a disability or other special circumstances, please make sure you notify lecturer Eric Atwell AND student support well in advance so they can prepare accordingly.  For the Report, you will develop a research project proposal, using data mining and text analytics theory, methods and technologies for a practical application of your choice. Lectures and online learning resources will include examples of data mining and text analytics methods, techniques, resources, and applications. You can also include other tools and techniques in your research\n\nDocument 574: Word limit and guidance Test1: 20 questions. Test2: 20 questions. Report: up to 12 pages Weighting Test1: 20% Test2: 20%. Report: 60% Submission deadline Test1: 10:00 Thursday 23.2.23 Test2: 10:00 Thursday 23.3.23 Report: 10:00 Thursday 4.5.23 Submission method Test1 submitted as Minerva MCQ Test Test2 submitted as Minerva MCQ Test Report submitted by team leader as Minerva Assignment Feedback provision Yes: Test1, Test2 answers will be presented in a lecture;  Report feedback via Minerva Assignment Learning outcomes assessed These exercises will enable you to: learn theory, methods and terminology used in data mining and text analytics; investigate how to apply AI methods, resources and techniques for implementing and evaluating data mining and text analytics in a practical applied research project; summarize and present your knowledge and ideas to a peer audience, in a research proposal report. Module lead Prof Eric Atwell Other Staff contact Dr Noorhan Abbas\n\nDocument 573: School of Computing: Assessment brief    Module title Data Mining Module code COMP2121 Assignment title Assessment for COMP2121 Data Mining, Semester 2 2022\/23 Assignment type and description Assessment 1: Test1 submitted as Minerva MCQ Test, 20% weight, 1 hour to complete, release week4 10:00 Wednesday 22.2.23, deadline 10:00 Thursday 23.2.23   Assessment 2: Test2 submitted as Minerva MCQ Test, 20% weight, 1 hour to complete, release week8 10:00 Wednesday 22.3.23, deadline 10:00 Thursday 23.3.23   Assessment 3: Report on team project, submitted by team leader as Minerva Assignment, 60% weight, approx 10 hours per student to complete, release week4 Wednesday 22.2.23, deadline week10 10:00 Thursday 4.5.23 Rationale Summative assessment of student knowledge and understanding of the module syllabus. Word limit and guidance Test1: 20 questions. Test2: 20 questions. Report: up to 12 pages Weighting Test1: 20% Test2: 20%. Report: 60% Submission deadline Test1: 10:00 Thursday 23.2.23 Test2:","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":575,"topic":"Data Mining Course Assessment"}}
{"id":"e7c0a4e6-64a0-404c-bcf4-11b5b98b8cab","question":"What are the potential challenges and risks associated with incorporating a language machine into an existing system, particularly in reference to error-rates and task approach?","reference_answer":"If we simply try to add a language machine to an existing system, the fit may not be perfect. Using a speech recogniser is a quite different process from typing into a word processor: people can speak much faster than they can type; words will not be recognised and transcribed correctly, leaving the speaker to review and correct mistakes. The time taken to dictate a book could be longer than the time taken to type it from scratch.","reference_context":"Document 141: Safety critical computing is a key area where language\nmachines may be not just unwise but dangerous, at least\nuntil error-rates are much lower than at present. Consider,\nfor example, the use of speech recognition . as an aid to Air\nTraffic Control around Leeds-Bradford Airport. \nProblem 5\nTo use the language machine successfully, we\nneed to rethink how we approach tasks \nIf we simply try to add a language machine to an existing\nsystem, the fit may not be perfect. Using a speech\nrecogniser is a quite different process from typing into a\nword processor: people can speak much faster than they\ncan type; words will not be recognised and transcribed\ncorrectly, leaving the speaker to review and correct\nmistakes. The time taken to dictate a book could be longer\nthan the time taken to type it from scratch.\nWith the advent of word processors in the 1980s, typing\npools diminished as more white-collar workers did their\nown word-processing. Tyler (1998) suggests that to make","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":141,"topic":"Speech and Language Technology"}}
{"id":"1388c647-1bcd-43d6-808b-45fc8bc529fe","question":"According to the given context, can you identify the three applications of text classifiers in the field of Machine Learning?","reference_answer":"Machine Learning text classifiers are used for sentiment analysis, authorship identification, and spam detection.","reference_context":"Document 591: Multi -Word Expressions  \nestimates of sentence probabilities  \nlong distance dependencies  \n8. Question 8  \nAn IBk classifier test run results in the following confusion matrix:   \na b <\u2013 classified as  \n5 4 | a = yes  \n6 5 | b = no  \nWhat is the accuracy of this IBk classifier, to the nearest integer?  \nSelect one answer.  \n25%  \n50%  \n9% \n11%  \n9. Question 9  \nSelect three answers that complete the following statement correctly.  \nMachine Learning text classifiers are used for [BLANK].  \nstop -word removal  \nsentiment analysis  \nauthorship identification  \nspam detection","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":591,"topic":"Machine Learning and Text Processing"}}
{"id":"d48e86df-66eb-400d-981d-36842574ccbf","question":"Could you elaborate on the main function of the Leeds Internet Corpora website and how it contributes to the open source development of large corpora?","reference_answer":"The Leeds Internet Corpora website allows you to query the corpora in much the same way as Sketch Engine queries the corpora. It also provides information on open source development of large corpora.","reference_context":"Document 478: \u00a9 University of Leeds   7 of 8 OK, I think I've had a quick look at Sketch Engine and used it to collect corpus and extract some \nthings from the corpus. So let's go back to our Po werPoint presentation. So we've had a quick look \nat Sketch Engine. Let's have a look at Leeds Internet Corpora. I won't spend that much time on \nthis. \nBut here is the website, and you can query the corpora in much the same way as Sketch Engine \nqueries the corpora. And you can get a concordance out. And again, most of these things, these \nare things that Sketch Engine could do for you. The real reason for looking at this web page is it \nhas some information on open source development of large corpo ra. So if you want to collect a \nvery large corpus of, let's say, a billion words or half a billion words from the web, then you have to \ncollect not just two or three keywords.  \nYou typically want to have about 500 keywords. And the keywords should be not fo r your","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":478,"topic":"Others"}}
{"id":"9883ed08-3f26-47bb-9935-4aa6a689dfc8","question":"What are the primary factors that shape a standard user profile for a language machine, considering the user's resources and policy towards translation and languages?","reference_answer":"There is no typical user profile for language machine; the main determinants are an organisation's resources and its policy towards translation and languages.","reference_context":"Document 188: Is there a typical \u0090user profile\u0091?\nThe range and variety of potential uses of the language\nmachine are as broad as the uses of language itself: any\nand every aspect of language can be studied and modelled.\nOne way to survey the field is therefore to look at a\nselection of \u0090typical\u0091 past and current language machine\napplications.\nIndustrial interest in the language machine has tended to\nfocus on broad application categories; in a market survey\nfor IT managers, Johnson (1985) saw six main categories of\nuse (see box opposite). Language machine researchers, on\nthe other hand, have historically focused on their own\nacademic interests and perhaps have failed to\ncommunicate potential uses and benefits to people outside\nof the field. An EPSRC report tried to reallocate the blame:\nIn general, UK industry seemed to consider that too\nmuch effort had been spent in the past on \u0090esoteric\u0091\nacademic problems ... Another problem was the lack of\nawareness of the applicability of speech and language\n\nDocument 190: language processing systems (EAGLES, 1995) concluded\nthat there is no typical user profile; the main determinants\nare an organisation\u0091s resources and its policy towards\ntranslation and languages. In size, users range from inter-\nnational organisations like the United Nations, EU, and IBM,\ndown to individuals using any or all of the above categoriesReal-life\n44situations\nWho\u0091s using the\nlanguage machine\nnow? Which contexts\nand customers are\nlikely to benefit from\nthe next wave of\ncommercial\nproducts?\nThis section\nhighlights how\nspeech and languagetechnology is used in\ndiverse contexts\n\u0097 from helping\nchildren tell stories\nto conflict resolution.SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":188,"topic":"Language Technology Research and Development"}}
{"id":"414e9320-5c62-47ce-b15d-751c08357a2f","question":"Could you tell me the name of the work authored by Rychly in 2007?","reference_answer":"The title of the work by Rychly in 2007 is 'Manatee\/bonito\u2013a modular corpus manager.'","reference_context":"Document 570: Proc LREC , 1799\u20131802. Genoa, Italy.\nRenouf, A., A. Kehoe, and J. Banerjee. 2006. WebCorp: an integrated system for web text search.\nLanguage and Computers 59(1): 47\u201367.\nRundell, M. ed. 2002. Macmillan English Dictionary for Advanced Learners . Macmillan.\nRundell, M. 2012. Stop the presses\u2014the end of the printed dictionary. Macmillan Dictionary Blog, 5\nNov. http:\/\/www.macmillandictionaryblog.com\/bye-print-dictionary .\nRychly \u00b4, P. 2000. Korpusove \u00b4manaz \u02c7ery a ~ jejich efektivn\u0131 \u00b4implementace.Rychly \u00b4. PhD Thesis, Masaryk\nUniversity, Brno, Czech Republic.\nRychly \u00b4, P. 2007. Manatee\/bonito\u2013a modular corpus manager. In 1st Workshop on Recent Advances in\nSlavonic Natural Language Processing , 65\u201370. Masaryk University, Brno, Czech Republic.\nSanseido. 2003, 2007. The WISDOM English\u2013Japanese Dictionary. Sanseido.Scha\u00a8fer, R., and F. Bildhauer. 2013. Web corpus construction. Synthesis Lectures on Human Language\nTechnologies 6(4): 1\u2013145.\n\nDocument 571: Sanseido. 2003, 2007. The WISDOM English\u2013Japanese Dictionary. Sanseido.Scha\u00a8fer, R., and F. Bildhauer. 2013. Web corpus construction. Synthesis Lectures on Human Language\nTechnologies 6(4): 1\u2013145.\nScheible, S., R.J. Whitt, M. Durrell, and P. Bennett. 2011. A gold standard corpus of Early Modern\nGerman. In Proc 5th Linguistic Annotation Workshop , 124\u2013128. Association for computational\nlinguistics.\nSharoff, S. 2006. Creating general-purpose corpora using automated search engine queries. In WaCky!\nWorking papers on the Web as Corpus , eds. Baroni and Bernardini, 63\u201398. Bologna: Gedit.\nSrdanovic Erjavecs, I., Erjavec, T., and Kilgarriff, A. 2008. A web corpus and word sketches for\nJapanese. Information and Media Technologies , 3(3).\nSuchomel, V., and J. Pomika \u00b4lek. 2012. Ef\ufb01cient Web crawling for large text corpora. In Proc Seventh\nWeb as Corpus Workshop (WAC7) , 39\u201343. Lyon, France.\nThomas, J. 2014. Discovering English with the Sketch Engine.\nPrint-on-demand. http:\/\/ske.li\/deske .","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":570,"topic":"Corpus Linguistics and Lexicography"}}
{"id":"0d770ed0-54fd-4aa9-ad03-30f0b253d590","question":"Could you identify and describe the words represented in the thirteenth and fourteenth figures of Document 523?","reference_answer":"Figure 13 depicts the word 'y\u00fcrek' which means 'heart' in Turkish. Figure 14 depicts the Japanese word for 'accumulate'.","reference_context":"Document 523: Fig. 13 Word sketch for Turkish y\u00fcrek (heart)\nFig. 14 Word sketches for Japanese (accumulate)Lexicography ASIALEX (2014) 1:7\u201336 21\n123","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":523,"topic":"Corpus Linguistics Software"}}
{"id":"8c9aa8d9-6805-4d0c-89df-f29c5ccadf36","question":"Could you elaborate on the main functionalities of WebBootCaT and how it aids in creating a specialized corpus from the web?","reference_answer":"WebBootCaT is a special tool for creating a specialised corpus of your own choice from the web. Once you've got that, then you can use terminology extraction to extract words and multi-word terms which are characteristic of that corpus and therefore, probably specialist terms.","reference_context":"Document 480: queries. It takes combinations of these words, let's say four words from the list, and creates them \nas a query, sends them to the search engine, and back you  get. \nAnd here, we have some examples of the query sent out. There's topples of words. Then you \ndownload the URL produced by Google or whatever the search engine is. And here, we have the \nURLs, the web pages. You then have to -- what WebBootCaT then does is  it does some post -\nprocessing, extracts the text, and gets rid of the rubbish you don't really want.  \nAnd then finally, you get some outputs, and you get some frequency lists from those corpora, \nwhich you can then check to make sure that they really are sen sible. So what this page tells you is \nmore about how you go about using something like WebBootCaT to collect a billion word corpus \nrather than just a small sample corpus that you're looking at.  \nOK. Let's go back to page here. What've we got? Next thing I w ant to look at is the Special Interest\n\nDocument 457: another language, then you can line up a word and its translation in various examples. Then we're \ngoing to look at WebBootCaT, which is a special tool for creating a specialised corpus of your own \nchoice from the web. And once you've got that, then you  can use terminology extraction to extract \nwords and multi -word terms which are characteristic of that corpus and therefore, probably \nspecialist terms. And there's more stuff too.","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":480,"topic":"Corpus Linguistics Software"}}
{"id":"a7ccc90f-df27-447e-9f2a-c0d08c2bce5a","question":"In what ways can language machines be utilized to enhance accessibility and ease of use of technology for individuals with disabilities?","reference_answer":"Language machines can help disabled people to more easily access technology. For instance, the Royal National Institute for the Blind offers extensive information on speech synthesis packages and suppliers. The EU's ISEAUS project aims to use language engineering in speech education and rehabilitation for adults with lifelong or acquired deafness.","reference_context":"Document 236: to provide thought-provoking ideas.\u0091\nSimilarly, this book, The Language Machine , aims to\nprovide background information and fuel for ideas. How\nmight we develop the language machine? Can it be\nexploited for commercial benefit? What practical uses will it\nhave for people . whoever they are? Here we identify ways\nforward to continue the debate.leading the way\n56the next steps\nVerdicts on\nmachine translation\nSee page 37\n.Future development of language\nmachine technology must include\npeople who actively use the\nproducts for ordinary tasks \u0097 as\nhighlighted here by Derek Child,\nAssistant Director Equal Oppor-\ntunities, The Open University.\n\u0090For the visually impaired, indepen-\ndent access to information has\nalways been a barrier, and ICT\noffers the greatest liberation since\nBraille and audio-cassettes. But\ncompared to older text-based\nsystems, the visually-oriented\nGraphic User Interfaces can raise\nnew barriers.\nThe conventions set out by RNIB\nmight inform future software\n\nDocument 228: difficult to believe that its overall command of English will\nmatch (let alone exceed) that of an advanced learner of\nEnglish, even in 20 years\u0091 time. Translators and teachers \u0097\ncapable of judging social language, multiple meanings,\nnuance, subtle forms, and language complexities \u0097 do not\nneed therefore to fear they will be easily replaced!\nMore probably, machine translation will be used\nalongside good teaching and translation. It is used alreadyquestioning\n54the future\nThe digital\nhelping hand\nLanguage machines can help\ndisabled people to more easily\naccess technology: the following\nindicates some present activities.\nThe Royal National Institute for\nthe Blind (www.rnib.org.uk) offers\nextensive information on speech\nsynthesis packages and suppliers.\nThe EU\u0091s ISEAUS project aims to\nuse language engineering in\nspeech education and rehabil ita-\ntion for adults with lifelong or\nacquired deafness (see page 63).\nThe funding body EPSRC actively\nencourages researchers to work\n\nDocument 88: Machine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\nto plan and integrate the future use of language machines,\nwhether as a substitute for conventional human-to-human\ninteraction, or for the delivery of language teaching.the language machine\n17\n.Algorithms \u0087 Natural-language\nlearning \u0087 Hidden Markov Models\n\u0087 neural networks?\nSee Glossary, pages 58\u009759\nToo expensive\nto be useful? See page 28.English language teachers and\nlearners, according to a report on a\nsurvey of user requirements for\nthe ISLE project (ISLE, 1999)\ndesired, above all, a \u0090conversation\npractice machine\u0091 as an aid to\nlearning: with such a system a\nlearner could \u0090chat\u0091 in ordinary\nspoken English to practise every-\nday conversational language skills.\n.Natural-language learning\nsystems often use sophisticated\nstatistical pattern-matching models\n(for example Hidden Markov","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":236,"topic":"Language Machine Translation"}}
{"id":"bbc938a6-006f-4871-9028-19b70723cc72","question":"Could you explain the fundamental methodology that ELIZA, the chatbot, utilizes to simulate a conversation?","reference_answer":"ELIZA works by having a series or cascade of regular expression substitutions each of which matches and changes some part of the input lines. It uses pattern matching to recognize phrases and translate them into suitable outputs.","reference_context":"Document 376: bots like ELIZA (Weizenbaum, 1966). Recall that ELIZA simulates a Rogerian\npsychologist by carrying on conversations like the following:\nUser 1: Men are all alike.\nELIZA 1:IN WHAT WAY\nUser 2: They\u2019re always bugging us about something or other.\nELIZA 2:CAN YOU THINK OF A SPECIFIC EXAMPLE\nUser 3: Well, my boyfriend made me come here.\nELIZA 3:YOUR BOYFRIEND MADE YOU COME HERE\nUser 4: He says I\u2019m depressed much of the time.\nELIZA 4:I AM SORRY TO HEAR YOU ARE DEPRESSED\nELIZA works by having a series or cascade of regular expression substitutions\neach of which matches and changes some part of the input lines. Input lines are\n\nDocument 343: a Rogerian psychotherapist (Weizenbaum, 1966). ELIZA is a surprisingly simple\nprogram that uses pattern matching to recognize phrases like \u201cI need X\u201d and translate\nthem into suitable outputs like \u201cWhat would it mean to you if you got X?\u201d. This\nsimple technique succeeds in this domain because ELIZA doesn\u2019t actually need to\nknow anything to mimic a Rogerian psychotherapist. As Weizenbaum notes, this is\none of the few dialogue genres where listeners can act as if they know nothing of the\nworld. Eliza\u2019s mimicry of human conversation was remarkably successful: many\npeople who interacted with ELIZA came to believe that it really understood them\nand their problems, many continued to believe in ELIZA\u2019s abilities even after the\nprogram\u2019s operation was explained to them (Weizenbaum, 1976), and even today\nsuch chatbots are a fun diversion. chatbots\nOf course modern conversational agents are much more than a diversion; they","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":376,"topic":"Others"}}
{"id":"938f5471-946c-4b4b-a4d7-616b34274de0","question":"Can you identify the authors who have contributed to the creation of the scholarly article titled 'Unsupervised multilingual sentence boundary detection'?","reference_answer":"The authors of the paper 'Unsupervised multilingual sentence boundary detection' are T. Kiss and J. Strunk.","reference_context":"Document 449: Kiss, T. and J. Strunk. 2006. Unsupervised multilingual\nsentence boundary detection. Computational Linguistics ,\n32(4):485\u2013525.\nKleene, S. C. 1951. Representation of events in nerve nets\nand \ufb01nite automata. Technical Report RM-704, RAND\nCorporation. RAND Research Memorandum.Kleene, S. C. 1956. Representation of events in nerve nets\nand \ufb01nite automata. In Claude Shannon and John Mc-\nCarthy, editors, Automata Studies , pages 3\u201341. Princeton\nUniversity Press.\nKrovetz, R. 1993. Viewing morphology as an inference pro-\ncess. SIGIR-93 .\nKruskal, J. B. 1983. An overview of sequence compari-\nson. In David Sankoff and Joseph B. Kruskal, editors,\nTime Warps, String Edits, and Macromolecules: The The-\nory and Practice of Sequence Comparison , pages 1\u201344.\nAddison-Wesley.\nKudo, T. 2018. Subword regularization: Improving neural\nnetwork translation models with multiple subword candi-\ndates. ACL.\nKudo, T. and J. Richardson. 2018. SentencePiece: A simple","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":449,"topic":"Others"}}
{"id":"024f3f34-e3ce-42bc-846b-45cd3226ca20","question":"In his speech delivered at the 5th Annual CEO Summit on Converging Technologies, how did Peter Mandleson articulate his vision for the future of the UK in the digital realm?","reference_answer":"Peter Mandleson's vision for the UK was to make it Europe's digital laboratory. He wanted Britain to be the test bed for digital products and services in Europe, so that UK consumers have access to these first and that British business can lead the world.","reference_context":"Document 187: entertainment: for use by  artists and visitors to galleries, libraries and museums..\u0091My vision  for the UK is quite\nsimple: to be Europe\u0091s digital\nlaboratory. I want Britain to be the\ntest bed for digital products and\nservices in Europe, so that UK\nconsumers have access to these\nfirst and so that British business\ncan lead the world.\u0091\nPeter Mandleson, speaking as\nSecretary of State for Trade and\nIndustry, at 5th Annual CEO\nSummit on Converging\nTechnologies, September 1998SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":187,"topic":"Others"}}
{"id":"c5f13110-3138-4960-b985-ab94c114f670","question":"Could you explain the methodology used by the Stanford CoreNLP toolkit for sentence tokenization, especially regarding the role of punctuation and abbreviations?","reference_answer":"In the Stanford CoreNLP toolkit, sentence splitting is rule-based, a deterministic consequence of tokenization; a sentence ends when a sentence-ending punctuation (., !, or ?) is not already grouped with other characters into a token (such as for an abbreviation or number), optionally followed by additional final quotes or brackets.","reference_context":"Document 420: 2.5 \u2022 M INIMUM EDITDISTANCE 21\n2.4.5 Sentence Segmentation\nSentence segmentation is another important step in text processing. The most use-sentence\nsegmentation\nful cues for segmenting a text into sentences are punctuation, like periods, question\nmarks, and exclamation points. Question marks and exclamation points are rela-\ntively unambiguous markers of sentence boundaries. Periods, on the other hand, are\nmore ambiguous. The period character \u201c.\u201d is ambiguous between a sentence bound-\nary marker and a marker of abbreviations like Mr.orInc.The previous sentence that\nyou just read showed an even more complex case of this ambiguity, in which the \ufb01nal\nperiod of Inc. marked both an abbreviation and the sentence boundary marker. For\nthis reason, sentence tokenization and word tokenization may be addressed jointly.\nIn general, sentence tokenization methods work by \ufb01rst deciding (based on rules\nor machine learning) whether a period is part of the word or is a sentence-boundary\n\nDocument 421: In general, sentence tokenization methods work by \ufb01rst deciding (based on rules\nor machine learning) whether a period is part of the word or is a sentence-boundary\nmarker. An abbreviation dictionary can help determine whether the period is part\nof a commonly used abbreviation; the dictionaries can be hand-built or machine-\nlearned (Kiss and Strunk, 2006), as can the \ufb01nal sentence splitter. In the Stanford\nCoreNLP toolkit (Manning et al., 2014), for example sentence splitting is rule-based,\na deterministic consequence of tokenization; a sentence ends when a sentence-ending\npunctuation (., !, or ?) is not already grouped with other characters into a token (such\nas for an abbreviation or number), optionally followed by additional \ufb01nal quotes or\nbrackets.\n2.5 Minimum Edit Distance\nMuch of natural language processing is concerned with measuring how similar two\nstrings are. For example in spelling correction, the user typed some erroneous","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":420,"topic":"Others"}}
{"id":"a0db6dc2-93dd-4560-9f97-4962a7455ad4","question":"Can you elaborate on the significance of language in the domain of telematics and how it is utilized in the creation of telematics systems?","reference_answer":"In the field of telematics, language engineering is concerned with building speech and language processing resources, and components for integration into telematics systems.","reference_context":"Document 76: computer interaction, and multimedia \u0097 as a sub-field of\ncomputer science. Speech and language technology is a\npotentially powerful way to give us \u0090natural\u0091 communi-\ncation with computers, and to facilitate various types of\n\u0090computer-mediated\u0091 communication between people.\nLanguage is also important in related fields, for example\nof telecommunications, or \u0090telematics\u0091 \u0097 a term conceived\nby European Union (EU) research funding agencies \u0097 within\nwhich language engineering is concerned with building\nspeech and language processing resources, and\ncomponents for integration into telematics systems.\nWhere languages meet computer science\nSpeech and language technology has a number of differentnames and perspectives. No single academic viewpoint is\nmore \u0090valid\u0091: there are at least as many language\nresearchers in computing as in linguistics departments.\nSpeech and language technology researchers additionally\nspan a wide range of related fields; at the University of\n\nDocument 75: An academic heritage\nThe history of research within various academic disciplines\ninto speech and language technology is a long one. Within\nuniversity linguistics departments, for example, compu-\ntational linguistics is a growing sub-field. Some linguists\nuse computers \u0097 in either research or teaching \u0097 as\npowerful tools for analysing or modelling aspects of\nlanguage. The grammar of English, for example, can be\nmodelled by a set of formal rules; used by a computer\nprogram to generate new sentences or parse a corpus of\ntest sentences. This application is comparable to\ngeneticists\u0091 use of computer models of gene-sequences or\ngeographers\u0091 use of computer maps and databases. \nIn a computer science department, natural language pro-\ncessing is seen \u0097 similarly to Artificial Intelligence, human-\ncomputer interaction, and multimedia \u0097 as a sub-field of\ncomputer science. Speech and language technology is a\npotentially powerful way to give us \u0090natural\u0091 communi-\n\nDocument 77: researchers in computing as in linguistics departments.\nSpeech and language technology researchers additionally\nspan a wide range of related fields; at the University of\nLeeds, for example, the Centre for Computer Analysis of\nLanguage And Speech (CCALAS) has had members\nworking in fields as diverse as Artificial Intelligence,\ncommunication studies, computer-based learning, com-\nputer studies, education, English, electrical engineering,Research labs\n14to desk-tops\nWhat stage of\ndevelopment has the\nlanguage machine\nreached?\nHow long before a\nlanguage machine is\nbundled with your\ndesk-top PC?SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":76,"topic":"Language Machine Technology"}}
{"id":"7e9ccc64-58da-4c81-b707-77fb6a0266ba","question":"Can you define what is meant by a 'controlled language', particularly in contexts where accuracy and rapid response are critical, such as in emergency services or air traffic control?","reference_answer":"A controlled language is a language designed to make language processing easier by restricting the number of words and structure of language used; it's commonly used in areas where precision and speed of response is critical, such as the emergency services or air traffic control.","reference_context":"Document 243: CALL \u0097 Computer Assisted Language Learning. Software that presents\nactivities designed to help language learners. Many of the activities arebased on conventional approaches, such as cloze.\ncomputational linguistics  \u0097 an area of applied linguistics concerned with the\nprocessing of natural language by computers.\ncontrolled language  \u0097 language designed to to make language processing\neasier by restricting the number of words and structure of languageused; commonly used in areas where precision and speed of response iscritical, such as the emergency services or air traffic control.\ncorpora \u0097 a corpus is a body of language, either text or speech, used as a\nbasis for analysing language to establish its characteristics. As well asnational corpora of hundreds of millions of words, corpora are alsoconstructed for particular purposes, such as recordings of car driversspeaking to simulated voice-activated control systems to help establishtheir marketability.","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":243,"topic":"Others"}}
{"id":"19026586-d0f5-4314-9aef-3d4771b91673","question":"Could you provide an explanation on how lemmatization and stemming differ in the context of text normalization?","reference_answer":"Lemmatization is the task of determining that two words have the same root, despite their surface differences. For example, the words sang, sung, and sings are forms of the verb sing. The word sing is the common lemma of these words, and a lemmatizer maps from all of these to sing. Stemming refers to a simpler version of lemmatization in which we mainly just strip suffixes from the end of the word.","reference_context":"Document 413: we segment each test sentence word into characters. Then we apply the \ufb01rst rule:\nreplace every instance of e r in the test corpus with er, and then the second rule:\nreplace every instance of er in the test corpus with er, and so on. By the end,\nif the test corpus contained the word n e w e r , it would be tokenized as a full\nword. But a new (unknown) word like l o w e r would be merged into the two\ntokenslower .\nOf course in real algorithms BPE is run with many thousands of merges on a very\nlarge input corpus. The result is that most words will be represented as full symbols,\nand only the very rare words (and unknown words) will have to be represented by\ntheir parts.\n2.4.4 Word Normalization, Lemmatization and Stemming\nWord normalization is the task of putting words\/tokens in a standard format, choos- normalization\ning a single normal form for words with multiple forms like USAandUSoruh-huh\nanduhhuh . This standardization may be valuable, despite the spelling information\n\nDocument 346: 2CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\nSome languages, like Japanese, don\u2019t have spaces between words, so word tokeniza-\ntion becomes more dif\ufb01cult.\nAnother part of text normalization is lemmatization , the task of determining lemmatization\nthat two words have the same root, despite their surface differences. For example,\nthe words sang ,sung , and sings are forms of the verb sing. The word sing is the\ncommon lemma of these words, and a lemmatizer maps from all of these to sing.\nLemmatization is essential for processing morphologically complex languages like\nArabic. Stemming refers to a simpler version of lemmatization in which we mainly stemming\njust strip suf\ufb01xes from the end of the word. Text normalization also includes sen-\ntence segmentation : breaking up a text into individual sentences, using cues likesentence\nsegmentation\nperiods or exclamation points.\nFinally, we\u2019ll need to compare words and other strings. We\u2019ll introduce a metric","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":413,"topic":"Text Normalization and Tokenization"}}
{"id":"b958d734-43e4-4b29-8655-b82cae5534eb","question":"Could you explain the procedure involved in preparing a webpage for the purpose of data mining, specifically focusing on the text content?","reference_answer":"The process involves discarding images, tables, and what is referred to as boilerplate. This includes headings, contact details, ownership details, and links to related web pages. The focus is on the text which is relevant to data mining.","reference_context":"Document 473: web page the text. It's throwing away the images, tables, and what we call boilerplate. That is, on \na web page, there's usually some sort heading at the beginning and some sort of -- at the bottom \nsomewhere it will say how to contact the web owner, who owns the web page, links to other \nrelated web pages, stuff like that we don't really want.  \nWhat we want is the text which we hope will be about data mining. So it's taking  some time to get \nrid of all this. And you'll find that if you have quite a few search terms or lots of web pages, this bit \nmay take a while. But I've only done a simple example. So we've done that. You can say get to","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":473,"topic":"Corpus Linguistics and Data Mining"}}
{"id":"14ff3a94-0b48-49f7-8f33-ba76f859293e","question":"What are the two anticipated future scenarios for the progression of personal computing and language machine technologies in the coming two decades, as per the predictions?","reference_answer":"Scenario 1 predicts that IT and language machines will be all-pervasive, with personal computing becoming as everyday as wristwatches and telephones. It suggests that the language machine will be a core component in this new technology, replacing traditional keyboard and screen-display with speech input\/output. Scenario 2 predicts that the language machine will improve significantly, with falling error-rates making it more acceptable to users. It suggests that the technology can only get better, posing interesting questions for the upcoming generation of computer users.","reference_context":"Document 212: new technology: wristwatch or telephone computing will\nnot be able to rely on keyboard input and screen-display\noutput, and speech input\/output seems the most likely\nreplacement. Today\u0091s students may each have their own\nwristwatches; in ten or 20 years\u0091 time, they may carry their\npersonal computing around with them as an everyday tool\nor fashion accessory. Software for this consumer market\nwill be made available: prime suppliers may be the\nlanguage teaching business alongside IT industries. \nScenario 2\nThe language machine will get better \nAt the moment, it is easy to ridicule the language machineby showing examples of its fallibility. Most applications\nhave a threshold of acceptability: a system that makes too\nmany mistakes will not be used, although users will put up\nwith it if the error-rate is low enough. Many computer-\nliterate professionals have learnt to touch-type at speeds of\n100 words per minute or more; speech recognition software\n\nDocument 211: The next 20 years \nOver the next 20 years, we can assume that the drawbacks\nof speech and language technology are likely to be\novercome or surmounted, allowing the language machine\nto make a more significant impact. Bearing in mind the\ndifficulty inherent in predicting future technological\ndevelopment and adoption, this section explores a number\nof possible future scenarios.\nScenario 1\nIT and language machines will be all-pervasive \nIT industry futurologists . agree that personal computing\ntechnology will continue to drop in price and increase in\npower, making it accessible to an ever-widening comm-\nunity. Personal computing will become as everyday as\nwristwatches and telephones; indeed, it will be integrated\ninto wristwatches and telephones.\nThe language machine will be a core component in this\nnew technology: wristwatch or telephone computing will\nnot be able to rely on keyboard input and screen-display\noutput, and speech input\/output seems the most likely\n\nDocument 214: noisy environments such as open-plan offices. On the other\nhand, many computer users struggle by typing with two or\nfour fingers, risking repetitive strain injuries. As speech-\nrecogniser error-rates fall, there will inevitably come a time\nwhen personal thresholds of acceptability will be reached\nfor language machines. \nAnd indeed, the technology can only get better: personal\ncomputing software generally, and language machine\ntechnology in particular, has improved beyond recognition\nover the past decade, and there is no reason to suspect any\nimminent slow-down in this rate of development. This\nposes interesting questions for those currently teaching the\nupcoming generation of computer users. Should parents\nbuy their children a typing tutor program? Or can they\nassume that they will simply talk to their PC in the future?\nScenario 3\nCustomised language machines will be used by\nindividuals for particular tasks \nOne contemporary problem is already being addressed:","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":212,"topic":"Speech Recognition Technology"}}
{"id":"d9835b90-c238-4041-a28d-b3e5e9f03423","question":"If we consider 'San Francisco' as a single word, how many tokens would be present in the phrase 'they lay back on the San Francisco grass and looked at the stars and there'?","reference_answer":"There are 14 tokens.","reference_context":"Document 312: So we might say, the word the appears twice here. A more formal way of saying this is, there are \nthe type the appears as two tokens in this example. So how many words are there? Well there's, \nthey lay back on the San Francisco grass and looked at the stars and there.  \nThat's 15 tokens.  Or we might say San Francisco is really one word, in which case there's 14 \ntokens. But then how do you decide what a word is? Well because there's a space in there, well","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":312,"topic":"Text Analysis and Tokenization"}}
{"id":"3620a2b5-5bc8-484d-ab90-cd85523f854a","question":"According to the method proposed by Jakub\u0131 \u00b4c\u02c7ek et al. in 2013, what are the necessary components and human collaboration required to qualify a resource as high-level?","reference_answer":"The prerequisites for a high-level resource are a tokeniser, a lemmatiser, a part-of-speech tagger, a parser or 'sketch grammar', and a collaborator who speaks the language and ideally is a computational linguist.","reference_context":"Document 515: (Jakub\u0131 \u00b4c\u02c7ek et al. 2013 ) method.\nFor a high-level resource, further prerequisites are\n\u25cfa tokeniser (for Chinese and Japanese, usually called a segmenter) to identify thewords. In simple cases this might just use spaces between words but manylanguages have clitics and similar needing language-speci\ufb01c treatment. Englishis a very simple language in this regard but even there, the hyphen and\napostrophe characters, and mixtures of letters and non-letters, present\nchallenges.\n\u25cfa lemmatiser13\n\u25cfa part-of-speech tagger\n\u25cfa parser or \u2018sketch grammar\u2019.\nWhat is also required is a collaborator. This is a person who speaks the language,\n\nDocument 516: challenges.\n\u25cfa lemmatiser13\n\u25cfa part-of-speech tagger\n\u25cfa parser or \u2018sketch grammar\u2019.\nWhat is also required is a collaborator. This is a person who speaks the language,\nand is ideally a computational linguist, and who cares about the quality of theoutput. They might care because they want to use the corpus in their own (or theirgroup\u2019s) work, or because they developed some of the tools and this is anopportunity to thoroughly test them and to show them (via data processed by them)to the world. The collaboration is crucial: without input from people who speak thelanguage, the Sketch Engine team does not know if what it has done for a language\nis good. A collaborator is needed to point out mistakes and problems, which can\nthen be addressed.\nIn the following sections we provide details about the status of Sketch Engine\nintegration of various Asian languages.\n4.1 Chinese\nThe collaboration for Chinese began with Prof Huang Chu-Ren inviting the \ufb01rst","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":515,"topic":"Corpus Linguistics Software"}}
{"id":"dad228cd-b086-441d-90d9-f6c4764cc378","question":"Could you describe the contributions of EUROMAP, EUROMAP II, and LINGLINK towards promoting the adoption and awareness of language engineering applications among smaller organizations and end-users in Europe?","reference_answer":"EUROMAP and LINGLINK aim to develop general language resources and infrastructure, support and promote the take-up of language engineering, raise awareness of markets, customer needs, standards and potential uses, and help bring the technology to markets and users.","reference_context":"Document 181: How are people encouraged to buy?\nMuch of the work now being completed in speech andlanguage projects across Europe emerges as products for\nlarge organisations \u0097 pan-European administrations, trans-\nnational commercial organisations, or security and law\nenforcement agencies working across borders \u0097 but what\ncan encourage the smaller organisation to invest . in\nspeech and language technology?\nElsewhere in this book issues are raised \u0097 of cost; scale;\ntraining; dialogue between end-user and researcher \u0097 but\none key ingredient in bringing a product to market is that of\ninformation .\nSeveral projects now aim to develop general language\nresources and infrastructure, to support and promote the\ntake-up of language engineering, and to raise awareness of\nmarkets, customer needs, standards and potential uses:\nEUROMAP . (European Opportunity Mapping),\nEUROMAP II, and LINGLINK (Promotion and Support for\nLanguage Engineering in Europe) are surveying and\n\nDocument 182: markets, customer needs, standards and potential uses:\nEUROMAP . (European Opportunity Mapping),\nEUROMAP II, and LINGLINK (Promotion and Support for\nLanguage Engineering in Europe) are surveying and\npromoting language engineering applications, helping to\nbring the technology to markets and users.\nEAGLES (Expert Advisory Group on Languagesupply & demand\n42the markets\n.The EUROMAP project\n(European Opportunity Mapping)\nhas reported on a thriving\nEuropean research and\ndevelopment community in speech\nand language technology: \u0090A total\nof some 10,000 language\ntechnology players in Europe had\nbeen identified, including research\nstaff, vendors, and professional\nand corporate users, of which\n7,000 can be assumed to be\ndealing with core language tech-\nnology issues. Of these, more than\n1,000 research sites, academic and\ncommercial, were contacted, and\naround 300 provided information to\nthe survey.\u0091 (EUROMAP\nWeb site, 1999).Who supplies  speech and\nlanguage systems? Niche suppliers","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":181,"topic":"European Language Technology Projects"}}
{"id":"a7901958-7253-4803-a0df-86a109a5c14c","question":"Could you clarify which sections of the research proposal report are given a triple weight in grading and what is the maximum achievable score for the entire report?","reference_answer":"The total mark for the research proposal report is up to 60 marks. The sections on Programme and methodology, including workplan diagram, and Appendix: use of data mining and text analytics tools in developing your Report are most important and are triple-weighted, getting marks in the range of 0-18.","reference_context":"Document 586: In your research proposal report, we will assess: Background (0-6 marks) Contribution to knowledge (0-6 marks) Importance (0-6 marks) Research hypothesis and objectives (0-6 marks) Programme and methodology, including workplan diagram (0-18 marks) Appendix: use of data mining and text analytics tools in developing your Report (0-18 marks) TOTAL: up to 60 marks\n\nDocument 582: and methodology, and Appendix: these are most important, and are triple-weighted, so get mark in range 0-18.  In your research proposal report, we will assess:  Background (0-6 marks) Contribution to knowledge (0-6 marks) Importance (0-6 marks) Research hypothesis and objectives (0-6 marks) Programme and methodology, including workplan diagram (0-18 marks) Appendix: use of data mining and text analytics tools in developing your Report (0-18 marks) TOTAL: up to 60 marks  Return of marks and feedback will be via Minerva grade center, approximately 3 weeks after submission.\n\nDocument 581: two data mining and\/or text analytics methods, tools or techniques introduced in the module (eg SketchEngine, Weka, ChatGPT) 1-page workplan diagram must match the written description of the research work programme, showing start, end and duration of each phase or work-package.   EPSRC Evaluation Criteria: When a research project proposal is submitted to EPSRC, they check it meets the requirements, then send the proposal to several independent experts for Peer Review. These peer reviewers then give written feedback on strengths and weaknesses of the proposal, and marks or scores in the range 0-6.   4. Assessment criteria and marking process The mark scheme for your report will reflect the EPSRC grading scheme with marks in the range 0-6 for each criterion, EXCEPT the sections on Programme and methodology, and Appendix: these are most important, and are triple-weighted, so get mark in range 0-18.  In your research proposal report, we will assess:  Background (0-6 marks) Contribution to","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":586,"topic":"Academic Research Proposal Guidance"}}
{"id":"ec2ef30e-70ba-4ea1-84d4-f2b6cebd043e","question":"Despite the advancements and availability of machine translation technologies, what factors might motivate individuals to persist in their efforts to learn English?","reference_answer":"Many people will want access to the rich 'cultural resources' of English, and hence prefer to learn English for personal and cultural fulfilment even though machine translation is available. They may choose not to read translated works of literature, believing that translation compromises the integrity of the original text.","reference_context":"Document 235: many customers will continue to equate care and service\nwith social interaction, as will businesses who use human\ninteraction as a selling feature of quality customer care.\nLanguage is used for gate-keeping  Latin was once a\nrequirement for access to particular institutions or courses\n\u0097 veterinary science degree courses for example \u0097 demon-\nstrating how proficiency in English (and indeed any\nlanguage) can be used by educational systems and\nemployers as a criteria for access to better prospects, even\nwhen individuals don\u0091t need the language itself for routine\nprofessional purposes. This is likely to continue in various\nsubtle ways: it may even be that access to such technology\nbecomes a new means of discrimination.\nWays ahead\nAn earlier book arising from the British Council English2000 project, The Future of English?  (Graddol, 1997) \u0090aims\nto provide thought-provoking ideas.\u0091\nSimilarly, this book, The Language Machine , aims to\nprovide background information and fuel for ideas. How\n\nDocument 234: quality, human-centred language industry.\nLanguage offers cultural resources  It is very possible that\nthere will remain some aspects of language use and\nmultilingualism where the intervention of the language\nmachine will be viewed as inappropriate or intrusive. Many\npeople will want access, for example, to the rich \u0090cultural\nresources\u0091 of English, and hence prefer to learn English for\npersonal and cultural fulfilment even though machine\ntranslation is available. Although they would not consider it\nan issue for technical or trade documents, they may choose\nnot to read translated works of literature, believing that\ntranslation compromises the integrity of the original text. \nNot only art and culture may lie beyond the reach of the\nlanguage machine: quality is a watchword in business, and\nmany customers will continue to equate care and service\nwith social interaction, as will businesses who use human\ninteraction as a selling feature of quality customer care.","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":235,"topic":"Language Machine Translation"}}
{"id":"995d9ec5-d941-4a6b-9397-372fda166637","question":"Which operator is used in pattern matching to represent a negative lookahead assertion, thereby ruling out a specific case?","reference_answer":"The operator for negative lookahead in pattern matching is (?! pattern).","reference_context":"Document 378: text to see if some pattern matches, but not advance the match cursor, so that we can\nthen deal with the pattern if it occurs.\nThese lookahead assertions make use of the (?syntax that we saw in the previ- lookahead\nous section for non-capture groups. The operator (?= pattern) is true ifpattern\noccurs, but is zero-width , i.e. the match pointer doesn\u2019t advance. The operator zero-width\n(?! pattern) only returns true if a pattern does not match, but again is zero-width\nand doesn\u2019t advance the cursor. Negative lookahead is commonly used when we\nare parsing some complex pattern but want to rule out a special case. For example\nsuppose we want to match, at the beginning of a line, any single word that doesn\u2019t\nstart with \u201cV olcano\u201d. We can use negative lookahead to do this:\n\/\u02c6(?!Volcano)[A-Za-z]+\/\n2.2 Words\nBefore we talk about processing words, we need to decide what counts as a word.\nLet\u2019s start by looking at one particular corpus (plural corpora ), a computer-readable corpus","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":378,"topic":"Regular Expressions"}}
{"id":"2dd3d375-27c2-4ecd-a482-ce73d24e2890","question":"Could you elaborate on the linguistic phenomenon known as code switching, particularly how it involves the use of multiple languages in a single act of communication?","reference_answer":"Code switching is a phenomenon where speakers or writers use multiple languages in a single communicative act. It is enormously common across the world.","reference_context":"Document 388: to MAE talking about , both examples that in\ufb02uence word segmentation (Blodgett\net al. 2016, Jones 2015).\nIt\u2019s also quite common for speakers or writers to use multiple languages in a\nsingle communicative act, a phenomenon called code switching . Code switching code switching\nis enormously common across the world; here are examples showing Spanish and\n(transliterated) Hindi code switching with English (Solorio et al. 2014, Jurgens et al.\n2017):\n(2.2) Por primera vez veo a @username actually being hateful! it was beautiful:)\n[For the \ufb01rst time I get to see @username actually being hateful! it was\nbeautiful:) ]\n(2.3) dost tha or ra- hega ... dont wory ... but dherya rakhe\n[\u201che was and will remain a friend ... don\u2019t worry ... but have faith\u201d]\nAnother dimension of variation is the genre. The text that our algorithms must\nprocess might come from newswire, \ufb01ction or non-\ufb01ction books, scienti\ufb01c articles,\nWikipedia, or religious texts. It might come from spoken genres like telephone","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":388,"topic":"Machine Learning and Text Processing"}}
{"id":"9138c50b-bdba-439d-8df9-e862df725f5d","question":"Could you describe what an Ngram signifies within the realm of text data research and how it is applied?","reference_answer":"An Ngram is a sequence of N words. For example, a unigram, or one gram is just one word. A bigram is two words. A trigram is three words. A four gram is a sequence of four words, and so on. They are collected from sequences of one, two, three, four, or five, words which come together, which are found in a text.","reference_context":"Document 318: different people, and therefore it was more varied, because there are more different sources \naround.  \nJust by way of contrast, Google has access to the entire world wide web. So they have a huge \namount of text data. That's why if you want to do research on text, it's a good idea to go and work \nfor Google research labs. They actually collected the whole of the web and from it, extracted all \nthe Ngrams.  \nAn Ngram is a sequence of N words. So unigram, or one gram is just one wor d. A bigram is two \nwords. A trigram is three words. A four gram is a sequence of four words, and they did it up to five \ngrams.  \nSo they collected all the sequences of one, two, three, four, or five, words which came together, \nwhich were found. And this whole corpus is based on a trillion that a trillion different Ngrams that \nappeared on the web, but there are only 13 million differ ent ones. So there we see Heaps Law at \nmaximum.","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":318,"topic":"Corpus Linguistics Software"}}
{"id":"2745a3fd-9b65-49fd-b8ea-97dea71f10c3","question":"According to the document titled 'the language machine', what skill is predicted to be indispensable for any kind of job?","reference_answer":"Information technology literacy is anticipated to be essential for any employment.","reference_context":"Document 72: the language machine\n13\n1997\n19982000200220032004200520072012201820252030wristwatch telephone\nmachine recognition of body language and gesturesautomatic text summarisation and abstracts \nwrist computer and\/or PC Card wallet computer\nnatural language home information retrieval and\ninteraction\nelectronic newspaper\nhand videophone visual computer personalities on screens\none-chip, multi-speaker voice recognition\ninformation technology literacy essential for any\nemployment \nreal time language translation for print and voice \nvoice synthesis quality to human standard\nfull voice-interaction with machine \nprocessing vague information by \u0090common-senseinference\u0091\ndomestic robots: small, specialised attractive\nportable translation device for simple conversation\nsystems to understand text and drawings (e.g.patent information)\nrobots for almost any job in home or hospital\nArtificial Intelligence technology, imitating the\nthinking processes of the brain\nthought recognition as everyday input means","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":72,"topic":"Others"}}
{"id":"e1e598ca-84e1-452b-81ca-4369837d8ccc","question":"Can you specify the total count of words that were gathered in the corpus collection?","reference_answer":"The size of the corpus collected is about 25,000 words.","reference_context":"Document 474: \u00a9 University of Leeds   6 of 8 know your corpus in various ways. Turn  that off. Sorry about that. OK. Let's go to the corpus \ndetails and statistics.  \nWell, we've collected 29,000 tokens or 24,000 words. Was a subtle difference between tokens and \nwords. We saw this in a previous lecture. So this is not a very big corpus, abou t 25,000 words. Not \nhuge. But it will do to start off with. OK, we can go to Manage Corpus if you want to do some more \nstuff. We can make it bigger. We can do various other things with it.  \nAnd the other thing, going back to the dashboard, this is the dashboard for the data mining corpus \nwe've got. Well, what we want it to do is get out some terminology, some key words from this \ncorpus. So the key words extraction, well, again, you can just press the Go button and it will take a \nwhile.  \nBut that's becaus e what it does is it compares your corpus against some standard or reference","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":474,"topic":"Corpus Linguistics Software"}}
{"id":"315d9caa-65e7-4a98-af3a-454484e10709","question":"Could you elaborate on the variety of tasks that a machine equipped with language capabilities can execute?","reference_answer":"A language machine can transcribe accurately what we have said (speech recognition), understand the basic content of what we have said so they can respond appropriately (speech understanding), translate words automatically from one language to another (machine translation), produce a draft of our words in another language for subsequent refinement (machine-assisted translation), read out loud screen-based text such as email, Web pages or word-processed documents (speech synthesis), search through databases of multilingual documents, issue commands to intelligent devices using only our voices, give feedback on the correctness of pronunciation or the appropriateness of lexical choices and grammar style, and be used interactively in the teaching of languages.","reference_context":"Document 54: several languages (machine translation);\n* produce a draft of our words in another language for\nsubsequent refinement (machine-assisted translation);\n* read out loud screen-based text such as email, Web\npages or word-processed documents (speech synthesis);\n* search through databases of multilingual documents\nwithout needing the ability to speak, type or read all of\nthe languages involved;\n* issue commands to \u0090intelligent devices\u0091 \u0097 such as a car\nradio or a mobile phone \u0097 using only our voices;\n* speak to a computer and get feedback on the\n\u0090correctness\u0091 of pronunciation or the appropriateness of\nlexical choices and grammar style;\n* use computers interactively in the teaching of languages.\nAt the heart of each of these lies a model of language that\nunderstands not simply the vocabulary of one or more\nlanguages, but also grammar, syntax  and semantics . \nA language machine is therefore a computer that is\ncapable, in one way or another, of extracting and acting on\n\nDocument 55: languages, but also grammar, syntax  and semantics . \nA language machine is therefore a computer that is\ncapable, in one way or another, of extracting and acting on\nthe meaning of words.describing words\n8the technology\nIs it a language\nmachine?\nTo be called a language machine,\na language model must lie at the\nheart of a computer system,\nenabling natural language to be\nunderstood and processed in an\nintelligent way. The essential\ncomponents of a language\nmachine are outlined on page 20.\nPerhaps predictably, jargon and\nacronyms litter the field, making it\ndifficult for newcomers to find\ntheir way. To help, a glossary is\nincluded on pages 58\u009759, and for\nmore information, Web and book\nreferences are given on pages\n60\u009763.Imaginative ideas\nfrom the LinglinkReport to the EU\nSee page 7SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 53: What makes a language machine?\nThe term language machine is used throughout this book,\nbut it is really an umbrella term for several developments in\ncomputer technology. Such developments will provide us\nwith opportunities to carry out familiar tasks in new ways.\nFor example, we will be able to do the following:\n* talk to machines and have them transcribe accurately\nwhat we have said (speech recognition);\n* talk to machines and have them understand the basic\ncontent of what we have said, so they can respond\nappropriately to a question about information that they\ncontain, or to which they can provide access (speech\nunderstanding);\n* use machines that translate words automatically from\none language to another (whether we input words by\nspeech, handwriting, by scanning text or using a\nkeyboard), or use machines to translate our words to\nseveral languages (machine translation);\n* produce a draft of our words in another language for\nsubsequent refinement (machine-assisted translation);\n\nDocument 90: Why create language machines?\nSpeech and language technology researchers, like\npractitioners in many scientific disciplines, can find it\ndifficult to agree on a simple, comprehensive definition of\ntheir discipline and its boundaries. It is, however, possible\nto outline some of the objectives and interests that\nlanguage machine researchers have in common:\nCreating computer models of language  One common core\naim is to build computer models of human language and\nspeech, such as models of grammar, vocabulary, speech\nproduction and recognition, and language learning.\nComputer models do not have to use graphics to \u0090visualise\u0091\naspects of language: they can be conceptual as well as\nvisual. A set of formalised grammar rules defining the\nphrase-structure of part of the English language constitutes\na \u0090model\u0091. Such models have applications in several\ndisciplines and research areas.\nBuilding computerised language resources Researchers\ngenerally make use of computerised language resources in","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":54,"topic":"Artificial Intelligence in Language Learning"}}
{"id":"b6a5347e-7821-45f6-8af4-750920dc41d4","question":"Can you elaborate on the functionality of the WebBootCaT tool and how it aids in creating a specialized corpus from the web?","reference_answer":"WebBootCaT is a special tool for creating a specialised corpus of your own choice from the web. It can be used for terminology extraction to extract words and multi-word terms which are characteristic of that corpus.","reference_context":"Document 457: another language, then you can line up a word and its translation in various examples. Then we're \ngoing to look at WebBootCaT, which is a special tool for creating a specialised corpus of your own \nchoice from the web. And once you've got that, then you  can use terminology extraction to extract \nwords and multi -word terms which are characteristic of that corpus and therefore, probably \nspecialist terms. And there's more stuff too.\n\nDocument 480: queries. It takes combinations of these words, let's say four words from the list, and creates them \nas a query, sends them to the search engine, and back you  get. \nAnd here, we have some examples of the query sent out. There's topples of words. Then you \ndownload the URL produced by Google or whatever the search engine is. And here, we have the \nURLs, the web pages. You then have to -- what WebBootCaT then does is  it does some post -\nprocessing, extracts the text, and gets rid of the rubbish you don't really want.  \nAnd then finally, you get some outputs, and you get some frequency lists from those corpora, \nwhich you can then check to make sure that they really are sen sible. So what this page tells you is \nmore about how you go about using something like WebBootCaT to collect a billion word corpus \nrather than just a small sample corpus that you're looking at.  \nOK. Let's go back to page here. What've we got? Next thing I w ant to look at is the Special Interest\n\nDocument 483: you've introduced Sketch Engine as a web tool for corpus linguistics. You've been introduced to \nWebBootCaT within Sketch engine as a way of collecting a corpus from the web. You can use it \nyourself to collect your own corpus  and then to extract a list of terminology from that corpus.  \nMainly the multi -word expressions are the important ones for your domain. You can look at Leeds \ninternet corpora if you ever want to collect a billion word corpus, and this gives you more \ninforma tion about how to go about collecting seed words for this and then using those. Or if you \nwant to do some research in a particular area, then look at the ACL Special Interest Group for that \narea. You should have read or be reading or about to read Adam Kil garriff's paper on the search \nengine because it's got more examples in it. And look at the websites.  \n \n[END]","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":457,"topic":"Corpus Linguistics Software"}}
{"id":"31364f2b-7e8c-4b73-847d-ffa4696e58fb","question":"In the realm of regular expressions, how is the term 'word' defined and what characters does it encompass?","reference_answer":"A 'word' for the purposes of a regular expression is defined as any sequence of digits, underscores, or letters; this is based on the definition of 'words' in programming languages.","reference_context":"Document 360: a non-boundary. Thus, \/\\bthe\\b\/ matches the word thebut not the word other .\nMore technically, a \u201cword\u201d for the purposes of a regular expression is de\ufb01ned as any\nsequence of digits, underscores, or letters; this is based on the de\ufb01nition of \u201cwords\u201d\nin programming languages. For example, \/\\b99\\b\/ will match the string 99in\nThere are 99 bottles of beer on the wall (because 99 follows a space) but not 99in\nThere are 299 bottles of beer on the wall (since 99 follows a number). But it will\nmatch 99in$99(since 99follows a dollar sign ($), which is not a digit, underscore,\nor letter).\n2.1.2 Disjunction, Grouping, and Precedence\nSuppose we need to search for texts about pets; perhaps we are particularly interested\nin cats and dogs. In such a case, we might want to search for either the string cator\nthe string dog. Since we can\u2019t use the square brackets to search for \u201ccat or dog\u201d (why\ncan\u2019t we say \/[catdog]\/ ?), we need a new operator, the disjunction operator, also disjunction","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":360,"topic":"Regular Expressions"}}
{"id":"7f89b7bf-9d80-4377-a95f-1b60aadd9336","question":"Can you explain the role of a tokenizer in the process of text analytics, and how it interacts with the task of named entity recognition?","reference_answer":"A tokenizer is used to expand clitic contractions that are marked by clitic apostrophes, for example, converting what\u2019re to the two tokens what are, and we\u2019re to we are. It may also tokenize multiword expressions like New York or rock \u2019n\u2019 roll as a single token, which requires a multiword expression dictionary. Tokenization is thus intimately tied up with named entity recognition, the task of detecting names, dates, and organizations.","reference_context":"Document 398: where English puts commas, for example, 555 500,50 .\nA tokenizer can also be used to expand clitic contractions that are marked by clitic\napostrophes, for example, converting what\u2019re to the two tokens what are , and\nwe\u2019re towe are . A clitic is a part of a word that can\u2019t stand on its own, and can only\noccur when it is attached to another word. Some such contractions occur in other\nalphabetic languages, including articles and pronouns in French ( j\u2019ai ,l\u2019homme ).\nDepending on the application, tokenization algorithms may also tokenize mul-\ntiword expressions like New York orrock \u2019n\u2019 roll as a single token, which re-\nquires a multiword expression dictionary of some sort. Tokenization is thus inti-\nmately tied up with named entity recognition , the task of detecting names, dates,\nand organizations (Chapter 8).\nOne commonly used tokenization standard is known as the Penn Treebank to-\nkenization standard, used for the parsed corpora (treebanks) released by the Lin-Penn Treebank","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":398,"topic":"Text Analysis and Tokenization"}}
{"id":"e3f626bc-95b8-4049-b19f-98a506e07018","question":"Among the LOB Corpus, the Switchboard Phone Conversation Corpus, and the Works of Shakespeare Corpus, which one exhibits the highest number of word types? Provide your answer based on the options given.","reference_answer":"The options provided do not definitively state which corpus has the most word types.","reference_context":"Document 596: The LOB Corpus, the Switchboard Phone Conversation Corpus, and the Works of \nShakespeare Corpus are three English corpora of roughly the same size, in number of word \ntokens. Which corpus has the most word types, and why?  \nSelect one answer.  \nThe Shakespeare Corpus, because William Shakespeare was highly creative and used a wide \nvocabulary  \nThe LOB Corpus, because it included a range of texts from the Universities of Lancaster, Oslo \nand Bergen.  \nThe Switchboard Phone Conversation Corpus, because a range of topics were discussed in \nthe phone conversations.  \nThe LOB Corpus, because it followed the representative range of text source types in the \nBrown Corpus  \nThe Shakespeare Corpus, because spelling variations led to two or more word types for \nmany words  \n19. Question 19  \nWhich of these were NOT predicted in the BT Technology Calendar 1999?  \nSelect one answer.  \nHuman speech used for human -computer interaction  \nMore goods purchased online than in shops","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":596,"topic":"Corpus Linguistics Software"}}
{"id":"21b402e3-03d5-48a7-9cf3-08a7da4ed8f0","question":"In the context of English language wordforms being sufficient for many tasks, could you elaborate on the drawbacks of using speech input for normal office dictation as stated by Tyler in 1998?","reference_answer":"The drawback of speech input for normal office dictation is that the time spent correcting the errors which the speech\/text system committed cancels out the time saving won by speaking the words instead of keying them in.","reference_context":"Document 147: comfortable with a mouse and keyboard; to these users,\nspeech is not as self-evidently more \u0090natural\u0091 as it might\nhave appeared to a previous generation less familiar with\nusing computers.the language machine\n33\n.\u0091The drawback  of speech input\nfor normal office dictation, from a\nmanagement services point of\nview, is that time spent correcting\nthe errors which the speech\/text\nsystem committed cancels out the\ntime saving won by speaking the\nwords instead of keying them in ...\nSimply creating a speech\nrecognition software package that\ntransforms general\ncorrespondence speech input into\ntext will not serve the professional\nend user ... We (Philips) allow the\nauthor to dictate the document and\nsend a speech file for transcription\nto staff who can listen to the text\nwhile correcting. Having the author\ndo the correcting undermines the\nessence of speech recognition as\nthe author wastes time on\nadministrative tasks and the typing\npool sits idle\u0095.\u0091 (Tyler, 1998)\nWhat are the","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":147,"distracting_context":"languages like Arabic, we often need to deal with lemmatization. For many tasks in\nEnglish, however, wordforms are suf\ufb01cient.\nHow many words are there in English? To answer this question we need to\ndistinguish two ways of talking about words. Types are the number of distinct words word type\nin a corpus; if the set of words in the vocabulary is V, the number of types is the\nvocabulary size|V|.Tokens are the total number Nof running words. If we ignore word token\npunctuation, the following Brown sentence has 16 tokens and 14 types:\nThey picnicked by the pool, then lay back on the grass and looked at the stars.\nWhen we speak about the number of words in the language, we are generally\nreferring to word types.\nCorpus Tokens = NTypes =|V|\nShakespeare 884 thousand 31 thousand\nBrown corpus 1 million 38 thousand\nSwitchboard telephone conversations 2.4 million 20 thousand\nCOCA 440 million 2 million\nGoogle n-grams 1 trillion 13 million","topic":"Speech and Language Technology"}}
{"id":"3d5dcaf7-2efd-4fc0-9900-e9596b77dd33","question":"Considering the various components of a holistic speech and language processing system, which companies are actively engaged in the development of mobile multimedia systems for vehicles?","reference_answer":"Microsoft, Clarion, Mecel, Delphi Automotive Systems, and Saab are all involved in the development of mobile multimedia systems for vehicles.","reference_context":"Document 202: developing rapidly: several\nmanufacturers offer \u0090mobile multi-\nmedia systems\u0091, combining\ncomputer and audio with speech\nrecognisers responsive to simple\nvoice commands. A driver may\nrecord memos, tune the radio,\nselect a CD track or retrieve\ncontact data. Information can be\nfed back via speech-synthesis.\nMicrosoft, Clarion, Mecel, Delphi\nAutomotive Systems, and Saab are\nall involved in development.\n.\u0090Research showed that drivers\nusing a mobile phone \u0097 whether\nhand-held or hands-free \u0097 were\nfour times more likely to have an\naccident during, and up to five\nminutes after, a conversation \u0087 \nAt least six road deaths have been\nlinked to mobile phones in Great\nBritain.\u0091 (The Royal Society for the\nPrevention of Accidents, Press\nRelease, 25 February 1999)SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":202,"distracting_context":"Defining shared approaches \nIn 1995, the US National Science Foundation and the\nEuropean Commission commissioned a comprehensive\nsurvey of the state of the art in Human Language\nTechnology  (Cole et al, 1995), which reviewed the field in\nterms of the components or modules that are needed for an\noverall, holistic speech and language processing system.\nThese components \u0097 what makes up a language machine\n\u0097 are broken down into the various steps of the technology:\ninput of words (spoken or written); analysis; understanding;\nspoken output or text generation; dialogue; document\nprocessing; multilingual ability; multimodality; mathem-\natical models; language resources; storage; transmission;\nand evaluation.\nFigure 1 shows how these components interact:\nmathematical models, language resources, transmission,\nstorage and evaluation modules can be called by any of the\nother elements.what\u0091s involved\n20input to output\nmultimodalitymultilingualityanalysis \nand \nunderstanding","topic":"Language and Speech Technology"}}
{"id":"25861a01-1929-41e4-b7f4-9af061c3ef5b","question":"What potential issues could arise with the increased application of the language machine in education, particularly in the context of integrating various Asian languages such as Chinese?","reference_answer":"Language teachers who wish to use CALL software incorporating speech recognition technology may need to rethink approaches, and decide which aspects of learning could be achieved more successfully by the individual using the technology alone, and which learning should remain within the classroom as a shared, group activity.","reference_context":"Document 223: learning \u0090taught\u0091 in a classroom environment and those\n\u0090learnt\u0091 autonomously by students equipped with their own\npersonal language machines may also prove significant to\ncurricula and educational decisions. The teaching\nprofessions need to ensure that they are in a position to\nexploit the language machine to best advantage.the language machine\n53\n.Ownership of personal\ncomputers continues to rise in the\nUK \u0097 but will access to new\ntechnology become a new form of\ndiscrimination, social stratification,\nor inequality? Questions to help\nforward the debate on the impact\nof the language machine are listed\non page 64.\nScenario 1: the must-haves \u0097 handbag, lippy, wristwatch translator\nAlready, thanks to discreet ear-pieces that allow mobile-phone users to converse on the phone hands-free \u0097often with the phone out of sight \u0097 we are becoming used to seeing solitary speaking. The future begins:\n\nDocument 279: Scenario 3: customised language machines\nwill be used by individuals for particular tasks 51Implications: the professions 52Scenario 4: no aspect of language professionsis immune 52Rethinking our assumptions \u0097 and our self-image? 52\nScenario 1: the must-haves \u0097 handbag, lippy,wristwatch translator 53\nQuestioning the future 54Having misgivings? 54The digital helping hand? 54\nGood times and fortunes 55\nLeading the way: the next steps 56Ways ahead 56Wild child \u0097 or wired child? 57\nGlossary: the jargon 58\nReferences: the books 60\nMagazines: the quickest route 61\nWeb information: cyber-sites 62\nQuestions for debate 70the language machine\n69\n\nDocument 145: professions. For example, language teachers who wish to\nuse CALL software incorporating speech recognition tech-\nnology may need to rethink approaches, and decide which\naspects of learning could be achieved more successfully by\nthe individual using the technology alone, and which\nlearning should remain within the classroom as a shared,\ngroup activity. Similarly, whole-school policies \u0097 of funding\nnew equipment, providing new learning spaces, and\nmanaging the politics of departmental resourcing \u0097 may\nneed to come under similar scrutiny if language machine\ntechnology is to be used more widely and successfuly in\neducation. \nProblem 6\nNewcomers need training and time to learn to\nuse the language machine \nOne supposed strength of the language machine is that\ncommunicating with a computer in spoken English is\n\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic\n\nDocument 226: Having misgivings? \nClearly, there is great potential for the language machine to\nbecome a normal component in the personal computing\n\u0090kit\u0091 that is now so easily and widely adopted \u0097 and\nexpected \u0097 by new generations.\nBut along with such easy adoption of new technology lie\nold fears \u0097 will machines replace humans? With the\nlanguage machine to assist them, who will want to learn\nlanguages or use the services of a human interpreter or\ntranslator? Even if large numbers of people want to learn\nEnglish for example, will their human teachers be replaced\nby language machine based self-tutoring software?\nLearners prefer the human touch  Even if we can afford the\nlanguage machines of the future, that does not mean we\nwill necessarily choose to use them. Language students, for\nexample, may prefer human interaction: even when\nlanguage machine-based software offers comprehensive\nEnglish language self-tutoring facilities, many students will","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":223,"distracting_context":"integration of various Asian languages.\n4.1 Chinese\nThe collaboration for Chinese began with Prof Huang Chu-Ren inviting the \ufb01rst\nauthor to Taiwan in 2004. (At the time, Huang was Deputy Director of the\nLinguistics Department at Academia Sinica, Taiwan.) Following that visit, and\ncommercial interest in Chinese in the Sketch Engine from CJKI,\n14the Chinese\nGigaword corpus was acquired from the Linguistic Data Consortium, segmented\n12For Urdu, the relation between the language spoken in India (as a mother tongue) and in Pakistan (as\nan of\ufb01cial language but not the mother tongue of many people) is a particular puzzle. For both Urdu andPunjabi, multiple writing systems are a challenge. For all Indian languages, until quite recently, manyIndians would use the web in English: all educated Indians speak English, web searching worked better inEnglish, and not so much could be found in many of the Indian languages. This is changing fast.","topic":"Language Technology and Machine Translation"}}
{"id":"7b47e5de-d474-4f4d-8d04-aa99ea133a68","question":"In the context of regular expressions used for processing language, can you explain what a capture group is?","reference_answer":"In the context of regular expressions, a capture group is the use of parentheses to store a pattern in memory. Every time a capture group is used (i.e., parentheses surround a pattern), the resulting match is stored in a numbered register. This allows for the matched pattern to be used later in the expression.","reference_context":"Document 374: parenthesis operator, and replacing the second X with the number operator \\1, as\nfollows:\n\/the (.*)er they were, the \\1er they will be\/\nHere the\\1will be replaced by whatever string matched the \ufb01rst item in paren-\ntheses. So this will match the bigger they were, the bigger they will be but not the\nbigger they were, the faster they will be .\nThis use of parentheses to store a pattern in memory is called a capture group . capture group\nEvery time a capture group is used (i.e., parentheses surround a pattern), the re-\nsulting match is stored in a numbered register . If you match two different sets of register\nparentheses, \\2means whatever matched the second capture group. Thus\n\/the (.*)er they (.*), the \\1er we \\2\/\nwill match the faster they ran, the faster we ran but not the faster they ran, the faster\nwe ate . Similarly, the third capture group is stored in \\3, the fourth is \\4, and so on.\nParentheses thus have a double function in regular expressions; they are used to","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":374,"distracting_context":"identity? .the language machine\n11\nWhen destiny calls, have the confidence to answer\n\u0090In 1876, Bell and Watson demonstrated their new device to Western Union, but the company\u0091s executives\nfailed to see its potential. \u0094Mr Bell,\u0095 they wrote to him, \u0094after careful consideration of your invention, while it\nis a very interesting novelty, we have come to the conclusion that it has no commercial possibilities,\u0095 adding\nthat they saw no future for \u0094an electrical toy\u0095. \u0087 In the next twenty years \u0087 Bell\u0091s telephone company,\nrenamed American Telephone and Telegraph, became the largest corporation in America, with stock worth\n$1,000 a share. The Bell patent became the single most valuable patent in history .\u0091 (Bryson, 1994)Future scenarios\nSee pages 50 to 53\n.\u0091The evolution  of human\nintelligence keeps pace with the\nevolution not only of language, but\nof technologies supporting and\nprocessing language.\u0091\n(O\u0091Donnell, 1998)\nRemember your reactions onlearning to use a word processor,","topic":"Regular Expressions"}}
{"id":"fdaba4a7-6676-4b60-ae51-6c21ce816916","question":"Given that the language machine is not always the most suitable for certain tasks, what is the cost of insertion, deletion, and substitution in the edit distance computation in the context of computational linguistics?","reference_answer":"The cost of insertion, deletion, and substitution in the edit distance computation is 1.","reference_context":"Document 444: (but not, e.g., words like grottos that merely contain the word grotto );\n4. write a pattern that places the \ufb01rst word of an English sentence in a\nregister. Deal with punctuation.\n2.3 Implement an ELIZA-like program, using substitutions such as those described\non page 10. You might want to choose a different domain than a Rogerian psy-\nchologist, although keep in mind that you would need a domain in which your\nprogram can legitimately engage in a lot of simple repetition.\n2.4 Compute the edit distance (using insertion cost 1, deletion cost 1, substitution\ncost 1) of \u201cleda\u201d to \u201cdeal\u201d. Show your work (using the edit distance grid).\n2.5 Figure out whether drive is closer to brief or to divers and what the edit dis-\ntance is to each. You may use any version of distance that you like.\n2.6 Now implement a minimum edit distance algorithm and use your hand-computed\nresults to check your code.\n2.7 Augment the minimum edit distance algorithm to output an alignment; you","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":444,"distracting_context":"Problem 4\nThe language machine is not appropriate for\nsome tasks \nSome computational linguists might suggest that speech\nand language are obviously always the best means of\ncommunication \u0097 with or via computers. But even if the\nlanguage machine worked with a high degree of accuracy,\nit is still not clear that everything should be done via\nlanguage and speech. \nThe computer industry has put much effort into\ndeveloping graphical user interfaces (GUIs, pronounced\n\u0090goo-eez\u0091) that use icons, 2-D and 3-D graphics, menus, and\npointers; these may not readily convert into speech-\ncontrolled applications, and even if they could be converted\nit may not be the best approach to the task. Most of us, for\nexample, manage to use lifts quite happily by pressing one\nof a small number of buttons to get to our selected level in\na building: it is doubtful whether speech control could add\nmuch value to the experience. The automobile and\ncomputing industries are putting large amounts of money","topic":"Minimum Edit Distance Algorithm"}}
{"id":"838c94e6-2e21-473b-aed8-e174dbd60bb7","question":"What was the average monthly salary in 1998, expressed in British pounds, for a British individual and a Romanian individual, given that the data may have been processed and analyzed through tech analytics?","reference_answer":"In 1998, the average monthly salary for a British person was \u00a31600 and for a Romanian person, it was \u00a345.","reference_context":"Document 133: .\u0090Information technology  is\nimportant in tackling social\nexclusion because anyone can\nwalk in to a library, sit down and\nstart tapping away \u0097 at absolutely\nno cost.\u0091 \u0097 Chris Smith, the\nSecretary of State for Culture,\nMedia and Sport. (The\nIndependent, June 19 1999).Compare  two countries: in 1998,\nan IBM PC cost the same in\nLondon and Bucharest. Average\nmonthly salaries in GBP: \nBritish \u0097 \u00a31600 \nRomanian \u0097 \u00a345\nLanguage \nmachines fordisabilitiesSee page 54SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":133,"distracting_context":"\u00a9 University of Leeds   7 of 10  computers. You don't want to have to type in numbers. Maybe you want to be able to speak to \nyour computers and listen to your computer. It's also between people, it can assist communication.  \nFor example, when I go to China to teach, it's helpful that we have machine translation so that I \ndon't have to learn Chinese. Or it's very good for monitoring communication between people. \nSocial media is basically people posting to other people. And the tech scientists can analyze their \nsocial media, see what themes are coming up, stop posts which are fake news, and all sorts of \nuseful stuff like that. And of course, another big reason for developing tech analytics is there's \nmoney in it. So the government and the industry are interested i n wealth creation.  \nOK. And the book also looks at what the challenges are for text analytics. Well, one big problem \nfor the UK and for British companies is it's very expensive because the BIG IT companies like","topic":"Others"}}
{"id":"409daec5-8e91-4fe7-b1d1-0313d250de02","question":"Considering the unique linguistic characteristics of Arabic, could the same method used for learning text segmentation in languages like Japanese and Thai be applied to Arabic?","reference_answer":"You can use a training data set of segmented text for machine learning. Typically, a deep-learning neural sequence model might be used to learn segmentation.","reference_context":"Document 332: \u00a9 University of Leeds   12 of 14  You might just say, there's 7 characters, so that just say there are 7 sorts of words. And the words \nin Chinese don't map onto English words straightforwardly. But after all, this is Chinese. Therefore \nmaybe there are 7 characters. So in Chinese is common just to treat each character as a token, \nand in that case segmentati on is very simple. But then how do tokeni se words or meaning units, \nas opposed to characters, is a bit harder.  \nIn other languages like Thai and Japanese, it's more complicated. What you can do instead, is if \nyou have a training data set -- if you have a lot  of Japanese text where some people have \nsegmented it into words, then you can use this for machine learning, and standardly you might use \nsome sort of deep- learning neural sequence model to learn segmentation. We're not going to go \nthere yet. We'll see that later on.  \nThere is in the book even more about text tokenisation using bytecode, and coding using single","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":332,"distracting_context":"(sixteenth\u2013eighteenth centuries; Culpeper and Kyto \u00a82010 ).\nFor the Arabic world and Islam, the language has a special role. It is the language\nof the Quran and of the culture that the region shares. The different countries eachhave their own dialect, and the lingua franca, MSA, is closer to classical Arabic thanto the dialects. The King Saud University Corpus of Classical Arabic (KSUCCA\n23)\nbrings together many of the central texts of this language, culture and religion,including the Quran and the Hadith.\n5.1.5 Learning to speak\nSince 1984, the CHILDES and Talkbank projects, based at Carnegie Mellon\nUniversity, have been gathering child\u2013adult conversations.\n24They are largely","topic":"Text Analysis and Tokenization"}}
{"id":"fd964002-313b-419f-9f98-2b92e49fc44c","question":"In the context of natural-language learning systems that use statistical pattern-matching models, what regular expression would be employed to capture variations of the lemma 'sing'?","reference_answer":"[Ss].ng","reference_context":"Document 593: test.arff and then try running the following classifiers:  \nJ48 \nFilteredClassifier  \nNaiveBayes  \nIBk \nWhich of these classifiers is reasonably expected to produce the best accuracy?  \nSelect one answer.  \nJ48 \nFilteredClassifier  \nIBk \nNaiveBayes  \n11. Question 11  \nI use the following regular expression to capture variations of the lemma \"sing\":  \n[Ss].ng  \nWhich of the following are false positive matches?  \nSelect one answer.  \nSung  \nSeng  \nsang  \nSING  \n12. Question 12  \nGiven the iris.arff data -set as a training set using the Percentage Split option, how many \nfeatures does the Weka ZeroR classifier take into account?  \nSelect one answer.  \n1 \nAll \n2 \nNone","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":593,"distracting_context":"spoken English to practise every-\nday conversational language skills.\n.Natural-language learning\nsystems often use sophisticated\nstatistical pattern-matching models\n(for example Hidden Markov\nModels or neural networks),\noblivious to any possible lessons\nfrom education or language\nteaching theories of human\nlanguage learning. SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","topic":"Machine Learning and Text Processing"}}
{"id":"ab0eaec6-9dd8-48ce-83f4-d25bd71952a0","question":"In the context of machine translation where sentences in a parallel corpus need to be matched to each other, how does the Penn Treebank tokenization standard function and what is its role?","reference_answer":"The Penn Treebank tokenization standard is a commonly used tokenization standard used for parsed corpora (treebanks) released by the Linguistic Data Consortium (LDC). This standard separates out clitics (for example, 'doesn\u2019t' becomes 'does' plus 'n\u2019t'), keeps hyphenated words together, and separates out all punctuation.","reference_context":"Document 399: and organizations (Chapter 8).\nOne commonly used tokenization standard is known as the Penn Treebank to-\nkenization standard, used for the parsed corpora (treebanks) released by the Lin-Penn Treebank\ntokenization\nguistic Data Consortium (LDC), the source of many useful datasets. This standard\nseparates out clitics ( doesn\u2019t becomes does plus n\u2019t), keeps hyphenated words to-\ngether, and separates out all punctuation (to save space we\u2019re showing visible spaces\n\u2018\u2019 between tokens, although newlines is a more common output):","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":399,"distracting_context":"chine translation, in which sentences in a parallel corpus (a corpus with a text in two\nlanguages) need to be matched to each other.\nTo extend the edit distance algorithm to produce an alignment, we can start by\nvisualizing an alignment as a path through the edit distance matrix. Figure 2.19\nshows this path with the boldfaced cell. Each boldfaced cell represents an alignment\nof a pair of letters in the two strings. If two boldfaced cells occur in the same row,\nthere will be an insertion in going from the source to the target; two boldfaced cells\nin the same column indicate a deletion.","topic":"Text Normalization and Tokenization"}}
{"id":"70c34170-9b9e-4731-8bbf-770fc3fcbfad","question":"According to Lucinda Mobaraki, what are the potential benefits of machine translation in terms of improving the efficiency and quality of translation work?","reference_answer":"Machine Translation can help people to get the gist of the material to find out if it is worth translating. It can make the translator's job more interesting and better paid as they will be able to do more work in a normal eight-hour working day. This will eventually weed out the translator who produces poor quality material.","reference_context":"Document 164: be a shame if a sharp new focus on computers threw up yet another intimidating roadblock to\nlanguage-study for the poor or elderly.\n \u0097 Neil Langdon Inglis, Senior Translator, International Monetary Fund.\nMachine Translation is a wonderful tool. People will be able to get the gist of the material in order\nto find out if it is worth while translating. It will also make the translator\u0091s job a lot more interesting\nand better paid as they will be able to do a lot more work in a normal eight-hour working day. This\nwill eventually weed out the translator who produces poor quality material.\u0091\n \u0097 Lucinda Mobaraki, T & I Services\nCan the UK become \u0090Europe\u0091s digital laboratory\u0091 for such products? See pages 42\u009743.SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 228: difficult to believe that its overall command of English will\nmatch (let alone exceed) that of an advanced learner of\nEnglish, even in 20 years\u0091 time. Translators and teachers \u0097\ncapable of judging social language, multiple meanings,\nnuance, subtle forms, and language complexities \u0097 do not\nneed therefore to fear they will be easily replaced!\nMore probably, machine translation will be used\nalongside good teaching and translation. It is used alreadyquestioning\n54the future\nThe digital\nhelping hand\nLanguage machines can help\ndisabled people to more easily\naccess technology: the following\nindicates some present activities.\nThe Royal National Institute for\nthe Blind (www.rnib.org.uk) offers\nextensive information on speech\nsynthesis packages and suppliers.\nThe EU\u0091s ISEAUS project aims to\nuse language engineering in\nspeech education and rehabil ita-\ntion for adults with lifelong or\nacquired deafness (see page 63).\nThe funding body EPSRC actively\nencourages researchers to work\n\nDocument 159: may be the case in Mexico, where the state ministry \u0097 while\nworking with the British Council to upgrade the skills of its\nteachers \u0097 is keen to introduce new technology. \nInterestingly for education, in applications such as\nmachine translation (the focus of the box opposite) and for\npeople working in other professions, . it is clear that the\nlanguage machine is making clear inroads.\nBut do inroads lead to a revolution?determination\n36to succeed\n.One scenario for the ELT\nbusiness is a radical one: what if\nthe language machine brought\nabout the large-scale abandonment\nof language learning? Many people\nlearn English so they can use it to\ncommunicate with native English\nspeakers or as a lingua franca; but\nwhat if, in the future, they find that\nit is possible to communicate via\nmachine translation devices?\nIs this scenario a realistic one?\nImplications for language\nprofessionals are explored on\npages 50\u009757.\nHal \u0097 the \ntalking computer\nmade evil\nSee page 35.Searching for Extra Terrestrials?\n\nDocument 115: with simplified source texts, or to\nproduce a \u0094gist\u0095 version ... of\ndocuments that, for economic\nreasons, would otherwise never be\ntranslated at all. There is certainly\nno prospect in the foreseeable\nfuture of human translators being\nmade redundant by such systems!\u0091\nWith Machine-Assisted Translation\nhowever: \u0090the computer provides\nsophisticated aids to enhance the\nefficiency and consistency of the\ntranslation, but the human remains\nin charge and makes all the\ndecisions.\u0091 (Rothwell, 1998,\ndescribing the University of Leeds\nMA in Applied Translation Studies.)Taking the \nTuring test?\nSee page 10SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":164,"distracting_context":"parenthesis operator, and replacing the second X with the number operator \\1, as\nfollows:\n\/the (.*)er they were, the \\1er they will be\/\nHere the\\1will be replaced by whatever string matched the \ufb01rst item in paren-\ntheses. So this will match the bigger they were, the bigger they will be but not the\nbigger they were, the faster they will be .\nThis use of parentheses to store a pattern in memory is called a capture group . capture group\nEvery time a capture group is used (i.e., parentheses surround a pattern), the re-\nsulting match is stored in a numbered register . If you match two different sets of register\nparentheses, \\2means whatever matched the second capture group. Thus\n\/the (.*)er they (.*), the \\1er we \\2\/\nwill match the faster they ran, the faster we ran but not the faster they ran, the faster\nwe ate . Similarly, the third capture group is stored in \\3, the fourth is \\4, and so on.\nParentheses thus have a double function in regular expressions; they are used to","topic":"Language Machine Translation"}}
{"id":"55eb9752-69e2-4366-91f3-484c01b7e44f","question":"In relation to the Philips Vision of the Future, how does a product evolve while considering the tools and processes available for major world languages in the vulcanology domain?","reference_answer":"According to the Philips Vision of the Future, the progression of a product includes first imaginings, technological breakthrough, lowering of manufacturing costs, easy integration into equipment, experiments with consumer electronics, fashion items, adoption by designers and digerati, product copying, rock-bottom cost, high-street retail, global distribution, and worldwide acceptance.","reference_context":"Document 71: (Philips Vision of the Future\nonline magazine, 1997).From first imaginings \u0087\ntechnological breakthrough;\nlowering of manufacturing costs;\neasy integration into equipment;\nexperiments with consumer\nelectronics; fashion items;\nadoption by designers and digerati;\nproduct copying; rock-bottom cost;\nhigh-street retail; global\ndistribution; worldwide acceptance\n\u0087 SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":71,"distracting_context":"form and Fig. 19for the keywords and terms found, fully automatically and in a few\nminutes, for the vulcanology domain.\nMore can be done with a user corpus if it is accurately tokenised, lemmatised and\npart-of-speech tagged. Tools for these processes are language-speci\ufb01c. For 11 majorworld languages, tools have been identi\ufb01ed, licenced (where necessary) andinstalled. Some users have used the Sketch Engine explicitly for this service: they\ncan upload plain text, get it processed, and then download the processed data (in\nvertical format), perhaps for further annotation and re-uploading.\nProcessing options are steadily being added for more languages.There is \u2018access control\u2019 for user corpora. By default, the only user who can see a\ncorpus is the person who created it, but they can give access to others (at a webinterface). This allows a teacher to give access to a corpus that they have prepared,to their students, or a researcher to share their corpus with their colleagues.","topic":"Others"}}
{"id":"f691ed7b-9432-4424-acad-42e46a892660","question":"Considering the current level of machine language processing, how would you define the term 'Lexis' in this context?","reference_answer":"Lexis is the study of words or vocabulary items in a language, including all forms having individual meaning or grammatical function.","reference_context":"Document 23: scientific approach. And it takes that language signal and analyzes it at various  levels. So as \nphonetics, the study of speech, production, and perception. Lexicography, or Lexis, is a study of \nwords or vocabulary items in a dictionary for example. And the words will have the way that they \nwritten, the way that they're spoken, the meaning, and the big grammatical function. And then the \nsyntax or grammar, the study of grammatical arrangements of words and morphemes. And \nmorpheme is a minimal unit. We'll see more of this later on.  \nSemantics is the study of meaning, the meanings of words, the meaning of sentences, and how \nthese are related to each other. How can you tell that marriage and wedding mean the same thing, \neven though they're different character sequences? Pragmatics is the analysis of language in \npractical use. Take into account  the context of use. Discourse modeling is about phenomena that\n\nDocument 83: technology to a wider public, so we can expect language\nmachines to become widespread. . creating popular\n16markets\nThe contribution\nof computing\nSee page 15The language of language processing \nPhonetics : the study of speech processes, including the\nproduction, perception, and analysis of speech sounds from both\nan acoustic and a physiological point of view.\nLexis : the study of words or vocabulary items in a language,\nincluding all forms having individual meaning or grammatical\nfunction.\nSyntax : the study of the grammatical arrangement of words and\nmorphemes in the sentences of a language or of languages in\ngeneral.\nSemantics : the study of meaning in language, and the principles\nthat govern the relationship between words and sentences and\ntheir meanings.\nPragmatics : the analysis of language in practice, taking account\nof the context of language use.\nDiscourse modelling : the analysis of linguistic phenomena that","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":23,"distracting_context":"learners\u0091 pronunciation of English, teachers and learners\nhave been involved at every stage, from initial drafting of\nresearch plan through to specification of requirements and\nverification of the final system. (ISLE project, see page 62)\nProblem 3\nThe language machine doesn\u0091t match the\nexpectations of customers\nSome potential customers expect the language machine to\nbe able to understand everything and to match human\nlanguage-processing, even though people themselves often\ndisplay a considerable talent for misunderstanding! \nAlthough the language machine clearly falls well below\nhuman standards . for language processing at present,\nthere are a growing number of tasks for which it is arguably\nadequate. In practice, the best current machine translation\nsystems are at least as good as a fairly competent second\nlanguage learner. This may be quite acceptable for some\ntasks: imperfect translation may be adequate for the reader","topic":"Others"}}
{"id":"f2f59860-3380-41d6-b8c2-9f321d513627","question":"Considering the need for deep information analysis, knowledge extraction, and summarisation, how do the EUROMAP and LINGLINK projects contribute to the field of language technology?","reference_answer":"EUROMAP, EUROMAP II, and LINGLINK are surveying and promoting language engineering applications. They help to bring the technology to markets and users by raising awareness of markets, customer needs, standards, and potential uses.","reference_context":"Document 182: markets, customer needs, standards and potential uses:\nEUROMAP . (European Opportunity Mapping),\nEUROMAP II, and LINGLINK (Promotion and Support for\nLanguage Engineering in Europe) are surveying and\npromoting language engineering applications, helping to\nbring the technology to markets and users.\nEAGLES (Expert Advisory Group on Languagesupply & demand\n42the markets\n.The EUROMAP project\n(European Opportunity Mapping)\nhas reported on a thriving\nEuropean research and\ndevelopment community in speech\nand language technology: \u0090A total\nof some 10,000 language\ntechnology players in Europe had\nbeen identified, including research\nstaff, vendors, and professional\nand corporate users, of which\n7,000 can be assumed to be\ndealing with core language tech-\nnology issues. Of these, more than\n1,000 research sites, academic and\ncommercial, were contacted, and\naround 300 provided information to\nthe survey.\u0091 (EUROMAP\nWeb site, 1999).Who supplies  speech and\nlanguage systems? Niche suppliers\n\nDocument 183: 1,000 research sites, academic and\ncommercial, were contacted, and\naround 300 provided information to\nthe survey.\u0091 (EUROMAP\nWeb site, 1999).Who supplies  speech and\nlanguage systems? Niche suppliers\nmay sell language machines not\ndirectly to the end-user, but as\ncomponents of larger products and\nservices. The channels of supply\nidentified by EUROMAP are\nsoftware vendors; tele-\ncommunications providers; value\nadded network suppliers (including\nInternet Service Providers, or\nISPs); communications equipment\nsuppliers; information service\nproviders; electronic publishers\n(including the news media); and\nsystems integrators. (EUROMAP\nWeb site, 1999)SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 181: How are people encouraged to buy?\nMuch of the work now being completed in speech andlanguage projects across Europe emerges as products for\nlarge organisations \u0097 pan-European administrations, trans-\nnational commercial organisations, or security and law\nenforcement agencies working across borders \u0097 but what\ncan encourage the smaller organisation to invest . in\nspeech and language technology?\nElsewhere in this book issues are raised \u0097 of cost; scale;\ntraining; dialogue between end-user and researcher \u0097 but\none key ingredient in bringing a product to market is that of\ninformation .\nSeveral projects now aim to develop general language\nresources and infrastructure, to support and promote the\ntake-up of language engineering, and to raise awareness of\nmarkets, customer needs, standards and potential uses:\nEUROMAP . (European Opportunity Mapping),\nEUROMAP II, and LINGLINK (Promotion and Support for\nLanguage Engineering in Europe) are surveying and","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":182,"distracting_context":"understanding of messages and communicative acts, unconstrained language input-output and keyboard-\nless operation; \n3. enabling active digital content for an optimal use and acquistion by all, through personalised language\nassistants supporting deep information analysis, knowledge extraction and summarisation, meaning\nclassification and metadata generation.\u0091 (Varile, 1997)SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","topic":"European Language Technology Projects"}}
{"id":"342ea19f-4fa8-4f78-9e73-9ca4483a4034","question":"Considering the need for training and time for newcomers to learn to use language machines, what are some resources that can be utilized in the development of these machines?","reference_answer":"The resources used in the development of language machines include corpora (collections of texts), lexical databases (computerised dictionaries), and software tools to access these resources. Specific resources can include spoken corpus resources, part-of-speech word-tagged text, Treebanks, spoken corpora, parallel corpora, learner corpora, lattice corpora, parallel-annotated corpora, and wordlists for a wide range of languages.","reference_context":"Document 91: a \u0090model\u0091. Such models have applications in several\ndisciplines and research areas.\nBuilding computerised language resources Researchers\ngenerally make use of computerised language resources in\ndeveloping language machines, either directly or indirectly.\nThese resources may include: corpora (collections of texts);\nlexical databases (computerised dictionaries); and software\n\u0090tools\u0091 to access such resources and link them to other\nsoftware systems (page 27 lists available resources). In\nthemselves these resources are a huge investment\nsupporting potential uses in many different disciplines.\nA corpus can help not only in direct research: it may also\nhelp indirectly. One example would be in guiding the\ndevelopment of a new English dictionary. Once completed\nthe dictionary itself could be subsequently incorporated\ninto a language processing system.\nAssisting natural communication between people and\ncomputers Language machine developers have a common\n\nDocument 124: the language machine\n27\nResources for developing the language machine\nSpoken corpus resources\nRecordings of words, sentences, scripted speech, spontaneous monologues, dialogues.\nCollations of written texts.\nPart-of-speech word-tagged text (each word is annotated with a Part of Speech tag).\nTreebanks: sentences annotated with syntactic phrase structure.\nSpoken corpora: digitised acoustic signal aligned to transcription.\nParallel corpora: English sentences aligned to translations in another language.\nLearner corpora: English learners\u0091 text or speech with errors (pronunciation, spelling,\ngrammar, etc.) marked, and annotated with corrections.\nLattice corpora: the uncertain output of a speech recogniser, including a set of Ascii\n\u0090candidates\u0091 for each spoken word.\nParallel-annotated corpora: a single text sample annotated with several of the above\nlevels of linguistic analysis.\nLexical resources\nWordlists for a wide range of languages.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":91,"distracting_context":"professions. For example, language teachers who wish to\nuse CALL software incorporating speech recognition tech-\nnology may need to rethink approaches, and decide which\naspects of learning could be achieved more successfully by\nthe individual using the technology alone, and which\nlearning should remain within the classroom as a shared,\ngroup activity. Similarly, whole-school policies \u0097 of funding\nnew equipment, providing new learning spaces, and\nmanaging the politics of departmental resourcing \u0097 may\nneed to come under similar scrutiny if language machine\ntechnology is to be used more widely and successfuly in\neducation. \nProblem 6\nNewcomers need training and time to learn to\nuse the language machine \nOne supposed strength of the language machine is that\ncommunicating with a computer in spoken English is\n\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic","topic":"Others"}}
{"id":"194ba8c9-ef65-452d-8320-3bc8bbafd748","question":"In the context of using CALL software that incorporates speech recognition technology, what modifications might language educators need to make, particularly when teaching words such as Vietnamese 'tay' (hand) or Hindi 'dil' (heart)?","reference_answer":"Language teachers may need to rethink approaches, and decide which aspects of learning could be achieved more successfully by the individual using the technology alone, and which learning should remain within the classroom as a shared, group activity.","reference_context":"Document 222: resources that call for radical changes in teaching methods.\nThe relatively cumbersome and expensive PC of today may\nlook to some like a successor to the cumbersome and\nexpensive audio-visual technology of the language\nlaboratory \u0097 an approach to language teaching that did not\nwin universal popularity. \nUnlike the language laboratory, however, the language\nmachine is a technology that can permeate everyday . life;\nits acceptance into the classroom should be, therefore,\nmuch more natural. By analogy, many language learners in\n20 years\u0091 time may be accustomed to using their own\neveryday personal computing resources and expect\nlanguage learning to conform to other aspects of everyday\nlife in making appropriate use of such technology.\nThe potential shift of balance between aspects of\nlearning \u0090taught\u0091 in a classroom environment and those\n\u0090learnt\u0091 autonomously by students equipped with their own\npersonal language machines may also prove significant to\n\nDocument 145: professions. For example, language teachers who wish to\nuse CALL software incorporating speech recognition tech-\nnology may need to rethink approaches, and decide which\naspects of learning could be achieved more successfully by\nthe individual using the technology alone, and which\nlearning should remain within the classroom as a shared,\ngroup activity. Similarly, whole-school policies \u0097 of funding\nnew equipment, providing new learning spaces, and\nmanaging the politics of departmental resourcing \u0097 may\nneed to come under similar scrutiny if language machine\ntechnology is to be used more widely and successfuly in\neducation. \nProblem 6\nNewcomers need training and time to learn to\nuse the language machine \nOne supposed strength of the language machine is that\ncommunicating with a computer in spoken English is\n\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic\n\nDocument 223: learning \u0090taught\u0091 in a classroom environment and those\n\u0090learnt\u0091 autonomously by students equipped with their own\npersonal language machines may also prove significant to\ncurricula and educational decisions. The teaching\nprofessions need to ensure that they are in a position to\nexploit the language machine to best advantage.the language machine\n53\n.Ownership of personal\ncomputers continues to rise in the\nUK \u0097 but will access to new\ntechnology become a new form of\ndiscrimination, social stratification,\nor inequality? Questions to help\nforward the debate on the impact\nof the language machine are listed\non page 64.\nScenario 1: the must-haves \u0097 handbag, lippy, wristwatch translator\nAlready, thanks to discreet ear-pieces that allow mobile-phone users to converse on the phone hands-free \u0097often with the phone out of sight \u0097 we are becoming used to seeing solitary speaking. The future begins:\n\nDocument 157: Can problems be overcome?\nTaking a typical application \u0097 language teaching and\nlearning \u0097 can we imagine that the problems described in\nthis section will be overcome?\nClearly, full integration of the language machine is not\nforseeable in the immediate future. At the very least,\nlearners and teachers need to use computers confidently in\neveryday learning contexts. And, in its current state, the\nlanguage machine is not yet appropriate as a replacement\nfor some of the tasks undertaken by the language teacher. .\nYet as language technology improves, the boundary\nbetween tasks that can be delegated to the computer and\nthose that should be done only with a human language\nteacher will shift. The advent of widescale personal\ncomputing may also have an impact in terms of allowing\nstudents to use language machines to learn some aspects\nof language outside the classroom. It is likely that new\nways of teaching using computers will also spill into\nlanguage teaching from other areas of education.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":222,"distracting_context":"Fig. 15 Word sketches for Vietnamese tay(hand)\nFig. 16 Word sketches for Hindi (heart)22 Lexicography ASIALEX (2014) 1:7\u201336\n123","topic":"Artificial Intelligence in Language Learning"}}
{"id":"21554f49-1d44-43f2-ac24-4433725c435b","question":"In the process of normalizing and analyzing a text data set for a classifier, how is the size of the data set typically determined?","reference_answer":"The size of a text data set is usually measured by how many word tokens there are.","reference_context":"Document 317: \u00a9 University of Leeds   8 of 14  This was supposedly about a million words of text. At the time the internet didn't exist. So we had \nto collect published newspapers, books, other documents like that which were available. And had \nto be typed up again and transcri bed-- well not -- typed up onto the computer.  \nSo there's about a million words. And this contained 50,000, so that was more. So British English \nat the time in the 1960's and American English at the time in the 1960's was more varied than the \nworks of Shakes peare.  \nAnd this is because, OK, Shakespeare was very creative, but it was just Shakespeare. Whereas \nthe LOB Corpus and the Brown Corpus, that included newspapers written by lots of different \npeople, novels, books of various sorts, government reports. All s orts of things written by lots of \ndifferent people, and therefore it was more varied, because there are more different sources \naround.\n\nDocument 315: America. And they've recorded them and transcribed them. A nd it's 2 and 1\/2 million tokens \naltogether so that one way of measuring the size of a corpus isn't so much in how many bytes or \nmegabytes or terabytes it is, but how many words there are.  \nThat's the usual way of counting the size of a text data set, is how many word tokens there are. \nAnd there's 2 and 1\/2 million tokens. That's the size. And there's about 20,000 different types.  \nNow if you look at the complete works of Shakespeare, that's less than a million word tokens -- \nslightly less than a million, and there's 31,000 types. So actually Shakespeare is more productive. \nIt's more varied. That's completely not surprising.  \nWhen people talk on the phone, they tend to talk about the same sorts of things over and over \nagain. So there's not as much variety in what they say as in the complete works of Shakespeare. \nMaybe more surprising, one of my first jobs a long time ago was to work on the LOB Corpus -- The","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":317,"distracting_context":"the corpus for yourself. So that's why I'm saying this. Don't just collect the corpus, but note down \nmetadata about what features of the corpus are important.  \nOK, so that's word and corpus. Finally, I want to say something about tokenisation. So if you are \ncollecting data and analyzing data for a classifier, you want t o normalise it in some way. First of all, \nyou need to segment the text into words, and then you also want to normalise the format of the \nwords. You may even want to segment it into sentences.  \nSo a very simple way to tokeni se English and other language, which are written in characters like \nGreek, or Arabic, and so on. They typically have spaces between the words, so you can say \nwherever's a space, that segments it into tokens.  \nUnix has got a number of tools for a very simple s pace -based tokenisation. I'm going to show a \nsimple example. Ken Church, one of the developers of Unix wrote a really interesting paper called,","topic":"Corpus Linguistics Software"}}
{"id":"5f14141e-ad2d-42fe-8711-b7bd045f1ec6","question":"Given the current advancements in machine learning and regular expressions, what is the expert panel's assessment of the state of machine translation?","reference_answer":"The standards and skills of computer software are already better than many people realize. Observers are often surprised at the state of the art when demonstrating recent advances in areas such as speech or character recognition.","reference_context":"Document 139: book looks after a return trip to Italian through AltaVista\u0091s Babelfish translation service. You may have got the\nbasic meaning \u0097 apart perhaps from \u0090acknowledgement of the word\u0091. Compare this with the line of\nShakespeare in the title of this box to judge how conventional prose stands up to machine translation in\ncomparison with poetry. Yet we can be sure that translation systems will improve: expect upgraded and\nextended corpora to allow more continuously successful translations with fewer untranslated or mangled\nwords. A panel of experts give their verdict on the current usefulness of machine translation on page 37..The standards and skills of\ncomputer software are already\nbetter than many people realize. \u0090It\nis frequently my experience that\nwhen demonstrating recent\nadvances in, say, speech or\ncharacter recognition, observers\nare surprised at the state of the art.\nFor example, a typical computer\nuser\u0091s last experience with speech-\nrecognition technology may have","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":139,"distracting_context":"sophisticated problems.  \nYou can get away without doing any machine learning by doing quite complicated regular  \nexpressions, and that will match quite a lot of tasks. However, for harder tasks we do need to use \nmachine learning classifiers. But even then, regular expressions can be used for pre- processing \nthe data, or possibly for capturing the features that we want in the classifiers, or for capturing \ngeneralizations, even if you want to do machine learning. And this is before deciding whether you \nwant to do deep- learning, or traditional, sort of simple machine learning.  \nOK. So that's enough on regular expressions.  Except let's have a look at some examples. And we \nwant to have a look at some examples of substitutions is one more regular expression that's often \navailable in Python and Unix commands, that is having got a regular expression, you want to \nsubstitute it w ith something else.","topic":"Others"}}
{"id":"5d839b65-8ef3-4ada-933c-7d45570ba4c6","question":"Considering the potential error-prone nature of language machines, what could be the benefits for the UK in pursuing this technology, specifically in the context of language education?","reference_answer":"Pursuing the language machine brings benefits and opportunities to the UK at every level \u0097 from competitiveness in markets across the world and collaboration with European-based agencies and researchers, to the practical, everyday situations in the home, service industry, office, and school. EUROMAP suggests several potential markets \u0097 authoring tools as part of office automation and document management systems; speaker identification and authentication, speech recognition and synthesis embedded in call centres and built into the telecommunications infrastructure for voice messaging and voice delivery of email; information extraction embedded in knowledge management systems; semantic analysis in information retrieval services (including Web search engines); machine translation services supporting any workplace.","reference_context":"Document 99: universities and funding\nagencies seek to support\nresearch activities here \u0097 these\nareas may also indicate the\ntype of potential uses for the\nlanguage machine that we can\nexpect to emerge in the  office\nworkplace of the future.Can the\nlanguage machine\nreally help people to\ncommunicate?\nSee page 19SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 42: Contents\nThe language machine 6\nResearch labs to desk-tops 14\nTurning theory into practice 18\nThe problems with machines 28UK advantage? 38Real-life situations 44\nFuture scenarios 50\nGlossary 58References 60Questions for debate 64This season\u0091s\nmust-have: thewristwatch translatorSee page 53\nLanguage machines\nhelping withdisabilities See page 54What are the benefits\nto the UK of makingthe language machinework? See page 43SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 185: One of the key questions many will ask, is how will these\nlanguage machine projects benefit people in the UK? .the language machine\n43\nWhat are the benefits to the UK?\nPursuing the language machine brings benefits and opportunities to the UK at every level \u0097 from\ncompetitiveness in markets across the world and collaboration with European-based agencies and\nresearchers, to the practical, everyday situations in the home, service industry, office, and school. \nEUROMAP suggests several potential markets \u0097 authoring tools as part of office automation and document\nmanagement systems; speaker identification and authentication, speech recognition and synthesis\nembedded in call centres and built into the telecommunications infrastructure for voice messaging and voice\ndelivery of email; information extraction embedded in knowledge management systems; semantic analysis in\ninformation retrieval services (including Web search engines); machine translation services supporting\n\nDocument 96: any workplace \u0097 so expect to see\nlanguage machines built into off-\nthe-shelf word processors and\nsoftware. Some professions are\nalready using the technology:\npublishers have employed speech\nand language techniques to help\nbuild language teaching\ndictionaries and textbooks.\n.Industrial uses?  Manufacturers\nand suppliers of language\nmachines can find a route to\nmarket through companies looking\nto embed speech and language\ntechnology in third-party products\nor services. The UK DTI is a point\nof information and support.SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":99,"distracting_context":"range of sources rather than following a single textbook \u0097\nmay, in ten or 20 years from now, just as naturally select\nand combine speech and language technology materials\ninto class material to create their own personal \u0090look and\nfeel\u0091. \nScenario 4\nNo aspect of language professions is immune\nAll areas of the language professions are likely to beaffected to a greater or lesser degree. Language teachers\nhave a particular right to be wary of any error-prone\ntechnology: although language teaching may not be as\nimmediately safety-critical as air traffic control, a language\nmachine that cannot fully discriminate when dealing with\nlanguage will probably be widely judged as an unhelpful\nteaching aid. \nThis issue is crucial in speech and language systems that\naim to detect and diagnose errors in learners\u0091 language\nproduction. One standard solution is for the system to\nassess its \u0090confidence\u0091 in an error: a pronunciation error is\npointed out to the learner only if the system has a high","topic":"Language Machine Translation"}}
{"id":"1dbd3d02-944a-4017-b34c-39192622f9f7","question":"Can you provide some examples of African American English variations used in Twitter posts, especially those that reflect the influence of regional language varieties?","reference_answer":"Twitter posts might use features often used by speakers of African American English, such as constructions like 'iont' (I don\u2019t in Mainstream American English (MAE)), or 'talmbout' corresponding to MAE 'talking about'.","reference_context":"Document 387: (Chinese, Spanish, Japanese, German etc.), but we don\u2019t want to limit tools to just\nthese few languages. Furthermore, most languages also have multiple varieties, of-\nten spoken in different regions or by different social groups. Thus, for example,\nif we\u2019re processing text that uses features of African American English ( AAE ) or AAE\nAfrican American Vernacular English (AA VE) \u2014 the variations of English used by\nmillions of people in African American communities (King 2020) \u2014 we must use\nNLP tools that function with features of those varieties. Twitter posts might use fea-\ntures often used by speakers of African American English, such as constructions like\niont(I don\u2019t in Mainstream American English ( MAE )), or talmbout corresponding MAE\nto MAE talking about , both examples that in\ufb02uence word segmentation (Blodgett\net al. 2016, Jones 2015).\nIt\u2019s also quite common for speakers or writers to use multiple languages in a","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":387,"distracting_context":"be at ease in English, this may be a major advantage. A disadvantage of developing\nsoftware afresh is that the software will be new: it is likely to be less robust, withless functionality, than mature systems. The funding will end and then it will be\nhard to maintain. Growing numbers of corpus developers are taking the route of\nmaking their corpus available in the Sketch Engine.\n27\n7.2.1 Corpus websites for multiple languages\nMark Davies\u2019s website at Brigham Young University28offers corpora for English,\nSpanish and Portuguese. The resources for English are outstanding, supporting theexploration of the behaviour of words and phrases across time, genre, and regionalvarieties (Davies 2009 ). The system is fast and reliable.\nUwe Quasthoff and colleagues in Leipzig have crawled the web for corpora of\n229 languages and made them searchable at their Worschatz website (Quasthoffet al. 2006 ).\n29The website is in German. Within Germany, this is a very widely used","topic":"Others"}}
{"id":"d9084f0d-5b41-4104-b32a-a911d5ea1d71","question":"In the context of the Sketch Engine which has functionalities like domain corpus, reference corpus, grammar for terms, lemmatiser, part-of-speech tagger, and parser, what is the two-step process to compute the alignment path in the minimum edit distance algorithm?","reference_answer":"The computation proceeds in two steps. In the first step, the minimum edit distance algorithm is augmented to store backpointers in each cell. The backpointer from a cell points to the previous cell (or cells) that we came from in entering the current cell. In the second step, a backtrace is performed. In a backtrace, we start from the last cell (at the final row and column), and follow the pointers back through the dynamic programming matrix. Each complete path between the final cell and the initial cell is a minimum distance alignment.","reference_context":"Document 435: 2.6 \u2022 S UMMARY 25\nFigure 2.19 also shows the intuition of how to compute this alignment path. The\ncomputation proceeds in two steps. In the \ufb01rst step, we augment the minimum edit\ndistance algorithm to store backpointers in each cell. The backpointer from a cell\npoints to the previous cell (or cells) that we came from in entering the current cell.\nWe\u2019ve shown a schematic of these backpointers in Fig. 2.19. Some cells have mul-\ntiple backpointers because the minimum extension could have come from multiple\nprevious cells. In the second step, we perform a backtrace . In a backtrace, we start backtrace\nfrom the last cell (at the \ufb01nal row and column), and follow the pointers back through\nthe dynamic programming matrix. Each complete path between the \ufb01nal cell and the\ninitial cell is a minimum distance alignment. Exercise 2.7 asks you to modify the\nminimum edit distance algorithm to store the pointers and compute the backtrace to\noutput an alignment.\n# e x e c u t i o n\n# 0\u21901\u21902\u21903\u21904\u21905\u21906\u21907\u21908\u21909\n\nDocument 436: minimum edit distance algorithm to store the pointers and compute the backtrace to\noutput an alignment.\n# e x e c u t i o n\n# 0\u21901\u21902\u21903\u21904\u21905\u21906\u21907\u21908\u21909\ni\u21911\u2196\u2190\u2191 2\u2196\u2190\u2191 3\u2196\u2190\u2191 4\u2196\u2190\u2191 5\u2196\u2190\u2191 6\u2196\u2190\u2191 7\u21966\u21907\u21908\nn\u21912\u2196\u2190\u2191 3\u2196\u2190\u2191 4\u2196\u2190\u2191 5\u2196\u2190\u2191 6\u2196\u2190\u2191 7\u2196\u2190\u2191 8\u21917\u2196\u2190\u2191 8\u21967\nt\u21913\u2196\u2190\u2191 4\u2196\u2190\u2191 5\u2196\u2190\u2191 6\u2196\u2190\u2191 7\u2196\u2190\u2191 8\u21967\u2190\u21918\u2196\u2190\u2191 9\u21918\ne\u21914\u21963\u21904\u2196\u21905\u21906\u21907\u2190\u21918\u2196\u2190\u2191 9\u2196\u2190\u2191 10\u21919\nn\u21915\u21914\u2196\u2190\u2191 5\u2196\u2190\u2191 6\u2196\u2190\u2191 7\u2196\u2190\u2191 8\u2196\u2190\u2191 9\u2196\u2190\u2191 10\u2196\u2190\u2191 11\u2196\u219110\nt\u21916\u21915\u2196\u2190\u2191 6\u2196\u2190\u2191 7\u2196\u2190\u2191 8\u2196\u2190\u2191 9\u21968\u21909\u219010\u2190\u219111\ni\u21917\u21916\u2196\u2190\u2191 7\u2196\u2190\u2191 8\u2196\u2190\u2191 9\u2196\u2190\u2191 10\u21919\u21968\u21909\u219010\no\u21918\u21917\u2196\u2190\u2191 8\u2196\u2190\u2191 9\u2196\u2190\u2191 10\u2196\u2190\u2191 11\u219110\u21919\u21968\u21909\nn\u21919\u21918\u2196\u2190\u2191 9\u2196\u2190\u2191 10\u2196\u2190\u2191 11\u2196\u2190\u2191 12\u219111\u219110\u21919\u21968\nFigure 2.19 When entering a value in each cell, we mark which of the three neighboring\ncells we came from with up to three arrows. After the table is full we compute an alignment\n(minimum edit path) by using a backtrace , starting at the 8in the lower-right corner and\nfollowing the arrows back. The sequence of bold cells represents one possible minimum cost\nalignment between the two strings. Diagram design after Gus\ufb01eld (1997).","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":435,"distracting_context":"\u25cfa domain corpus\n\u25cfa reference corpus\n\u25cfa grammar for terms\n\u25cfa lemmatiser, part-of-speech tagger, and parser (to \ufb01nd linguistic units with the\ngrammatical shape that makes it possible for them to be terms)\n\u25cfa statistic (to identify the term candidates that are most distinctive of the domain\nin contrast to the reference material).\nThe Sketch Engine has most of these pieces in place. Users can upload their domain\ncorpus, or build one using WebBootCaT. Reference corpora are available for 60\nlanguages. There are already grammars for the word sketches, which can be adapted toprovide term grammars. The parsing machinery is in place, and, as discussed above, for agrowing number of languages, language-speci\ufb01c processing tools are installed and readyto use. The statistic used to identify keywords is also suitable for identifying terms.\nTerm-\ufb01nding functionality is now available in the Sketch Engine, as illustrated in\nFig. 19, for ten languages.\n6.6 Localisation","topic":"Minimum Edit Distance Algorithm"}}
{"id":"07994819-86bb-43a3-b7a0-8ee991c3bbc6","question":"Considering the concept of minimum edit distance in string similarity, what is the joint institute of UK and Ireland that requires the least number of character transformations from 'Foras na Gaeilge'?","reference_answer":"Foras na Gaeilge is a joint institute of both UK and Ireland.","reference_context":"Document 507: is part of the UK) and Foras na Gaeilge is a joint institute of both countries.Lexicography ASIALEX (2014) 1:7\u201336 15\n123","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":507,"distracting_context":"seems like useful evidence for deciding that they might be coreferent.\nEdit distance gives us a way to quantify both of these intuitions about string sim-\nilarity. More formally, the minimum edit distance between two strings is de\ufb01nedminimum edit\ndistance\nas the minimum number of editing operations (operations like insertion, deletion,\nsubstitution) needed to transform one string into another.\nThe gap between intention andexecution , for example, is 5 (delete an i, substi-\ntuteeforn, substitute xfort, insertc, substitute uforn). It\u2019s much easier to see\nthis by looking at the most important visualization for string distances, an alignment alignment\nbetween the two strings, shown in Fig. 2.14. Given two sequences, an alignment is\na correspondence between substrings of the two sequences. Thus, we say Ialigns\nwith the empty string, NwithE, and so on. Beneath the aligned strings is another\nrepresentation; a series of symbols expressing an operation list for converting the","topic":"Others"}}
{"id":"37017008-ade9-4324-989c-6d77ada4d0f7","question":"What was a primary request from language educators during the Project ISLE user consultation exercise, considering their preference for human interaction over machine-based tutoring?","reference_answer":"One of the main requests of language teachers was for a 'conversation practice machine': a computer system with which a learner could 'chat' in ordinary spoken English to practise everyday conversational skills.","reference_context":"Document 150: what they would use. the technology for: the Project ISLE\nuser consultation exercise described on page 30 is the\nexception rather than the rule. One of the main requests of\nlanguage teachers was for a \u0090conversation practice\nmachine\u0091: a computer system with which a learner could\n\u0090chat\u0091 in ordinary spoken English to practise everyday\nconversational skills. Unfortunately \u0097 as speech recognisers\nare not accurate or robust enough to cope with general\nunconstrained dialogue and conversational skills,\nparticularly where the unconstrained dialogue comes fromexpensive\n34and useless?\nConversing with\nyour computer?\nSee pages 23 & 24\nTower of Babel? Or Cubicle of Babble?\nOne potential scenario for the language machine is that it will become part of our everyday interactions with\nmany kinds of equipment \u0097 from PCs to wristwatches. What will this mean for the office? The open plan office\nis a design that many people find distractingly noisy \u0097 sound barriers are already becoming more common \u0097","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":150,"distracting_context":"example, may prefer human interaction: even when\nlanguage machine-based software offers comprehensive\nEnglish language self-tutoring facilities, many students will\nprefer a class led by a human teacher: teachers, after all,\ncan offer what machines cannot \u0097 wit, warmth and empathy\n\u0097 as part of a learning experience.\nLikewise, human dependency on machines can appear\ncold in social situations. In international communication, for\nexample, particularly in face-to-face meetings, a reliance on\na machine shows an unwillingness to learn to converse\neven at a basic level in more than one language \u0097 and may\nbe judged adversely in terms of an individual\u0091s\nsocialisation, diplomatic skills and hospitality.\nPeople offer quantity \u0097 and quality  As stated elsewhere in\nthis book, the language machine is far from perfect: it is\ndifficult to believe that its overall command of English will\nmatch (let alone exceed) that of an advanced learner of\nEnglish, even in 20 years\u0091 time. Translators and teachers \u0097","topic":"Language Machine Development"}}
{"id":"69db490c-9399-475a-8e11-7a3c7fc46dfc","question":"What are the potential future scenarios mentioned in the text, specifically those that involve significant technological advancements or disasters?","reference_answer":"The potential future scenarios mentioned are: life expectancy approaches 100, nanotechnology takes off, no-carbon economy worldwide, rise of an American dictator, self-aware machine intelligence, time travel invented, major technology accident, asteroid hits earth, social breakdown in US or Europe, and a whole generation unable to effectively read, write, think or work.","reference_context":"Document 74: ? Life expectancy approaches 100\n? Nanotechnology takes off\n? No-carbon economy worldwide\n? Rise of an American dictator\n? Self-aware machine intelligence\n? Time travel invented\n? Major technology accident\n? Asteroid hits earth\n? Social breakdown in US or Europe\n? Whole generation unable to\neffectively read, write, think or work \nWeb addresses \nfor Philips and BT?See page 63SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":74,"distracting_context":"different. So I'm showing you the generic one that's used for Unix.  \nYou can al so have ranges. Like open square brackets, a dash z, closed square brackets, matches \nanything in the range a to z, any uppercase letter. You can also do that for lowercase letters, or for \ndigits. A bit more complicatedly, you can have as well as disjunction, or, you can also have \nnegation, not.","topic":"Others"}}
{"id":"994554c0-b8ba-4bb8-bdfb-9a228ddaffff","question":"In the context of machine translation and speech recognition, who is the recommended citation reference for the book 'The Language Machine'?","reference_answer":"The recommended citation reference for the book 'The Language Machine' is Eric Atwell (1999).","reference_context":"Document 41: Copyright ' The British Council 1999\nAll rights reseved. No part of this publication may be\nreproduced, stored in a retrieval system or transmitted in\nany form or by any means, electronic, mechanical,\nphotocopying, recording, or otherwise, without the prior\npermission of the copyright holder.\nPublished by The British Council\nhttp:\/\/www.britishcouncil.org\n10 Spring Gardens\nLondon SW1A 2BN\nUnited Kingdom\nDigital book production by Catchline\nhttp:\/\/www.english.co.uk\nThe Catchline team:\nEditorial director: Margaret Keeton\nPublishing manager: Sjanoche Wakely\nDesign consultant: Carlton Larode\nOriginal cover design by Carlton Larode\nRecommended citation reference: Eric Atwell (1999) The\nLanguage Machine . London: British Council\nISBN 0 86355 439 3(This digital book is also available in conventional print\nformat ISBN 0 86355 438 5)production creditsSITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 42: Contents\nThe language machine 6\nResearch labs to desk-tops 14\nTurning theory into practice 18\nThe problems with machines 28UK advantage? 38Real-life situations 44\nFuture scenarios 50\nGlossary 58References 60Questions for debate 64This season\u0091s\nmust-have: thewristwatch translatorSee page 53\nLanguage machines\nhelping withdisabilities See page 54What are the benefits\nto the UK of makingthe language machinework? See page 43SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":41,"distracting_context":"Machine translation? Speech recognition?\nDo they work? 37\nUK advantage? The key-players 38\nA global interest 38What\u0091s happening in the UK? 39What do EU projects aim to do? 39\nUK-Europe overview 40UK involvement across Europe 40Case Study: Lernout and Hauspie 40\nFor translation, security, medicine \u0087 41The ten EU rules for language machinesin telematics 41\nSupply & demand: the markets 42How are people encouraged to buy? 42What are the benefits to the UK? 43\nReal-life situations 44\nIs there a typical \u0090user profile\u0091? 44Labs, factories, outdoors, offices, homes 45How are people using language machines? 45\nEmployment, society, leisure 46The art of translation. Or the translation of art? 47\nEducational resources 48Focus: language education & teaching 48Have a go? Language technology by email 48\nEducational projects in progress 49\nFuture scenarios: the impact 50","topic":"Others"}}
{"id":"49b03ee8-dead-4001-8e5e-16906da66115","question":"What is one of the primary objectives of language machine developers, considering the current limitations and constraints of these systems?","reference_answer":"Language machine developers have a common interest in using language to make communication between people and computers more 'natural'.","reference_context":"Document 87: learning . systems thus learn how to analyse and process\nnatural-language by being given examples of expected\ninput together with appropriate analyses (Charniak, 1993;\nAtwell, 1996).\nOffice and home  In some systems, voice has already\narrived at the desk-top: Apple Computer\u0091s recent operating\nsystems include English speech-to-text, which can read\nback screen-based text or \u0090alert\u0091 messages in 25 different\nvoices. While some users may struggle to find an\napplication for a talking computer, others \u0097 such as the\nvisually impaired \u0097 will find this technology beneficial.\nWhat of applications such as translation? To develop a\nmachine-translation system, a researcher could use a\ncorpus of English sentences and their French equivalents to\nderive an algorithm .for mapping from English to French.\nMachine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\n\nDocument 88: Machine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\nto plan and integrate the future use of language machines,\nwhether as a substitute for conventional human-to-human\ninteraction, or for the delivery of language teaching.the language machine\n17\n.Algorithms \u0087 Natural-language\nlearning \u0087 Hidden Markov Models\n\u0087 neural networks?\nSee Glossary, pages 58\u009759\nToo expensive\nto be useful? See page 28.English language teachers and\nlearners, according to a report on a\nsurvey of user requirements for\nthe ISLE project (ISLE, 1999)\ndesired, above all, a \u0090conversation\npractice machine\u0091 as an aid to\nlearning: with such a system a\nlearner could \u0090chat\u0091 in ordinary\nspoken English to practise every-\nday conversational language skills.\n.Natural-language learning\nsystems often use sophisticated\nstatistical pattern-matching models\n(for example Hidden Markov\n\nDocument 92: the dictionary itself could be subsequently incorporated\ninto a language processing system.\nAssisting natural communication between people and\ncomputers Language machine developers have a common\ninterest in using language to make communication between\npeople and computers more \u0090natural\u0091. \nWith a natural-language spoken dialogue system, for\nexample, people can access information on a computerTurning theory\n18into practice\nWhy do researchers\ndedicate lifetimes?\nWhy do universities\nwork to provide\nresources? Why do\nfunding agencies\nsupport speech and\nlanguage projects?\nThis section looks at\nwhat the language\nmachine aims to do,\nand how researchers\nare trying to get\nthere.SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 146: \u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic\ncapabilities sufficiently advanced to pass the Turing Test\n(pages 10, 24). To yield useable results, people need\ntraining and time to learn the constraints and limitations of\na particular system. Furthermore, a language machine is\nlikely to be one component in a much larger IT system:\npeople need time to develop an understanding of how the\nlanguage machine fits into the overall system. \nIn learning to use speech recognition, for example, a\nspeaker must plan ahead and enunciate clearly, and learn\n(or re-learn) how to use software using their voice rather\nthan a mouse and keyboard. \nMany of today\u0091s computer-literate professionals are now\ncomfortable with a mouse and keyboard; to these users,\nspeech is not as self-evidently more \u0090natural\u0091 as it might\nhave appeared to a previous generation less familiar with","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":87,"distracting_context":"\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic\ncapabilities sufficiently advanced to pass the Turing Test\n(pages 10, 24). To yield useable results, people need\ntraining and time to learn the constraints and limitations of\na particular system. Furthermore, a language machine is\nlikely to be one component in a much larger IT system:\npeople need time to develop an understanding of how the\nlanguage machine fits into the overall system. \nIn learning to use speech recognition, for example, a\nspeaker must plan ahead and enunciate clearly, and learn\n(or re-learn) how to use software using their voice rather\nthan a mouse and keyboard. \nMany of today\u0091s computer-literate professionals are now\ncomfortable with a mouse and keyboard; to these users,\nspeech is not as self-evidently more \u0090natural\u0091 as it might\nhave appeared to a previous generation less familiar with","topic":"Artificial Intelligence in Language Learning"}}
{"id":"d5a3f462-0426-4dd9-90f0-a2534c7f16dc","question":"In the context of text normalization, how does the BYTE-PAIR ENCODING function operate to merge tokens and create a new vocabulary, particularly when dealing with a corpus that has been transformed into CQL queries?","reference_answer":"The BYTE-PAIR ENCODING function in text normalization takes a corpus broken up into individual characters or bytes, and learns a vocabulary by iteratively merging tokens. It starts with all unique characters in the corpus as the initial set of tokens. It then merges the most frequent pair of adjacent tokens in the corpus, creating a new token by concatenating them. This new token is added to the vocabulary, and each occurrence of the merged tokens in the corpus is replaced with the new token. This process is repeated for a specified number of merges.","reference_context":"Document 412: 2.4 \u2022 T EXT NORMALIZATION 19\nfunction BYTE-PAIR ENCODING (strings C, number of merges k)returns vocab V\nV\u2190all unique characters in C # initial set of tokens is characters\nfori= 1tokdo # merge tokens til ktimes\ntL,tR\u2190Most frequent pair of adjacent tokens in C\ntNEW\u2190tL+tR # make new token by concatenating\nV\u2190V+tNEW # update the vocabulary\nReplace each occurrence of tL,tRinCwith tNEW # and update the corpus\nreturn V\nFigure 2.13 The token learner part of the BPE algorithm for taking a corpus broken up\ninto individual characters or bytes, and learning a vocabulary by iteratively merging tokens.\nFigure adapted from Bostrom and Durrett (2020).\nfrom the training data, greedily, in the order we learned them. (Thus the frequencies\nin the test data don\u2019t play a role, just the frequencies in the training data). So \ufb01rst\nwe segment each test sentence word into characters. Then we apply the \ufb01rst rule:\nreplace every instance of e r in the test corpus with er, and then the second rule:","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":412,"distracting_context":"automatically transformed into CQL queries which are then evaluated by the\nunderlying database engine to obtain the results from the corpus.7\nLexicographers often want to home in on a particular pattern of use to explore it\nfurther. This can be done with the Context options, as in Fig. 6.\nTo \ufb01nd all instances of catch that have pant orpants within \ufb01ve words, we search\nforcatch with pant in as a lemma \ufb01lter, with results as shown in Fig. 7.\nFig. 5 Query types\nFig. 6 Context \ufb01lters\nFig. 7 Concordance for catch with context \ufb01lter pant (lemma) within \ufb01ve words leftorright\n7Most databases are based on relational modelling and queried using Structured Query Language (SQL).\nHowever, for text, the sequence of words is the central fact, not the relations, so it is debatable whetherSQL databases are suitable. The Sketch Engine is based on its own database management system calledManatee (Rychly \u00b42000 ,2007 ) devised speci\ufb01cally for corpus linguistics. The web-based front end of","topic":"Others"}}
{"id":"04060a8f-5f46-4a78-92cb-ad7cf7c19812","question":"Considering the future advancements in AI and human brain intelligence, why is the selection of a large corpus as the reference corpus crucial in data mining?","reference_answer":"Choosing a large corpus as your reference corpus is significant in data mining because smaller corpora may not provide statistically significant meanings. This is due to the fact that certain words might not occur very commonly or at all in a small corpus, leading to inaccurate or incomplete analysis.","reference_context":"Document 476: 2010s.  \nAnd we see that there are quite a few words like mining, funny words like doi. Well, what do these \nwords mean? Well, you have to figure it out. Disproportionality. I'm not quite sure t hese are \nparticularly data mining words. And you might want to look these up.  \nThese are probably words which occur not very commonly at all, even in the data mining corpus, \nbut they don't occur at all or maybe only one occurrence in the Brown corpus. So if  you're taking \nyour reference corpus, a small corpus, then you won't get a very good example. Statistically, not \nvery significant meanings. This is the reason for choosing a large corpus as your reference \ncorpus. But we've done this to make it work faster.  \nWhat about multi -word terms? Well, here, we're better. Data mining, data mine, adverse event, \nsafety report, text mining. So more of the multi -word terms. So typically, in a domain, in a","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":476,"distracting_context":"\u00a9 University of Leeds   9 of 10  even talk to the computer. You simply think and it would work. They even thought that you \nwouldn't have to learn anything. You wouldn't have to go to University to learn stuff. You simply \nplug- in and somehow we're learning via the thought interface. So you wouldn't even have to plug it \nin. You just have to think about things, and you know them somehow. Again, I don't think it's going \nto happen by 2025. They certainly thought by 2030, human brain intelligence would be enhanced \nby just linking it to AI. Maybe. I don't know.  \nThe book finishes with some examples of real applications. For example, soldiers in Bosnia and \nthat shows you the years in the 1990s, the war in Bosnia was a big thing. There were British \nsoldiers and other soldiers from other countries there. The soldiers in Bosnia wear a small \ncomputer on their chests, and say to it hands up, or get out of the car, or other things that soldiers","topic":"Corpus Linguistics Software"}}
{"id":"e52349fd-9621-4584-be58-90a3ebbe132e","question":"What significant transformations have taken place in the dictionary industry over the years, particularly in the context of the shift from paper to electronic dictionaries and the rise of language technology?","reference_answer":"The dictionary industry has seen the emergence of new ecosystems of dictionaries on the web with new players like Google, weblio.jp, dictionary.com, Leo, Wordnik.com. Previously, the dominant players were Longman, Kenkyusha, OUP, Le Robert, Duden, Merriam-Webster who had been around for decades or even centuries. There has also been a shift in the way people look up words, from paper to electronic between 1994\u20132004, and from computer to phone between 2004\u20132014. This has made dictionaries far more available and accessible, leading to a rise in the number of dictionary lookups, despite many dictionary companies seeing their income collapse.","reference_context":"Document 486: emergence of entire new ecosystems of dictionaries on the web, with many new\nplayers (Google, weblio.jp, dictionary.com, Leo, Wordnik.com). Previously, thedominant players had been around for decades, even centuries\u2014Longman (who\npublished Johnson\u2019s dictionary in 1754), Kenkyusha, OUP, Le Robert, Duden,\nMerriam-Webster.\nIn the world at large, we have seen the invention and world takeover of the\nsmartphone. 1994\u20132004 saw the switch of most dictionary lookups from paper toelectronic: 2004\u20132014 has seen them nearly all (in percentage terms) switch fromcomputer to phone. (Just think how often your students look up words on theirphones, versus how often they look them up in any other way.) Dictionaries are far,far more available and accessible than they were. The sheer number of dictionary\nlookups has risen many times over (even as\u2014bitter irony\u2014many dictionary\ncompanies have seen their income collapse).\nThis is all at the publishing end of the dictionary business. What about the","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":486,"distracting_context":"yourself greeted in your own language or dialect \u0087 pick\nup a phone and talk to Chaucer \/Shakespeare \/Churchill.educational\n48resources\nHave a go? Language\ntechnology by email\nAdd a twist to a language class:\nemail English text to:\namalgam-tagger@scs.leeds.ac.uk\nYou\u0091ll receive back the same text,\nwith each word annotated with\nthe \u0090parts of speech\u0091. The\nfollowing sentence was emailed,\nand the parts of speech returned:\nRemote access over the Internet,\nvia WWW or email is an\nincreasingly popular alternative.\nRemote  \u0097adjective\naccess \u0097noun, singular, common\nover \u0097preposition\nthe \u0097article, singular or plural\nInternet \u0097noun, singular, proper\n, \u0097comma\nvia \u0097preposition\nWWW \u0097noun, singular, proper\nor \u0097conjunction, coordinating\nemail \u0097noun, singular, common \nis \u0097verb \u0090to be\u0091, \npresent tense\n3rd person singular\nan \u0097article, singular\nincreasingly \u0097adverb\npopular \u0097adjective\nalternative \u0097noun \nsingular, common\n. \u0097full stop\nThe text is annotated according to","topic":"Corpus Linguistics and Lexicography"}}
{"id":"fca62cec-f082-4af7-aebb-7e3fba56cdf7","question":"Considering the European Commission's extensive use of machine translation techniques since 1976, what could be the potential challenges or issues with using these language machines for language learning?","reference_answer":"Current language machines might not accurately detect and diagnose errors in learners' language production. For example, a learner could say something reasonable and be corrected, say something wrong and not be corrected, or say something wrong, be told it is wrong, but be given an inappropriate diagnosis or correction. This could be harmful to a new language learner's progress.","reference_context":"Document 219: production. One standard solution is for the system to\nassess its \u0090confidence\u0091 in an error: a pronunciation error is\npointed out to the learner only if the system has a high\ndegree of confidence that an error has actually occurred.\nAlthough this strategy tends to stop the error-diagnosis\nsystem giving incorrect advice, it also means that some\ngenuine errors go uncorrected. \nBut is this so different from real \u0097 human \u0097 teaching\npractice? Teachers do not correct every imperfection in\nlearners\u0091 English, but instead focus on specific weaknesses\nand\/or language features of the day\u0091s lesson. Viewed in this\nway, it is hard to identify any aspect of language teaching\nwhere the language machine would be entirely\ninappropriate. \nScenario 5\nLanguage professions will adapt to make use of\nthe language machine \nLanguage teachers, like many professionals, have a natural\nwariness of change for change\u0091s sake, and of new teachingimplications\n52the professions\nRethinking our\n\nDocument 218: range of sources rather than following a single textbook \u0097\nmay, in ten or 20 years from now, just as naturally select\nand combine speech and language technology materials\ninto class material to create their own personal \u0090look and\nfeel\u0091. \nScenario 4\nNo aspect of language professions is immune\nAll areas of the language professions are likely to beaffected to a greater or lesser degree. Language teachers\nhave a particular right to be wary of any error-prone\ntechnology: although language teaching may not be as\nimmediately safety-critical as air traffic control, a language\nmachine that cannot fully discriminate when dealing with\nlanguage will probably be widely judged as an unhelpful\nteaching aid. \nThis issue is crucial in speech and language systems that\naim to detect and diagnose errors in learners\u0091 language\nproduction. One standard solution is for the system to\nassess its \u0090confidence\u0091 in an error: a pronunciation error is\npointed out to the learner only if the system has a high\n\nDocument 153: inexpert speakers \u0097 the current project has been forced to\nfocus on pronunciation tutoring. English language\nteachers . also wanted the ability to correct errors in\nlearners\u0091 conversations and give guidance on their causes.\nOur current language machines are not up to this task; in\nfact, we need to debate whether it is appropriate \u0097 or\nperhaps whether it is dangerous \u0097 to use today\u0091s tech-\nnology in this way. With the current levels of performance\nfrom language machines, it is quite likely that the learner\ncould say something quite reasonable to the system and be\ncorrected; say something wrong and not be corrected; or\n(perhaps worst of all) say something wrong, be told it is\nwrong, but be given an inappropriate diagnosis or\ncorrection. This may not be as critical as the confusion of\n\u0090descend to a hundred feet\u0091 with \u0090descend 200 feet\u0091 in an air\ntraffic control system (see page 32), but it could be harmful\nto a new language learner\u0091s progress \u0097 and it would almost\n\nDocument 145: professions. For example, language teachers who wish to\nuse CALL software incorporating speech recognition tech-\nnology may need to rethink approaches, and decide which\naspects of learning could be achieved more successfully by\nthe individual using the technology alone, and which\nlearning should remain within the classroom as a shared,\ngroup activity. Similarly, whole-school policies \u0097 of funding\nnew equipment, providing new learning spaces, and\nmanaging the politics of departmental resourcing \u0097 may\nneed to come under similar scrutiny if language machine\ntechnology is to be used more widely and successfuly in\neducation. \nProblem 6\nNewcomers need training and time to learn to\nuse the language machine \nOne supposed strength of the language machine is that\ncommunicating with a computer in spoken English is\n\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":219,"distracting_context":"bundle of techniques that may have worked in\npractice but were not theoretically well founded.\nThe EU, however, decided it was better to have an\ninelegant system that worked than an elegant one\nthat didn\u0091t.\u0087 with no clear solution?\nThe translation demands for the EuropeanCommission are huge \u0097 the translation department,\nbased in Luxembourg, now employs nearly 2000\nstaff. Not surprisingly, the centre continues to seek\ntranslation methods such as voice activation tech-\nniques, to take it into the future, with varying\ndegrees of success:\n\u0090The Commission has been developing machine\ntranslation techniques since 1976, and it now\noperates a machine translation procedure called\nEC\/Systran, based on the product developed by\nSystran. \u0094Any official in any of the European\ninstitutions can send his or her text for translation\nto this system by e-mail,\u0095 explains Mr. Theologitis.\n\u0094Turnaround time for any document, virtually\nregardless of length, is around ten minutes.\u0095\u0091 Voice","topic":"Others"}}
{"id":"4054a0ab-8135-4e90-9f9b-4dbd87990223","question":"Can you specify the current research interest at Leeds University in the field of Data Mining and Text Analytics as mentioned in the provided context?","reference_answer":"The current research interest at Leeds University is chat bot and text analytics for University education, such as teaching students.","reference_context":"Document 3: much bigger data sets.  \nUnit four, look at some examples of text analytics, in particular text analytics for machine \ntranslation and for information extraction. Having looked at Weka before and sketch engine as tool \nkits, you also look at some Python bits of program and tools for text analytics. Then we go on to a \ncurrent research interest at Leeds University is chat bot and text analytics for University education, \nand such as teaching students. And then finally unit six, look at some current research in text \nanalytics, and in particular BERT, a system developed by Google research labs. And there are","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":3,"distracting_context":"School of Computing: Assessment brief    Module title Data Mining Module code COMP2121 Assignment title Assessment for COMP2121 Data Mining, Semester 2 2022\/23 Assignment type and description Assessment 1: Test1 submitted as Minerva MCQ Test, 20% weight, 1 hour to complete, release week4 10:00 Wednesday 22.2.23, deadline 10:00 Thursday 23.2.23   Assessment 2: Test2 submitted as Minerva MCQ Test, 20% weight, 1 hour to complete, release week8 10:00 Wednesday 22.3.23, deadline 10:00 Thursday 23.3.23   Assessment 3: Report on team project, submitted by team leader as Minerva Assignment, 60% weight, approx 10 hours per student to complete, release week4 Wednesday 22.2.23, deadline week10 10:00 Thursday 4.5.23 Rationale Summative assessment of student knowledge and understanding of the module syllabus. Word limit and guidance Test1: 20 questions. Test2: 20 questions. Report: up to 12 pages Weighting Test1: 20% Test2: 20%. Report: 60% Submission deadline Test1: 10:00 Thursday 23.2.23 Test2:","topic":"Text Analytics and Data Mining"}}
{"id":"6560e224-6c21-4b36-8b17-83060064735b","question":"Considering the potential of language machines in the context of string operations such as deletion, substitution, and insertion, what could be their impact on language teaching and learning?","reference_answer":"The language machine has the potential to become a normal component in personal computing, widely adopted by new generations. It can allow students to learn some aspects of language outside the classroom. However, despite the comprehensive self-tutoring facilities it might offer, many students may still prefer human interaction. The boundary between tasks that can be delegated to the computer and those that should be done only with a human language teacher will shift as language technology improves.","reference_context":"Document 44: Preface\nHow will computers be used for language learning in 2020?\nWill we still be learning languages at all? This book goes\nsome way towards answering those questions.\nPotentially, computers let you choose your own speed of\nlearning, your own method, and your own vocabulary to\nreflect your own interests. The concept of \u0090the classroom\u0091,\nwhere learning takes place in groups for economic reasons,\nis itself under threat. The success of individual computer-\nbased learning in subjects such as maths and physics has\nalready proved that.\nBut isn\u0091t language a social skill? Language, yes.\nLanguage learning, not necessarily. Teachers may soon be\nable to concentrate on productive tasks, while the donkey\nwork of practice takes place between individuals and their\ncomputers.\nSo language use will never be replaced by machines?\nWe can\u0091t be sure of that either. This book shows how close\nwe are to Douglas Adams\u0091 babelfish becoming reality.\nThere is no point in suggesting that diplomats will never\n\nDocument 157: Can problems be overcome?\nTaking a typical application \u0097 language teaching and\nlearning \u0097 can we imagine that the problems described in\nthis section will be overcome?\nClearly, full integration of the language machine is not\nforseeable in the immediate future. At the very least,\nlearners and teachers need to use computers confidently in\neveryday learning contexts. And, in its current state, the\nlanguage machine is not yet appropriate as a replacement\nfor some of the tasks undertaken by the language teacher. .\nYet as language technology improves, the boundary\nbetween tasks that can be delegated to the computer and\nthose that should be done only with a human language\nteacher will shift. The advent of widescale personal\ncomputing may also have an impact in terms of allowing\nstudents to use language machines to learn some aspects\nof language outside the classroom. It is likely that new\nways of teaching using computers will also spill into\nlanguage teaching from other areas of education.\n\nDocument 226: Having misgivings? \nClearly, there is great potential for the language machine to\nbecome a normal component in the personal computing\n\u0090kit\u0091 that is now so easily and widely adopted \u0097 and\nexpected \u0097 by new generations.\nBut along with such easy adoption of new technology lie\nold fears \u0097 will machines replace humans? With the\nlanguage machine to assist them, who will want to learn\nlanguages or use the services of a human interpreter or\ntranslator? Even if large numbers of people want to learn\nEnglish for example, will their human teachers be replaced\nby language machine based self-tutoring software?\nLearners prefer the human touch  Even if we can afford the\nlanguage machines of the future, that does not mean we\nwill necessarily choose to use them. Language students, for\nexample, may prefer human interaction: even when\nlanguage machine-based software offers comprehensive\nEnglish language self-tutoring facilities, many students will","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":44,"distracting_context":"with the empty string, NwithE, and so on. Beneath the aligned strings is another\nrepresentation; a series of symbols expressing an operation list for converting the\ntop string into the bottom string: dfor deletion, sfor substitution, ifor insertion.","topic":"Language Machine Development"}}
{"id":"c38e6661-7b2f-4843-86e5-0ef6bfe1a758","question":"Considering the historical context of speech synthesis and machine language projects in the UK, what are the potential markets for these technologies in the country?","reference_answer":"EUROMAP suggests several potential markets for language machine projects in the UK such as authoring tools as part of office automation and document management systems; speaker identification and authentication, speech recognition and synthesis embedded in call centres and built into the telecommunications infrastructure for voice messaging and voice delivery of email; information extraction embedded in knowledge management systems; semantic analysis in information retrieval services (including Web search engines); machine translation services.","reference_context":"Document 184: Engineering Standards), MATE (Multi-level Annotation\nTools Engineering), ELSE (Evaluation in Language and\nSpeech Engineering) and DIET (Diagnostic and Evaluation\nTools for Natural Language Applications) are developing\nstandards and guidelines for the development and\nevaluation of language engineering resources and systems.\nPAROLE (Preparatory Action for linguistic Resources\nOrganisation for Language Engineering), EUROWORDNET\n(Building a multilingual wordnet database with semantic\nrelations between words), SIMPLE (Semantic Information\nfor Multifunctional Plurilingual Lexica) and SPEECHDAT\n(Speech Databases for Creation of Voice Driven Teles-\nervices) are gathering corpora of text, speech, and dic-\ntionaries across the range of EU languages, to be re-used in\nEuropean language engineering research and products.\nOne of the key questions many will ask, is how will these\nlanguage machine projects benefit people in the UK? .the language machine\n43\nWhat are the benefits to the UK?\n\nDocument 185: One of the key questions many will ask, is how will these\nlanguage machine projects benefit people in the UK? .the language machine\n43\nWhat are the benefits to the UK?\nPursuing the language machine brings benefits and opportunities to the UK at every level \u0097 from\ncompetitiveness in markets across the world and collaboration with European-based agencies and\nresearchers, to the practical, everyday situations in the home, service industry, office, and school. \nEUROMAP suggests several potential markets \u0097 authoring tools as part of office automation and document\nmanagement systems; speaker identification and authentication, speech recognition and synthesis\nembedded in call centres and built into the telecommunications infrastructure for voice messaging and voice\ndelivery of email; information extraction embedded in knowledge management systems; semantic analysis in\ninformation retrieval services (including Web search engines); machine translation services supporting\n\nDocument 265: the language machine\n63\nLanguage Resources Projects\nEUROWORDNET (Building a multilingual wordnet database with semantic relations between words): http:\/\/www.linglink.lu\/le\/projects\/eurowordnetPAROLE (Preparatory Action for linguistic Resources Organisation for Language Engineering):http:\/\/www.linglink.lu\/le\/projects\/le-paroleSIMPLE (Semantic Information for Multifunctional Plurilingual Lexica):http:\/\/www.linglink.lu\/le\/projects\/simpleSPEECHDAT (Speech Databases for Creation of Voice Driven Teleservices):http:\/\/www.linglink.lu\/le\/projects\/speechdat\nInfrastructure and Support Projects","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":184,"distracting_context":"fraud, powered by a chess-playing dwarf.\nSome years later the British scientist Charles Wheatstone\ncreated an improved model of the Kempelen machine,\nwhich was later to capture the imagination of Alexander\nGraham Bell \u0097 the inventor of the telephone. In 1863 Bell\nproduced his own \u0090talking head\u0091. The device could articulate\nthe sound \u0090mama\u0091 sufficiently clearly to cause a neighbour\nto enquire after the baby\u0091s welfare.\nPerhaps it is unclear whether these experiments and\ndevelopments belong to the realm of science, technology,\nmusic, magic, or public entertainment (Bell\u0091s brother\nMelville once took to the Edinburgh stage with a false beard\nand foreign accent to demonstrate one machine), but all\nthese early attempts at speech synthesis arose from\nattempts to reproduce the articulatory apparatus of a\nhuman vocal tract, using bellows and resonating chambers.\nIt was not until after World War II, when the science of\nacoustic analysis was more developed, that an alternative","topic":"Others"}}
{"id":"1d2d600a-e3b5-4b81-8bcb-61dc50f69e16","question":"In the context of a document that discusses language machines, syntax, and semantics, what does the pattern enclosed in brackets signify?","reference_answer":"The pattern in brackets signifies any sequence of digits from 0 to 9.","reference_context":"Document 304: So for example, the pattern at the bottom is in brackets, any -- the pattern in brackets is any \nsequence of 0 to 9, any sequence of digits, and we replace it with open angle bracket, whatever \nthe pattern was, followed by closed angle bracket. So that's a nice way of converting the 35 boxes \ninto the open square, open angle brackets, 35, close angle brackets, boxes.  \nWe may have more than one register if we have more than one pattern. So for example, the \npattern the, dot, star, er, which means that match anything followed by er, they something, dot,","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":304,"distracting_context":"languages, but also grammar, syntax  and semantics . \nA language machine is therefore a computer that is\ncapable, in one way or another, of extracting and acting on\nthe meaning of words.describing words\n8the technology\nIs it a language\nmachine?\nTo be called a language machine,\na language model must lie at the\nheart of a computer system,\nenabling natural language to be\nunderstood and processed in an\nintelligent way. The essential\ncomponents of a language\nmachine are outlined on page 20.\nPerhaps predictably, jargon and\nacronyms litter the field, making it\ndifficult for newcomers to find\ntheir way. To help, a glossary is\nincluded on pages 58\u009759, and for\nmore information, Web and book\nreferences are given on pages\n60\u009763.Imaginative ideas\nfrom the LinglinkReport to the EU\nSee page 7SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","topic":"Regular Expressions"}}
{"id":"5db0bc36-f107-46e1-818e-ec09b3219c58","question":"As a data mining student studying the relationship between text analytics and lexicography using Japanese words, I've stumbled upon a Turkish word 'y\u00fcrek'. Can you tell me what it translates to in English?","reference_answer":"The Turkish word 'y\u00fcrek' translates to 'heart' in English.","reference_context":"Document 523: Fig. 13 Word sketch for Turkish y\u00fcrek (heart)\nFig. 14 Word sketches for Japanese (accumulate)Lexicography ASIALEX (2014) 1:7\u201336 21\n123","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":523,"situational_context":"The user is a data mining student trying to understand the relationship between text analytics and lexicography by analyzing Japanese words.","topic":"Corpus Linguistics Software"}}
{"id":"2ab5cf76-1dcd-4ff3-9630-1cdd406a3fa1","question":"As a student preparing for the COMP2121 Data Mining and Text Analytics module, I want to generate some sample questions for practice. Could you tell me what the assessments for this module are?","reference_answer":"There will be a couple of online tests at the beginning and at the end. Most importantly, students will be asked to come up with a data mining and text analytics research project proposal, and write it up in the style of an EPSRC research grant proposal.","reference_context":"Document 37: replies to emails on the move. Well this is a nice example of technology which was technically \npossible, but it turned out to be not very safe to do. So nowadays, you're not supposed to listen to \nemail messages or dictate replies while you're driving because you're being distracted from \ndriving. OK then.  \nSo in summary, I have introduced you to myself. I'm Eric Atwell. Google Eric Atwell and find out \nmore about me. If you go to my webpage, you'll hear some happy songs you can listen to. You \nhave an overview of the data mining and text analytics module and the assessments that are \ncoming. There'll be a couple of online tests at the beginning and at the end. But most importantly, \nI'm going to be asking you individually to come up with a data mining and text analytics research \nproject proposal, and write it up in the style of an EPSRC research grant proposal following the \nguidel ines there.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":37,"situational_context":"In order to successfully prepare for the upcoming COMP2121 assessments, a student wants to generate some sample questions for practice.","topic":"Others"}}
{"id":"4d36561e-33f6-43ba-922b-2ca65bb53ce1","question":"Hello there, I'm a linguistics researcher currently studying text analytics methods for my upcoming project on web corpus construction. Could you please tell me the title of the PhD thesis by Rychly in 2000?","reference_answer":"The title of the PhD thesis by Rychly in 2000 is 'Korpusove \u00b4manaz \u02c7ery a ~ jejich efektivn\u0131 \u00b4implementace.'","reference_context":"Document 571: Sanseido. 2003, 2007. The WISDOM English\u2013Japanese Dictionary. Sanseido.Scha\u00a8fer, R., and F. Bildhauer. 2013. Web corpus construction. Synthesis Lectures on Human Language\nTechnologies 6(4): 1\u2013145.\nScheible, S., R.J. Whitt, M. Durrell, and P. Bennett. 2011. A gold standard corpus of Early Modern\nGerman. In Proc 5th Linguistic Annotation Workshop , 124\u2013128. Association for computational\nlinguistics.\nSharoff, S. 2006. Creating general-purpose corpora using automated search engine queries. In WaCky!\nWorking papers on the Web as Corpus , eds. Baroni and Bernardini, 63\u201398. Bologna: Gedit.\nSrdanovic Erjavecs, I., Erjavec, T., and Kilgarriff, A. 2008. A web corpus and word sketches for\nJapanese. Information and Media Technologies , 3(3).\nSuchomel, V., and J. Pomika \u00b4lek. 2012. Ef\ufb01cient Web crawling for large text corpora. In Proc Seventh\nWeb as Corpus Workshop (WAC7) , 39\u201343. Lyon, France.\nThomas, J. 2014. Discovering English with the Sketch Engine.\nPrint-on-demand. http:\/\/ske.li\/deske .\n\nDocument 570: Proc LREC , 1799\u20131802. Genoa, Italy.\nRenouf, A., A. Kehoe, and J. Banerjee. 2006. WebCorp: an integrated system for web text search.\nLanguage and Computers 59(1): 47\u201367.\nRundell, M. ed. 2002. Macmillan English Dictionary for Advanced Learners . Macmillan.\nRundell, M. 2012. Stop the presses\u2014the end of the printed dictionary. Macmillan Dictionary Blog, 5\nNov. http:\/\/www.macmillandictionaryblog.com\/bye-print-dictionary .\nRychly \u00b4, P. 2000. Korpusove \u00b4manaz \u02c7ery a ~ jejich efektivn\u0131 \u00b4implementace.Rychly \u00b4. PhD Thesis, Masaryk\nUniversity, Brno, Czech Republic.\nRychly \u00b4, P. 2007. Manatee\/bonito\u2013a modular corpus manager. In 1st Workshop on Recent Advances in\nSlavonic Natural Language Processing , 65\u201370. Masaryk University, Brno, Czech Republic.\nSanseido. 2003, 2007. The WISDOM English\u2013Japanese Dictionary. Sanseido.Scha\u00a8fer, R., and F. Bildhauer. 2013. Web corpus construction. Synthesis Lectures on Human Language\nTechnologies 6(4): 1\u2013145.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":571,"situational_context":"A linguistics researcher is brushing up on text analytics methods for his upcoming project on web corpus construction.","topic":"Corpus Linguistics Software"}}
{"id":"0d787bca-a082-4e72-b98c-cd70131554e1","question":"Hi, I'm currently studying the COMP2121 Data Mining and Text Analytics module and I'm a bit confused about a topic. Could you explain some applications of language technology in office and home settings?","reference_answer":"In some systems, voice has already arrived at the desktop. Apple Computer's recent operating systems include English speech-to-text, which can read back screen-based text or 'alert' messages in 25 different voices. This technology can be particularly beneficial for visually impaired users. Additionally, machine translation systems are used for gist or 'first-draft' translation.","reference_context":"Document 193: computing resources by means of a natural English dialogue with an apparently intelligent program (a\nKnowledge-Based System). Content-scanning : scanning electronic text (such as email, newswire\nservices, or World Wide Web documents) to extract and\/or summarise key information. Text editing : \u0090smart\ntools\u0091 to check grammar, idioms, and style are now options available in many word processors. Machine\ntranslation : translation of text from one language to another; more ambitious projects such as the German\n\u0090Verbmobil\u0091 aim to translate from spoken input (German) to spoken output (Japanese) to allow a \u0090virtual\ndialogue\u0091. Talkwriter : transcription of spoken input into a word processor \u0097 this is seen as one of the main\nmarkets for language technologies. (Source: Johnson, 1985)Speech and \nlanguage technologyin the classroomSee pages 48 & 49\n.Language technology in action\nfor policing across Europe: national\npolice forces across Europe are\nalready pooling their language\n\nDocument 87: learning . systems thus learn how to analyse and process\nnatural-language by being given examples of expected\ninput together with appropriate analyses (Charniak, 1993;\nAtwell, 1996).\nOffice and home  In some systems, voice has already\narrived at the desk-top: Apple Computer\u0091s recent operating\nsystems include English speech-to-text, which can read\nback screen-based text or \u0090alert\u0091 messages in 25 different\nvoices. While some users may struggle to find an\napplication for a talking computer, others \u0097 such as the\nvisually impaired \u0097 will find this technology beneficial.\nWhat of applications such as translation? To develop a\nmachine-translation system, a researcher could use a\ncorpus of English sentences and their French equivalents to\nderive an algorithm .for mapping from English to French.\nMachine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\n\nDocument 58: may even increasingly expect voice to be part of our interaction with machines, perhaps\nanticipating the usefulness of the language machine in practical contexts such as language\nteaching and learning. \nThe same technologies apply not only to English but to other languages. Email messages need not\nbe in English: technology can be used to transmit and receive any sequence of characters \u0097 ;-) or\n8-{*} \u0097 and the World Wide Web allows a wide variety of different data types and formats to be\ntransparently interwoven, so that a Web page can include images, sound, and text. \nYet these technologies are not true SALT technologies: they do not process or model language in\nan \u0090intelligent\u0091 way. Intelligence is required of the person using the system, rather than the system\nitself. Recent word processors may provide spell-checkers and guidance on grammar and points\nof style, but incorporate only rudimentary \u0090Artificial Intelligence\u0091 models of English. Likewise, most","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":193,"situational_context":"A student enrolled in the COMP2121 Data Mining and Text Analytics module is seeking clarification regarding some course content.","topic":"Language Machine Technology"}}
{"id":"85ae06c2-e146-4613-9048-8b3f10d53fa1","question":"As a linguistics major, I'm curious about the benefits of different language machine projects. Can you tell me about some of the Language Resources Projects that might be particularly beneficial to the United Kingdom?","reference_answer":"Some of the Language Resources Projects are EUROWORDNET, PAROLE, SIMPLE, and SPEECHDAT.","reference_context":"Document 265: the language machine\n63\nLanguage Resources Projects\nEUROWORDNET (Building a multilingual wordnet database with semantic relations between words): http:\/\/www.linglink.lu\/le\/projects\/eurowordnetPAROLE (Preparatory Action for linguistic Resources Organisation for Language Engineering):http:\/\/www.linglink.lu\/le\/projects\/le-paroleSIMPLE (Semantic Information for Multifunctional Plurilingual Lexica):http:\/\/www.linglink.lu\/le\/projects\/simpleSPEECHDAT (Speech Databases for Creation of Voice Driven Teleservices):http:\/\/www.linglink.lu\/le\/projects\/speechdat\nInfrastructure and Support Projects\n\nDocument 263: http:\/\/www.linglink.lu\/le\/projects\/select\nSPEAK (Supported Prototype Easy-Access Authoring Keys): http:\/\/www.linglink.lu\/le\/projects\/speak\nPublic Interest Projects\nAVENTINUS (Advanced Information System for Multilingual Drug Enforcement):\nhttp:\/\/www.linglink.lu\/le\/projects\/aventinus\nLINGUANET (Communicating Through the Language Barrier):\nhttp:\/\/www.linglink.lu\/le\/projects\/linguanet\nMIETTA (Multilingual Information Extraction for Tourism and Travel Assistance):\nhttp:\/\/www.linglink.lu\/le\/projects\/mietta\nSENSUS (LE for police and emergency service communications and information systems):\nhttp:\/\/www.linglink.lu\/le\/projects\/sensus\nInternational Business Support Projects\nDOCSTEP (Product DOCumentation Creation and Management using STEP):\nhttp:\/\/www.linglink.lu\/le\/projects\/docstep\nMABLE (Multilingual Authoring of Business Letters): http:\/\/www.linglink.lu\/le\/projects\/mable\nOTELO (Common Access to Translation Systems): http:\/\/www.linglink.lu\/le\/projects\/otelo\n\nDocument 184: Engineering Standards), MATE (Multi-level Annotation\nTools Engineering), ELSE (Evaluation in Language and\nSpeech Engineering) and DIET (Diagnostic and Evaluation\nTools for Natural Language Applications) are developing\nstandards and guidelines for the development and\nevaluation of language engineering resources and systems.\nPAROLE (Preparatory Action for linguistic Resources\nOrganisation for Language Engineering), EUROWORDNET\n(Building a multilingual wordnet database with semantic\nrelations between words), SIMPLE (Semantic Information\nfor Multifunctional Plurilingual Lexica) and SPEECHDAT\n(Speech Databases for Creation of Voice Driven Teles-\nervices) are gathering corpora of text, speech, and dic-\ntionaries across the range of EU languages, to be re-used in\nEuropean language engineering research and products.\nOne of the key questions many will ask, is how will these\nlanguage machine projects benefit people in the UK? .the language machine\n43\nWhat are the benefits to the UK?","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":265,"situational_context":"A linguistics major is wondering about the benefits of different language machine projects to the United Kingdom.","topic":"Others"}}
{"id":"de5bbe50-c62c-4fd1-a21e-30abce930404","question":"Hey, I'm a bit confused about my research project for the COMP2121 Data Mining and Text Analytics module. Can you help me understand what the main focus of a machine learning course is, and how it differs from data mining?","reference_answer":"The main focus of a machine learning course is about learning the algorithms for doing various different sorts of machine learning, where you input some data and some classes if it's a classifier. You then have various different ways of predicting the classes of unseen data. You want to aim to have optimal accuracy, or to measure how good it is, how many of it you got right in your test set and how many are wrong.","reference_context":"Document 11: you've learned about in the module in your research project.  \nAnd just by way of reminding you-  so you might be asking-  what's the difference between machine \nlearning and data mining? So if you've done the machine learning course, or maybe you haven't \nyet but you will do sometime soon, this is mainly about learning the algorithms for doing various \ndifferent sorts of machine learning, where you input some data and some classes if it's a classifier. \nAnd then you have various different ways of predicting the classes of unseen data. And you want \nto aim to have optimal accuracy, or to measure how good it is, how many of it you got right in your \ntest set and how many  are wrong.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":11,"situational_context":"A confused student needs help to distinguish the difference between machine learning and data mining for his research project in COMP2121 Data Mining and Text Analytics module.","topic":"Text Analytics and Data Mining"}}
{"id":"ac6f3284-939c-414d-8d29-4094e7e69cf5","question":"Hey there, I'm a linguistics student preparing for the COMP2121 Data Mining and Text Analytics module. I'm trying to understand the concept of parallel concordancing in 300 language pairs. Could you tell me what are the two main sources of data for the Sketch Engine's 300 language pairs?","reference_answer":"The two main sources of data for the Sketch Engine's 300 language pairs are EUROPARL and OPUS.","reference_context":"Document 527: corpus, comprising sets of texts which are translations of each other (or, are bothtranslations of the same source). Parallel concordancing, as in Fig. 17, is where a\nuser inputs a search term in one language and sees pairs of sentence: those with thematching term in the \ufb01rst language, and the corresponding sentence in the target\nlanguage.\nIn the Sketch Engine there are data for 300 language pairs. These data are from\ntwo main sources: EUROPARL and OPUS. EUROPARL comprises speeches madeat the European parliament, which have been translated into 21 of\ufb01cial EuropeanUnion languages (Koehn 2005 ).\n17The OPUS data, a collection of parallel corpora\ncollected in the OPUS project, are made available on its website.18It comprises\n17The original release was for fewer languages. For recent releases see http:\/\/www.statmt.org\/europarl\/ .\n18http:\/\/opus.ling\ufb01l.uu.se\/ .Lexicography ASIALEX (2014) 1:7\u201336 23\n123","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":527,"situational_context":"A linguistics student is preparing for the COMP2121 Data Mining and Text Analytics module and needs to understand the concept of parallel concordancing in 300 language pairs.","topic":"Corpus Linguistics and Lexicography"}}
{"id":"99dde2f0-024b-4e24-86ba-fa3f5b8550e8","question":"As a university lecturer preparing for a quiz in my COMP2121 Data Mining and Text Analytics class, I need to generate sample questions. Can you tell me what the Sketch Engine defines as a 'large language' in terms of the total number of speakers?","reference_answer":"By a \u2018large language\u2019, the Sketch Engine means a language with a large number of speakers.","reference_context":"Document 512: keywords, lemmas, terms) for many languages. Several technology companies have\nbeen users of this kind.\n4 Languages\nThe Sketch Engine aims to cover all the large languages of the world, as well as any\nlanguages which particular users are asking for.\nBy a \u2018large language\u2019 we mean a language with a large number of speakers. The\nethnologue website provides a list of languages sorted by numbers of speakers, asshown in Table 1.Table 1 All the world languages with over 50 million speakers\nRank Language Primary Country Total countries Speakers (millions) SkE status\n1 Chinese [zho] China 33 1,197 Good\n2 Spanish [spa] Spain 31 406 Good3 English [eng] United Kingdom 101 335 Good4 Hindi [hin] India 4 260 Good5 Arabic [ara] Saudi Arabia 59 223 Good\n6 Portuguese [por] Portugal 11 202 Good\n7 Bengali [ben] Bangladesh 4 193 Basic8 Russian [rus] Russian Federation 16 162 Good9 Japanese [jpn] Japan 3 122 Good10 Javanese [jav] Indonesia 3 84.3 No11 German [deu] Germany 18 83.8 Good12 Lahnda [lah]","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":512,"situational_context":"A university lecturer preparing for a quiz in her COMP2121 Data Mining and Text Analytics class, needs to generate sample questions on the total number of speakers for different languages.","topic":"Others"}}
{"id":"fbdb008a-d819-4500-8ea3-f6a11143faba","question":"Hey, I'm studying for my COMP2121 Data Mining and Text Analytics module exam and I'm trying to understand corpus collections better. Can you tell me what the Brown corpus is and how punctuation is handled in the word count?","reference_answer":"The Brown corpus is a million-word collection of samples from 500 written English texts from different genres (newspaper, fiction, non-fiction, academic, etc.), assembled at Brown University in 1963\u201364.","reference_context":"Document 379: 2.2 Words\nBefore we talk about processing words, we need to decide what counts as a word.\nLet\u2019s start by looking at one particular corpus (plural corpora ), a computer-readable corpus\ncorpora collection of text or speech. For example the Brown corpus is a million-word col-\nlection of samples from 500 written English texts from different genres (newspa-\nper, \ufb01ction, non-\ufb01ction, academic, etc.), assembled at Brown University in 1963\u201364\n(Ku\u02c7cera and Francis, 1967). How many words are in the following Brown sentence?\nHe stepped out into the hall, was delighted to encounter a water brother.\nThis sentence has 13 words if we don\u2019t count punctuation marks as words, 15\nif we count punctuation. Whether we treat period (\u201c .\u201d), comma (\u201c ,\u201d), and so on as\nwords depends on the task. Punctuation is critical for \ufb01nding boundaries of things\n(commas, periods, colons) and for identifying some aspects of meaning (question\nmarks, exclamation marks, quotation marks). For some tasks, like part-of-speech","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":379,"situational_context":"A student preparing for his COMP2121 Data Mining and Text Analytics module exam, needs to understand the concepts around corpus collections and how punctuation is handled in count of the words.","topic":"Others"}}
{"id":"1bcde2da-4e7d-4596-8eb6-ee22c29ebbf3","question":"Hi there, I'm a linguistics researcher preparing for a lecture on 'Machine learning applied to natural language processing'. Could you help me clarify the definition of Optical Character Recognition (OCR)?","reference_answer":"Optical Character Recognition (OCR) is the recognition of printed language using a symbolic representation derived from its graphical form: for alphabetic languages, this means recognising and transforming characters. OCR for a document using a single printed font can achieve a very high degree of accuracy, although problems can arise with unknown or decorative fonts or poor print quality. In these cases, and in the case of handwriting, good results can be achieved only by using Intelligent Character Recognition.","reference_context":"Document 247: natural language learning  \u0097 machine learning applied to natural language\ncorpora to extract computable language models.\nneural network  \u0097 an important area of Artificial Intelligence research, neural\nnetworks are statistical pattern-recognition systems built to emulatebiological and neural systems.\nOptical Character Recognition (OCR)  \u0097 recognition of printed language using\na symbolic representation derived from its graphical form: for alphabeticlanguages, this means recognising and transforming characters. OCR fora document using a single printed font can achieve a very high degree ofaccuracy, although problems can arise with unknown or decorative fontsor poor print quality. In these cases, and in the case of handwriting, goodresults can be achieved only by using Intelligent Character Recognition. \nparse \u0097 to analyse language in order to establish its syntactic and\/or\nsemantic structure and relationships.\nsemantics \u0097 the study of meaning, and of the principles that govern the","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":247,"situational_context":"A linguistics researcher is preparing for an upcoming lecture on \"Machine learning applied to natural language processing\" and wants to clarify some concepts.","topic":"Language Processing and Computational Linguistics"}}
{"id":"1787abe5-dd4c-4412-a7d3-6be2374cf1ee","question":"I'm a translator working for a large organization, and I have a task to translate some content related to the COMP2121 Data Mining and Text Analytics module. Could you explain how corpora could assist me in understanding the specific terminology and phraseology of this module?","reference_answer":"Translators find corpora useful for identifying the terminology and phraseology of the domain, in the language they are translating into.","reference_context":"Document 509: Czech Republic, Germany, Italy, Japan, Spain and Taiwan as well as the UK.\n3.4 Translators\nTranslators \ufb01nd corpora (of speci\ufb01c domains) useful for identifying the terminology\nand phraseology of the domain, in the language they are translating into. (They willusually be a native speaker of that language, but will often not know the terms andturns of phrase for specialised areas in which they have a translation task). Anumber of professional translators are Sketch Engine users.\n3.5 Terminologists\nIn the context of large organisations needing to prepare many documents in multiple\nlanguages, consistency is a challenge: in particular, the consistent use of the same","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":509,"situational_context":"A translator needs to understand the specific terminology and phraseology of the Data Mining and Text Analytics module for a translation task in the context of a large organization.","topic":"Corpus Linguistics and Lexicography"}}
{"id":"f9ca1fbe-3011-4b89-bdcb-2a6205fe1159","question":"Hey, I'm studying for my upcoming COMP2121 Data Mining and Text Analytics exam and I'm trying to understand how it relates to PC access inequality. Can you tell me what the role of the EPSRC is in this context?","reference_answer":"EPSRC, the Engineering and Physical Science Research Council, promotes and supports strategic and applied research, advances knowledge and technology that contributes to economic competitiveness and life quality, and promotes understanding in the fields of engineering and the physical sciences.","reference_context":"Document 132: learning experience, while fundamentally changing the\nbalance between classroom and individual learning.\nInequality of home PC access may however become a\npressing issue, and perhaps makes more important the role\nof study centres and libraries .offering access for all. In\nproviding points of access to new technology, such centres\nmay perhaps in the process reinvent themselves as\ntechnology junctions.the language machine\n29\n.EPSRC  \u0097 Engineering and\nPhysical Science Research Council\n\u0097 is one of seven agencies funding\nresearch in UK universities. Its role\nis to promote and support strategic\nand applied research, advance\nknowledge and technology that\ncontributes to economic\ncompetitiveness and life quality,\nand promote understanding in the\nfields of engineering and the\nphysical sciences.\n.\u0090Information technology  is\nimportant in tackling social\nexclusion because anyone can\nwalk in to a library, sit down and\nstart tapping away \u0097 at absolutely\nno cost.\u0091 \u0097 Chris Smith, the","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":132,"situational_context":"Preparing for an upcoming exam, a university student is trying to understand more about the COMP2121 Data Mining and Text Analytics module and how it relates to the issue of inequality in PC access.","topic":"Language Machine Translation"}}
{"id":"11402974-26d3-4ed4-ae83-5a34ce35369f","question":"As a university student preparing for my COMP2121 Data Mining and Text Analytics module exam, can you explain to me what the functionality of WebBootCaT is in the context of corpus creation, particularly in relation to the concept of 'parallel corpora'?","reference_answer":"WebBootCaT allows you to create a corpus from a web page.","reference_context":"Document 461: If you have a corpus in Chinese and the translation's in English -- and there are some corpora \nwhich are parallel corpora. For example, Opus 2 i s one within Sketch Engine where we have, for a \nwhole lot of documents, the English and the translated Chinese and the translation is in other \nlanguages too, and you could choose a word like smile and get the Chinese translations for smile, \nwhich lets you see what sort of words appear before and after smile in English and the equivalent \nin Chinese.  \nAnd the thing you're interested in for your coursework is WebBootCaT, which allows you to create \na corpus from a web page. And in the paper, we have a slightly d ifferent look and feel to the","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":461,"situational_context":"A university student is preparing for her COMP2121 Data Mining and Text Analytics module exam, and wants to understand the concept of 'parallel corpora' and 'WebBootCaT'.","topic":"Others"}}
{"id":"0f534488-44ac-4bed-951d-1878d3b521f4","question":"As a university student preparing for a COMP2121 Data Mining and Text Analytics exam and researching about the process of symbol merging, I'm interested in understanding the sequence and frequency of pair merges. Can you explain the purpose of the token parser in this system?","reference_answer":"Once the vocabulary has been learned, the token parser is used to tokenize a test sentence. It runs the merges that have been learned on the test data.","reference_context":"Document 410: 3) for a total of 9 occurrences1. We then merge these symbols, treating eras one\nsymbol, and count again:\ncorpus vocabulary\n5l o w , d, e, i, l, n, o, r, s, t, w, er\n2l o w e s t\n6n e w er\n3w i d er\n2n e w\nNow the most frequent pair is er , which we merge; our system has learned\nthat there should be a token for word-\ufb01nal er, represented as er:\ncorpus vocabulary\n5l o w ,d,e,i,l,n,o,r,s,t,w,er,er\n2l o w e s t\n6n e w er\n3w i d er\n2n e w\nNextn e(total count of 8) get merged to ne:\ncorpus vocabulary\n5l o w ,d,e,i,l,n,o,r,s,t,w,er,er,ne\n2l o w e s t\n6ne w er\n3w i d er\n2ne w\nIf we continue, the next merges are:\nMerge Current Vocabulary\n(ne, w) ,d,e,i,l,n,o,r,s,t,w,er,er,ne,new\n(l, o) ,d,e,i,l,n,o,r,s,t,w,er,er,ne,new,lo\n(lo, w) ,d,e,i,l,n,o,r,s,t,w,er,er,ne,new,lo,low\n(new, er ) ,d,e,i,l,n,o,r,s,t,w,er,er,ne,new,lo,low,newer\n(low,) ,d,e,i,l,n,o,r,s,t,w,er,er,ne,new,lo,low,newer ,low\nOnce we\u2019ve learned our vocabulary, the token parser is used to tokenize a test\n\nDocument 411: (new, er ) ,d,e,i,l,n,o,r,s,t,w,er,er,ne,new,lo,low,newer\n(low,) ,d,e,i,l,n,o,r,s,t,w,er,er,ne,new,lo,low,newer ,low\nOnce we\u2019ve learned our vocabulary, the token parser is used to tokenize a test\nsentence. The token parser just runs on the test data the merges we have learned\n1Note that there can be ties; we could have instead chosen to merge r \ufb01rst, since that also has a\nfrequency of 9.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":410,"situational_context":"A university student is researching about the process of symbol merging in text analytics, particularly understanding the sequence and frequency of pair merges, in preparation for a COMP2121 Data Mining and Text Analytics exam.","topic":"Text Normalization and Tokenization"}}
{"id":"b54fb9aa-afba-4058-a4d0-28349ceb30f9","question":"As a college student studying the COMP2121 Data Mining and Text Analytics module, I need to summarise a future-oriented document titled 'Life expectancy approaches 100' for my assignment. Can you help me identify the major events listed in this context?","reference_answer":"The major events listed are: Life expectancy approaches 100, Nanotechnology takes off, No-carbon economy worldwide, Rise of an American dictator, Self-aware machine intelligence, Time travel invented, Major technology accident, Asteroid hits earth, Social breakdown in US or Europe, and Whole generation unable to effectively read, write, think or work.","reference_context":"Document 74: ? Life expectancy approaches 100\n? Nanotechnology takes off\n? No-carbon economy worldwide\n? Rise of an American dictator\n? Self-aware machine intelligence\n? Time travel invented\n? Major technology accident\n? Asteroid hits earth\n? Social breakdown in US or Europe\n? Whole generation unable to\neffectively read, write, think or work \nWeb addresses \nfor Philips and BT?See page 63SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":74,"situational_context":"A college student is seeking help in understanding the COMP2121 Data Mining and Text Analytics module while also needing to summarize a future-oriented document titled \"Life expectancy approaches 100\" for his assignment.","topic":"Others"}}
{"id":"48723758-3a74-4291-a0bf-1478605f9881","question":"As a student preparing an impressive research proposal, I'm curious about the specifics of the COMP2121 Data Mining and Text Analytics module. Could you tell me what is expected from the students in the first part of unit one in this module?","reference_answer":"In the first part of unit one, students are expected to look at some practical applications of corpus linguistics and text analytics from the language machine. They are also expected to read a book and the assessment specification in more detail.","reference_context":"Document 38: \u00a9 University of Leeds   10 of 10  OK. So for unit one, the first part, we've looked at some practical applications of corpus linguistics \nand text analytics from the language machine. This book, I'd like you to read it in some more detail \nand also read the assessment specificati on in more detail. And hopefully you'll feel comfortable \nwith that. And then later on in the module, I'll give you some more details as to what you actually \nhave to do to make sure you all come up with really good research proposals. OK. Thank you for \nwatching and listening, and I hope you enjoy the module. Bye for now.  \n[END]","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":38,"situational_context":"A student is curious about the specifics of the COMP2121 Data Mining and Text Analytics module and wants to prepare an impressive research proposal.","topic":"Text Analytics and Data Mining"}}
{"id":"1ab3785f-e9f1-4161-99ec-cb14fe343dd5","question":"As a student researching for my COMP2121 Data Mining and Text Analytics module, I'm trying to understand the concept of a text corpus. Could you explain the potential challenges, like identifying word count and distinguishing speech transcriptions, that I might encounter when counting the number of words in a sentence?","reference_answer":"Challenges in counting the number of words in a sentence can include deciding whether to count fragments, pauses, interruptions, and deciding whether different forms of the same word (like 'cat' and 'cats') should be counted as the same word or different words.","reference_context":"Document 310: even more complicated things in ELIZA, but we'll come back to that later.  \nOK, so we want to try to collect a corpus. A corpus is a text data set. And typically you want to split \nit up into words, and do things like counting up how many words there are. Well you might think \ncounting the number of  words in the sentence is easy, but it depends on what you mean by a \nword.  \nHere's an example. I do uh main-  mainly business data processing. How many words is that? \nWell, part of the problem is, maybe there are fragments, like main-  mainly. Particularly in  \ntranscriptions of speech, and maybe ooh, and ah, and pauses and interruptions and things like \nthat. Do you want to count those? Well probably not.  \nAnother thing is OK, here's another example, Seuss's cat in the hat is different from other cats. \nWell in th is example, maybe cats is the same word as cat. Do we want to count those twice, or \nonce?","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":310,"situational_context":"A student is researching for his COMP2121 Data Mining and Text Analytics module, in need of understanding the concept of a text corpus and the challenges involved such as identifying word count and distinguishing speech transcriptions.","topic":"Others"}}
{"id":"1b3e51fd-3853-46f6-aab3-e9f890940f27","question":"Hi there, I'm a linguistics researcher currently delving into historical corpus linguistics. Could you help me out by telling me what the topic of Pomik\u00e1lek's 2011 PhD thesis is?","reference_answer":"Pomik\u00e1lek's 2011 PhD thesis is about 'Removing boilerplate and duplicate content from Web Corpora.'","reference_context":"Document 569: Kosem, I., V. Baisa, V. Kova \u00b4r\u02c7, and A. Kilgarriff. 2013. User-friendly interface of error\/correction-\nannotated corpus for both teachers and researchers . Solstrand: Proc Learner Corpus Research.\nMcGillivray, B., and A. Kilgarriff. 2013. Tools for historical corpus research, and a corpus of Latin. In\nNew Methods in Historical Corpora , Bennett, P.D. ed. Vol 3. BoD\u2013books on demand.\nO\u2019Donnell, M. 2008. Demonstration of the UAM CorpusTool for text and image annotation. In Proc 46th\nACL: Demo Session , 13\u201316. Association for computational linguistics.\nPomika \u00b4lek, J. 2011. Removing boilerplate and duplicate content from Web Corpora. PhD thesis, Masaryk\nUniversity, Brno, Czech Republic.\nQuasthoff, U., M. Richter, and C. Biemann. 2006. Corpus portal for search in monolingual corpora. In\nProc LREC , 1799\u20131802. Genoa, Italy.\nRenouf, A., A. Kehoe, and J. Banerjee. 2006. WebCorp: an integrated system for web text search.\nLanguage and Computers 59(1): 47\u201367.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":569,"situational_context":"A linguistics researcher is looking for information on the COMP2121 Data Mining and Text Analytics module to aid in her research on historical corpus linguistics.","topic":"Corpus Linguistics and Lexicography"}}
{"id":"a779dd5b-031a-4c56-8426-bb5a81d2b77e","question":"As a data science student trying to summarize my readings, could you help me understand some of the challenges that hinder the progress of language machine development?","reference_answer":"Some problems that slow the development of the language machine include its high cost, the need for powerful computers with large amounts of memory and disk storage space, and the need for in-house research and development teams. Additionally, its practical applications have been hindered by the combination of these problems. For instance, few language teachers or individual learners can afford a computer powerful enough to use the latest language machine software.","reference_context":"Document 127: What slows development?\nThere are several problems facing the researcher \u0097 and\nindeed the potential customer \u0097 for the language machine,\nsome of which may continue to hold back the development\nof the technology well into the future. This section\nexamines seven key problems.\nProblem 1\nThe language machine is expensive\nSpeech and language technology has, in the past, had areputation for requiring computers with powerful\nprocessors and large amounts of memory and disk storage\nspace, allied to in-house research and development teams\nwho develop and install language machines and integrate\nthem into current systems.\nThis situation is now changing, thanks to rapid increases\nin computing technology. Much like advanced graphics and\nInternet access, technologies previously restricted to\nuniversity research laboratories are increasingly available\non home and office computers. \nOne concrete example of this is speech recognition\ntechnology. IBM, like many others, have used the basic\n\nDocument 149: Problem 7\nApplications face all of the above problems \nAttempts to use the language machine in practice have\nbeen dogged by a combination of several or all of the\nabove problems, as its application in English language\nteaching illustrates. Relatively few language teachers, let\nalone individual learners, can afford a computer powerful\nenough to use the latest language machine software. IBM\nViaVoice Gold, for example, requires a PC with a Pentium\n166MHz processor, 32Mb RAM and 125Mb free disk space.\nWhile this is no longer the sort of machine confined to\nresearch laboratories, it is still not easily within the budget\nof every teacher or student \u0097 even in Western countries. \nNeither have very many language teachers been\nconsulted by language machine researchers to discover\nwhat they would use. the technology for: the Project ISLE\nuser consultation exercise described on page 30 is the\nexception rather than the rule. One of the main requests of\n\nDocument 129: This move, from research laboratories to everyday use, .\nleaves some academic researchers feeling redundant.\nSpeech recognition is no longer a technology research\nissue, as the theoretical problems are (supposedly) largelyThe problems\n28with machines\nIf we have the\ncommon aims and\napproaches in place,\nwhy isn\u0091t the\nlanguage machine in\ncommon use?\nWhat problems are\nslowing\ndevelopment? What\nholds it all back?SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":127,"situational_context":"In pursuit of understanding the hindrances in language machine development, a data science student is summarizing his readings on the subject for better retention and clarity.","topic":"Language Machine Development"}}
{"id":"f0b7cadc-ea53-45aa-b1a7-3293da650637","question":"Hey, I'm a computer science student currently revising for my COMP2121 Data Mining and Text Analytics module exam. I'm having trouble understanding the concept of minimum edit distance and Levenshtein distance in text analytics. Can you explain what the minimum edit distance is and how it is defined?","reference_answer":"The minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.","reference_context":"Document 425: 22 CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\nINTE*NTION\n||||||||||\n*EXECUTION\nd s s i s\nFigure 2.14 Representing the minimum edit distance between two strings as an alignment .\nThe \ufb01nal row gives the operation list for converting the top string into the bottom string: d for\ndeletion, s for substitution, i for insertion.\nWe can also assign a particular cost or weight to each of these operations. The\nLevenshtein distance between two sequences is the simplest weighting factor in\nwhich each of the three operations has a cost of 1 (Levenshtein, 1966)\u2014we assume\nthat the substitution of a letter for itself, for example, tfort, has zero cost. The Lev-\nenshtein distance between intention andexecution is 5. Levenshtein also proposed\nan alternative version of his metric in which each insertion or deletion has a cost of\n1 and substitutions are not allowed. (This is equivalent to allowing substitution, but\n\nDocument 426: an alternative version of his metric in which each insertion or deletion has a cost of\n1 and substitutions are not allowed. (This is equivalent to allowing substitution, but\ngiving each substitution a cost of 2 since any substitution can be represented by one\ninsertion and one deletion). Using this version, the Levenshtein distance between\nintention andexecution is 8.\n2.5.1 The Minimum Edit Distance Algorithm\nHow do we \ufb01nd the minimum edit distance? We can think of this as a search task, in\nwhich we are searching for the shortest path\u2014a sequence of edits\u2014from one string\nto another.\nn t e n t i o ni n t e c n t i o ni n x e n t i o ndelinssubsti n t e n t i o n\nFigure 2.15 Finding the edit distance viewed as a search problem\nThe space of all possible edits is enormous, so we can\u2019t search naively. However,\nlots of distinct edit paths will end up in the same state (string), so rather than recom-\nputing all those paths, we could just remember the shortest path to a state each time\n\nDocument 431: If we assume the version of Levenshtein distance in which the insertions and dele-\ntions each have a cost of 1 (ins-cost( \u00b7) = del-cost(\u00b7) = 1), and substitutions have a\ncost of 2 (except substitution of identical letters have zero cost), the computation for\nD[i,j]becomes:\nD[i,j] =min\uf8f1\n\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f3D[i\u22121,j]+1\nD[i,j\u22121]+1\nD[i\u22121,j\u22121]+{2; if source [i]\u0338=target [j]\n0; if source [i] =target [j](2.8)\nThe algorithm is summarized in Fig. 2.17; Fig. 2.18 shows the results of applying\nthe algorithm to the distance between intention andexecution with the version of\nLevenshtein in Eq. 2.8.\nAlignment Knowing the minimum edit distance is useful for algorithms like \ufb01nd-\ning potential spelling error corrections. But the edit distance algorithm is important\nin another way; with a small change, it can also provide the minimum cost align-\nment between two strings. Aligning two strings is useful throughout speech and\nlanguage processing. In speech recognition, minimum edit distance alignment is\n\nDocument 423: seems like useful evidence for deciding that they might be coreferent.\nEdit distance gives us a way to quantify both of these intuitions about string sim-\nilarity. More formally, the minimum edit distance between two strings is de\ufb01nedminimum edit\ndistance\nas the minimum number of editing operations (operations like insertion, deletion,\nsubstitution) needed to transform one string into another.\nThe gap between intention andexecution , for example, is 5 (delete an i, substi-\ntuteeforn, substitute xfort, insertc, substitute uforn). It\u2019s much easier to see\nthis by looking at the most important visualization for string distances, an alignment alignment\nbetween the two strings, shown in Fig. 2.14. Given two sequences, an alignment is\na correspondence between substrings of the two sequences. Thus, we say Ialigns\nwith the empty string, NwithE, and so on. Beneath the aligned strings is another\nrepresentation; a series of symbols expressing an operation list for converting the","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":425,"situational_context":"A computer science student is revising for their COMP2121 Data Mining and Text Analytics module exam and needs help understanding the concept of minimum edit distance and Levenshtein distance in text analytics.","topic":"Minimum Edit Distance Algorithm"}}
{"id":"6182c0ce-55fe-46d7-957e-8fead38d69cf","question":"Hey, I'm studying for my COMP2121 Data Mining and Text Analytics module and I'm a bit confused. Could you explain the difference between text analytics and natural language processing in this context?","reference_answer":"Text analytics is the term preferred by industry and it usually uses computational linguistics or NLP as a toolkit for tackling practical problems. On the other hand, natural language processing, along with cooperation linguistics and corpus linguistics, tend to focus on the theory and algorithms for doing things.","reference_context":"Document 16: \u00a9 University of Leeds   5 of 10  finally, if it's OK, putting the results into practice by some sort of repeated continuous mining of the \ndata.  \nOK this is my way of reminding you should have seen this last in the data science m odule. OK so \nthat's data mining. What about text analytics? What's text analytics? Well, it's data mining applied \nto text. So you might as well call it text mining, but text analytics seems to be a popular term in \nindustry. Other terms abound as well. Computational linguistics is the part of linguistics or \nlanguage science involving computation. Or within computer science and AI, it's often called \nnatural language processing to differentiate from programming languages. It's natural languages. \nJurafsky and M artin have decided to call it speech and language processing because speech is \nquite important. Language often is taken in text, and speech is quite different from text. Within\n\nDocument 18: tend to focus on the theory and algorithms for doing things, whereas text analytics is the term \npreferred by industry. It's usually using computational linguistics or NLP as a sort of toolkit for \ntackling practical problems, making money in the end. Things like text data collection, \nunderstanding annotation, and wrangling are much more important in text analytics than they are \nin the theoretical fields of natural language processing.  \nIf you look up in Wikipedia text analytics, you'll see your redirected to the text mining. So even \nWikipedia thinks that text analytics is just  a fancy word for text mining, or text data mining. All of \nthis, you might think text is - it's English language is quite different from the sorts of things that are \nused to dealing with in machine learning-  because for the machine learning course works, you \nprobably had vectors of numbers. But if you can convert text into vectors of numbers, then all the\n\nDocument 17: Jurafsky and M artin have decided to call it speech and language processing because speech is \nquite important. Language often is taken in text, and speech is quite different from text. Within \nlinguistics, it's also called corpus linguistics. A corpus is a body of text, or a data set of text. So it's \nthe linguistics to do with data sets, whereas computational linguistics is the linguistics to do with \ncomputation. But to do the computation, you have to have data sets. Or to analyze the corpus, you \nhave to have computation. So actually corpus linguistics and computational linguistics are also \nvery similar.  \nAll of these things, cooperation linguistics, corpus linguistics, or natural language processing, they \ntend to focus on the theory and algorithms for doing things, whereas text analytics is the term \npreferred by industry. It's usually using computational linguistics or NLP as a sort of toolkit for","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":16,"situational_context":"A student is preparing for his COMP2121 Data Mining and Text Analytics module and needs to understand the difference between text analytics and text mining.","topic":"Language Processing and Computational Linguistics"}}
{"id":"9a97bf07-cf0c-49a1-8a42-ce4181e6bd80","question":"As a linguist working on translating characteristics of African American English in social media posts, could you help me understand what are some examples of African American English features that might be used in Twitter posts?","reference_answer":"Twitter posts might use features often used by speakers of African American English, such as constructions like 'iont' (I don\u2019t in Mainstream American English), or 'talmbout' corresponding to 'talking about' in Mainstream American English.","reference_context":"Document 387: (Chinese, Spanish, Japanese, German etc.), but we don\u2019t want to limit tools to just\nthese few languages. Furthermore, most languages also have multiple varieties, of-\nten spoken in different regions or by different social groups. Thus, for example,\nif we\u2019re processing text that uses features of African American English ( AAE ) or AAE\nAfrican American Vernacular English (AA VE) \u2014 the variations of English used by\nmillions of people in African American communities (King 2020) \u2014 we must use\nNLP tools that function with features of those varieties. Twitter posts might use fea-\ntures often used by speakers of African American English, such as constructions like\niont(I don\u2019t in Mainstream American English ( MAE )), or talmbout corresponding MAE\nto MAE talking about , both examples that in\ufb02uence word segmentation (Blodgett\net al. 2016, Jones 2015).\nIt\u2019s also quite common for speakers or writers to use multiple languages in a","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":387,"situational_context":"A linguist, working on translating characteristics of African American English in social media posts, seeks assistance to better understand data mining and text analytics.","topic":"Others"}}
{"id":"2af2ffbe-e763-405a-b35f-78329e919a6d","question":"Hello, I'm a student preparing for the COMP2121 Data Mining and Text Analytics module. Could you please clarify the topics covered in the six units of this module?","reference_answer":"The six units of the module cover: an introduction to Corpus linguistics, text analytics, and sketch engine; text data mining and a tool called Weka; the meanings of words and text, tagging of text and scaling to very large data sets; and text analytics for machine.","reference_context":"Document 2: the British Council.  \nOK so what's coming up in the overall module-  well if you look at the Minerva page, you'll find \nmore details - essentially like most modules, there are six units. And the first is an introducti on to \nCorpus linguistics, text analytics, and sketch engine. And then unit two we'll look into more data \nabout text data mining and a tool called Weka, Waikato environment for knowledge analysis. \nEveryone just calls it Weka. Unit three, we'll be looking at  not just the text but the meanings of \nwords and text because you want to compare two texts not in terms of what character strings they \nare but in terms of how they mean. Look at tagging of text and also for practical applications \nscaling to very large dat a sets. So what are the repercussions for classifiers if you're dealing with \nmuch bigger data sets.  \nUnit four, look at some examples of text analytics, in particular text analytics for machine","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":2,"situational_context":"A student preparing for the COMP2121 Data Mining and Text Analytics module is seeking clarification on the details of the six units covered in the module.","topic":"Text Analytics and Data Mining"}}
{"id":"2d75ce04-7c22-4ef2-ac62-4ef2b3c67bdc","question":"Hey, I'm working on a project for my COMP2121 Data Mining and Text Analytics module, focusing on the evolution of speech recognition technology. Could you tell me what the basic algorithm used in this technology is, as mentioned in the context?","reference_answer":"The basic algorithm used in speech recognition technology is known as Hidden Markov Modelling.","reference_context":"Document 128: university research laboratories are increasingly available\non home and office computers. \nOne concrete example of this is speech recognition\ntechnology. IBM, like many others, have used the basic\nalgorithm used in speech recognition \u0097 known as Hidden\nMarkov Modelling  \u0097 since the 1970s. In the 1980s, they\ndeveloped impressive speech recognition demonstrators in\ntheir research laboratories, although showing them at\nconferences and exhibitions required advanced computing\nhardware and speech research experts. \nThe same demonstration (or perhaps a more convincing\none) now can be taken into small business premises,\ncolleges, schools or homes \u0097 without the need for a\nresearcher or a lorry full of hardware. You can buy a speech\nrecognition package off the shelf, or may even get one free\nas a promotional item with a PC magazine.\nThis move, from research laboratories to everyday use, .\nleaves some academic researchers feeling redundant.\nSpeech recognition is no longer a technology research","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":128,"situational_context":"A university student is looking for additional information on the evolution of speech recognition technology for his COMP2121 Data Mining and Text Analytics module project.","topic":"Speech and Language Technology"}}
{"id":"19993e8d-c2ce-4c8a-bdc8-243875497e0d","question":"As a linguistics researcher exploring the potential social impact of automated language technology, could you explain what challenges might arise for linguistic minorities and the hearing and sight-impaired from new technologies, as discussed in the COMP2121 Data Mining and Text Analytics module?","reference_answer":"Linguistic minorities and the hearing and sight-impaired stand to gain from these technologies, but hardware and software costs or technophobia might become new sources of division and inequality.","reference_context":"Document 281: hearing and sight-impaired stand to gain from these\ntechnologies, but will hardware and software costs or\ntechnophobia become new sources of division and\ninequality?\nHow will technology change our interactions? How will we\nadapt once technology shapes \u0097 and speaks \u0097 the actual\nwords we send and receive? Will speech recognition re-\nemphasise oral skills?\nHow will a greater transparency of information in other\nlanguages affect economies? \nWill customer services be automated further, with personal\ninteraction becoming a premium service in the 21st\ncentury?\nWill the UK be seen as a leader of language machine\ntechnology?\n\nDocument 280: questions\n70for debate\nHow will the language machine affect the language-based\nprofessions? \nHow can computer scientists and language professionals\ncollaborate to mutual benefit?\nHow will practitioners find ways of influencing and\ninforming \u0097 and of staying informed of \u0097 developments\nin technology and best practice? If discussion is needed,\nhow will it be facilitated? \nWill we stop learning languages? And, if we do, what will\nbe the cultural and social impact?\nWill endangered languages be saved by a lesser need to\nlearn a lingua franca, or will software not be developed\nfor languages with smaller, less profitable audiences? \nNot all languages are similarly alphabetic, phonetic or\ntonal. Will some languages benefit more than others?\nHow equally will we benefit? Linguistic minorities and the\nhearing and sight-impaired stand to gain from these\ntechnologies, but will hardware and software costs or\ntechnophobia become new sources of division and\ninequality?","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":281,"situational_context":"A linguistics researcher is exploring the potential social impact and implications of automated language technology and seeks clarification on certain aspects of the COMP2121 Data Mining and Text Analytics module.","topic":"Others"}}
{"id":"fb9294c8-6dd3-481c-87e3-5bf13f7dfc57","question":"Hi, I'm an undergraduate student preparing for my Data Mining and Text Analytics module exam. Can you explain the difference between corpus linguistics and computational linguistics to me?","reference_answer":"Corpus linguistics is the linguistics to do with data sets, or a body of text. Computational linguistics is the linguistics to do with computation. However, to do the computation, you have to have data sets, and to analyze the corpus, you have to have computation. So actually corpus linguistics and computational linguistics are also very similar.","reference_context":"Document 17: Jurafsky and M artin have decided to call it speech and language processing because speech is \nquite important. Language often is taken in text, and speech is quite different from text. Within \nlinguistics, it's also called corpus linguistics. A corpus is a body of text, or a data set of text. So it's \nthe linguistics to do with data sets, whereas computational linguistics is the linguistics to do with \ncomputation. But to do the computation, you have to have data sets. Or to analyze the corpus, you \nhave to have computation. So actually corpus linguistics and computational linguistics are also \nvery similar.  \nAll of these things, cooperation linguistics, corpus linguistics, or natural language processing, they \ntend to focus on the theory and algorithms for doing things, whereas text analytics is the term \npreferred by industry. It's usually using computational linguistics or NLP as a sort of toolkit for\n\nDocument 16: \u00a9 University of Leeds   5 of 10  finally, if it's OK, putting the results into practice by some sort of repeated continuous mining of the \ndata.  \nOK this is my way of reminding you should have seen this last in the data science m odule. OK so \nthat's data mining. What about text analytics? What's text analytics? Well, it's data mining applied \nto text. So you might as well call it text mining, but text analytics seems to be a popular term in \nindustry. Other terms abound as well. Computational linguistics is the part of linguistics or \nlanguage science involving computation. Or within computer science and AI, it's often called \nnatural language processing to differentiate from programming languages. It's natural languages. \nJurafsky and M artin have decided to call it speech and language processing because speech is \nquite important. Language often is taken in text, and speech is quite different from text. Within","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":17,"situational_context":"An undergraduate student is trying to understand the field of computational linguistics for their upcoming Data Mining and Text Analytics module exam.","topic":"Others"}}
{"id":"9eb0b8d8-baa0-48bf-8542-6106c932e605","question":"As a COMP2121 student preparing my research on machine translation systems' effectiveness, I need to understand the desires of English language teachers and learners. Could you tell me what the main desire of English language teachers and learners was according to the ISLE project report?","reference_answer":"English language teachers and learners desired a 'conversation practice machine' as an aid to learning, where a learner could 'chat' in ordinary spoken English to practise everyday conversational language skills.","reference_context":"Document 88: Machine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\nto plan and integrate the future use of language machines,\nwhether as a substitute for conventional human-to-human\ninteraction, or for the delivery of language teaching.the language machine\n17\n.Algorithms \u0087 Natural-language\nlearning \u0087 Hidden Markov Models\n\u0087 neural networks?\nSee Glossary, pages 58\u009759\nToo expensive\nto be useful? See page 28.English language teachers and\nlearners, according to a report on a\nsurvey of user requirements for\nthe ISLE project (ISLE, 1999)\ndesired, above all, a \u0090conversation\npractice machine\u0091 as an aid to\nlearning: with such a system a\nlearner could \u0090chat\u0091 in ordinary\nspoken English to practise every-\nday conversational language skills.\n.Natural-language learning\nsystems often use sophisticated\nstatistical pattern-matching models\n(for example Hidden Markov\n\nDocument 135: learners\u0091 pronunciation of English, teachers and learners\nhave been involved at every stage, from initial drafting of\nresearch plan through to specification of requirements and\nverification of the final system. (ISLE project, see page 62)\nProblem 3\nThe language machine doesn\u0091t match the\nexpectations of customers\nSome potential customers expect the language machine to\nbe able to understand everything and to match human\nlanguage-processing, even though people themselves often\ndisplay a considerable talent for misunderstanding! \nAlthough the language machine clearly falls well below\nhuman standards . for language processing at present,\nthere are a growing number of tasks for which it is arguably\nadequate. In practice, the best current machine translation\nsystems are at least as good as a fairly competent second\nlanguage learner. This may be quite acceptable for some\ntasks: imperfect translation may be adequate for the reader\n\nDocument 87: learning . systems thus learn how to analyse and process\nnatural-language by being given examples of expected\ninput together with appropriate analyses (Charniak, 1993;\nAtwell, 1996).\nOffice and home  In some systems, voice has already\narrived at the desk-top: Apple Computer\u0091s recent operating\nsystems include English speech-to-text, which can read\nback screen-based text or \u0090alert\u0091 messages in 25 different\nvoices. While some users may struggle to find an\napplication for a talking computer, others \u0097 such as the\nvisually impaired \u0097 will find this technology beneficial.\nWhat of applications such as translation? To develop a\nmachine-translation system, a researcher could use a\ncorpus of English sentences and their French equivalents to\nderive an algorithm .for mapping from English to French.\nMachine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\n\nDocument 113: language learners can clearly benefit from access to\n\u0090language-aware\u0091 functions in word processors, although\nthey do need to be aware of their possible fallibility. \nMultilinguality A machine translation (MT) system\ntranslates text from one language into another, and may\neven deal with spoken input or output. They may also\ninvolve language identification: determining which\nlanguage is being used given a printed or spoken signal.\nMost research has concentrated on English and, to a lesser\nextent, other European languages. For languages and\nlanguage-pairs that have no comprehensive machine-\ntranslation system, tools for machine-assisted translation \u0097\nsuch as bilingual dictionaries and term-banks \u0097 may be\nuseful. \nAn obvious potential concern for language teachers and\nlanguage professionals, such as interpreters and\ntranslators, is whether MT (and the language machine in a\nbroader sense) could make language-learning \u0097 and hence\nlanguage teachers \u0097 redundant. .","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":88,"situational_context":"A COMP2121 student is preparing her research on machine translation systems' effectiveness and needs a comprehensive summary of an article to fine-tune her research points.","topic":"Artificial Intelligence in Language Learning"}}
{"id":"08adad51-1f3d-4f29-9c91-184433edc9e5","question":"As a student researching the interconnection between language and computer science, I'm trying to understand the COMP2121 Data Mining and Text Analytics module better. Could you explain to me the role of language engineering within telematics?","reference_answer":"Language engineering is concerned with building speech and language processing resources, and components for integration into telematics systems.","reference_context":"Document 76: computer interaction, and multimedia \u0097 as a sub-field of\ncomputer science. Speech and language technology is a\npotentially powerful way to give us \u0090natural\u0091 communi-\ncation with computers, and to facilitate various types of\n\u0090computer-mediated\u0091 communication between people.\nLanguage is also important in related fields, for example\nof telecommunications, or \u0090telematics\u0091 \u0097 a term conceived\nby European Union (EU) research funding agencies \u0097 within\nwhich language engineering is concerned with building\nspeech and language processing resources, and\ncomponents for integration into telematics systems.\nWhere languages meet computer science\nSpeech and language technology has a number of differentnames and perspectives. No single academic viewpoint is\nmore \u0090valid\u0091: there are at least as many language\nresearchers in computing as in linguistics departments.\nSpeech and language technology researchers additionally\nspan a wide range of related fields; at the University of\n\nDocument 75: An academic heritage\nThe history of research within various academic disciplines\ninto speech and language technology is a long one. Within\nuniversity linguistics departments, for example, compu-\ntational linguistics is a growing sub-field. Some linguists\nuse computers \u0097 in either research or teaching \u0097 as\npowerful tools for analysing or modelling aspects of\nlanguage. The grammar of English, for example, can be\nmodelled by a set of formal rules; used by a computer\nprogram to generate new sentences or parse a corpus of\ntest sentences. This application is comparable to\ngeneticists\u0091 use of computer models of gene-sequences or\ngeographers\u0091 use of computer maps and databases. \nIn a computer science department, natural language pro-\ncessing is seen \u0097 similarly to Artificial Intelligence, human-\ncomputer interaction, and multimedia \u0097 as a sub-field of\ncomputer science. Speech and language technology is a\npotentially powerful way to give us \u0090natural\u0091 communi-\n\nDocument 77: researchers in computing as in linguistics departments.\nSpeech and language technology researchers additionally\nspan a wide range of related fields; at the University of\nLeeds, for example, the Centre for Computer Analysis of\nLanguage And Speech (CCALAS) has had members\nworking in fields as diverse as Artificial Intelligence,\ncommunication studies, computer-based learning, com-\nputer studies, education, English, electrical engineering,Research labs\n14to desk-tops\nWhat stage of\ndevelopment has the\nlanguage machine\nreached?\nHow long before a\nlanguage machine is\nbundled with your\ndesk-top PC?SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":76,"situational_context":"A student is doing a research on the interconnection between language and computer science and needs help with understanding the COMP2121 Data Mining and Text Analytics module to further delve into the topic.","topic":"Language Machine Technology"}}
{"id":"2db026f1-217d-4edc-bc2f-656b6fe67e3d","question":"Hey, I'm preparing for my COMP2121 Data Mining and Text Analytics module and I'm having trouble understanding some key topics. Could you explain what machine learning is, specifically in the context of language technology?","reference_answer":"Machine learning is a sub-field of Artificial Intelligence. In the context of language technology, a machine learns behaviour through exposure to a 'training set' of examples. Natural-language learning systems learn how to analyse and process natural-language by being given examples of expected input together with appropriate analyses.","reference_context":"Document 86: Education The practical applications for speech and\nlanguage technology are many, and several are explored in\nthis book. But what of one of the first uses many people\nthink of for a language machine? Teaching and learning. . \nAlthough it is natural to assume that the needs of\nteaching and learning should contribute to the develop-\nment of language machines, this has not been the case, and\nindeed researchers and teachers still struggle to marry their\ndifferent disciplines. One reason is that the practical tasks\ninvolved in teaching languages to humans are\nfundamentally different from those involved in teaching\ncomputers. \nTeaching a machine \u0097 machine learning \u0097 is a sub-field of\nArtificial Intelligence. A machine learns behaviour through\nexposure to a \u0090training set\u0091 of examples. Natural-language\nlearning . systems thus learn how to analyse and process\nnatural-language by being given examples of expected\ninput together with appropriate analyses (Charniak, 1993;\nAtwell, 1996).\n\nDocument 145: professions. For example, language teachers who wish to\nuse CALL software incorporating speech recognition tech-\nnology may need to rethink approaches, and decide which\naspects of learning could be achieved more successfully by\nthe individual using the technology alone, and which\nlearning should remain within the classroom as a shared,\ngroup activity. Similarly, whole-school policies \u0097 of funding\nnew equipment, providing new learning spaces, and\nmanaging the politics of departmental resourcing \u0097 may\nneed to come under similar scrutiny if language machine\ntechnology is to be used more widely and successfuly in\neducation. \nProblem 6\nNewcomers need training and time to learn to\nuse the language machine \nOne supposed strength of the language machine is that\ncommunicating with a computer in spoken English is\n\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic\n\nDocument 157: Can problems be overcome?\nTaking a typical application \u0097 language teaching and\nlearning \u0097 can we imagine that the problems described in\nthis section will be overcome?\nClearly, full integration of the language machine is not\nforseeable in the immediate future. At the very least,\nlearners and teachers need to use computers confidently in\neveryday learning contexts. And, in its current state, the\nlanguage machine is not yet appropriate as a replacement\nfor some of the tasks undertaken by the language teacher. .\nYet as language technology improves, the boundary\nbetween tasks that can be delegated to the computer and\nthose that should be done only with a human language\nteacher will shift. The advent of widescale personal\ncomputing may also have an impact in terms of allowing\nstudents to use language machines to learn some aspects\nof language outside the classroom. It is likely that new\nways of teaching using computers will also spill into\nlanguage teaching from other areas of education.\n\nDocument 88: Machine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\nto plan and integrate the future use of language machines,\nwhether as a substitute for conventional human-to-human\ninteraction, or for the delivery of language teaching.the language machine\n17\n.Algorithms \u0087 Natural-language\nlearning \u0087 Hidden Markov Models\n\u0087 neural networks?\nSee Glossary, pages 58\u009759\nToo expensive\nto be useful? See page 28.English language teachers and\nlearners, according to a report on a\nsurvey of user requirements for\nthe ISLE project (ISLE, 1999)\ndesired, above all, a \u0090conversation\npractice machine\u0091 as an aid to\nlearning: with such a system a\nlearner could \u0090chat\u0091 in ordinary\nspoken English to practise every-\nday conversational language skills.\n.Natural-language learning\nsystems often use sophisticated\nstatistical pattern-matching models\n(for example Hidden Markov","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":86,"situational_context":"A university student is preparing for their COMP2121 Data Mining and Text Analytics module and needs help understanding key topics.","topic":"Language Machine Technology"}}
{"id":"496d267f-d361-4fa0-b5b6-c9ccd358af24","question":"Hey, I'm studying for an upcoming exam for the COMP2121 Data Mining and Text Analytics module and I need some details. Could you tell me what database management system the Sketch Engine is based on?","reference_answer":"The Sketch Engine is based on its own database management system called Manatee.","reference_context":"Document 498: automatically transformed into CQL queries which are then evaluated by the\nunderlying database engine to obtain the results from the corpus.7\nLexicographers often want to home in on a particular pattern of use to explore it\nfurther. This can be done with the Context options, as in Fig. 6.\nTo \ufb01nd all instances of catch that have pant orpants within \ufb01ve words, we search\nforcatch with pant in as a lemma \ufb01lter, with results as shown in Fig. 7.\nFig. 5 Query types\nFig. 6 Context \ufb01lters\nFig. 7 Concordance for catch with context \ufb01lter pant (lemma) within \ufb01ve words leftorright\n7Most databases are based on relational modelling and queried using Structured Query Language (SQL).\nHowever, for text, the sequence of words is the central fact, not the relations, so it is debatable whetherSQL databases are suitable. The Sketch Engine is based on its own database management system calledManatee (Rychly \u00b42000 ,2007 ) devised speci\ufb01cally for corpus linguistics. The web-based front end of","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":498,"situational_context":"A student is looking for detailed information about the COMP2121 Data Mining and Text Analytics module to prepare for an upcoming exam.","topic":"Sketch Engine Software"}}
{"id":"3e0d1570-1b32-4f3b-9ef8-b24a76c0203d","question":"As a researcher trying to understand the evolution and impact of language machines in society, could you tell me what the main topics covered in the book about language machines are?","reference_answer":"The book provides a survey of language machines, their history, and their place in our culture and expectations. It focuses particularly on machine translation and speech recognition, highlighting the histories and academic disciplines contributing to their development. It examines the components and technologies, possible pitfalls, main developers, current and potential uses, and predicted developments. It also paints some likely scenarios for the future impact of the language machine, focusing on current and prospective developments that could impact the demand in the marketplace for language teachers and language-based professions in the foreseeable future.","reference_context":"Document 274: Preface 5\nProgress and Prospects 5\nThe language machine 6\nSurveying the territory 6The impact? 6What\u0091s in a name? 7\nDescribing words: the technology 8What makes a language machine? 8Is it a language machine? 8\n... So is it SALT? 9\nTelling histories: 1791\u00972020 10Dreaming of speaking machines 10From Turing\u0091s child-machine to a 25 thousand dollar race 10\nWhen destiny calls, have the confidence to answer 11\nSeeing futures emerging 12To 2045: the BT Technology Calendar 12A widespread expectation 12* the wildcards? 13\nResearch labs to desk-tops 14\nAn academic heritage 14Where languages meet computer science 14Creating popular markets 16A use for everyone? 16The language of language processing 16\nTurning theory into practice 18\nWhy create language machines? 18What\u0091s involved: input to output 20Defining shared approaches 20Listen, analyse, understand 22full contents\n66click to goSITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 42: Contents\nThe language machine 6\nResearch labs to desk-tops 14\nTurning theory into practice 18\nThe problems with machines 28UK advantage? 38Real-life situations 44\nFuture scenarios 50\nGlossary 58References 60Questions for debate 64This season\u0091s\nmust-have: thewristwatch translatorSee page 53\nLanguage machines\nhelping withdisabilities See page 54What are the benefits\nto the UK of makingthe language machinework? See page 43SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 52: CALL Computer Assisted Language\nLearning\nHLT Human Languages Technology\nIT Information Technology\nMAT Machine Assisted Translation\nMT Machine Translation\nPC Personal Computer\nSLE Speech and Language Engineering\nSR Speech Recognition\nSALT \/ SLT Speech And Language\nTechnology\nWWW World Wide WebWhat\u0091s in a name?\nThis book is a survey of language\nmachines \u0097 what they are; where\nthey\u0091ve come from; the present-\nday research; implications for the\nlanguage industries; and the\nimpressive range of UK and EU\ncollaboration on speech and\nlanguage technology.\nThis book also explores another\ntheme \u0097 how language machines\nmay evolve from their present use\nin high-cost, high-specification\nsystems, to practical, everyday\ncontexts in education, industry,\nbusines and the home.\nGlossary?\nSee pages 58 & 59SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 47: Surveying the territory\nLanguage machines \u0097 machines that in some sense\nsimulate human language and human language behaviour\n\u0097 are used daily around us. Indeed, such machines already\nhave a long history, and have acquired a place in our\nculture and our expectations.\nThis book provides a survey of the current state of\nspeech and language technology, focusing particularly on\nmachine translation and speech recognition, highlighting\nthe histories and academic disciplines contributing to their\ndevelopment; it examines the components and tech-\nnologies; possible pitfalls; main developers; current and\npotential uses; predicted developments; and paints some\nlikely scenarios for the future impact of the language\nmachine. Finally, this book focuses on current and\nprospective developments that could have an impact on\ndemand in the marketplace for language teachers and\nlanguage-based professions in the foreseeable future.\nIt may help to define what constitutes \u0090the foreseeable","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":274,"situational_context":"A researcher is attempting to understand the evolution and impact of language machines in society.","topic":"Language Machine Translation"}}
{"id":"954702f5-b654-4296-a58a-b626fbb58997","question":"Hello, I'm an undergraduate student studying the COMP2121 module and I recently came across an interesting article about language detection in radio-telescope signals. Can you explain how this application of language detection is used in the search for Extra Terrestrials?","reference_answer":"Language detection is being applied to radio-telescope signals, to ascertain if language-like features exist within. If ever such a structure were to be detected it would be from an intelligent source.","reference_context":"Document 160: Is this scenario a realistic one?\nImplications for language\nprofessionals are explored on\npages 50\u009757.\nHal \u0097 the \ntalking computer\nmade evil\nSee page 35.Searching for Extra Terrestrials?\n\u0090Language detection is being\napplied to radio-telescope signals,\nto ascertain if language-like\nfeatures exist within ... if ever such\na structure were to be detected it\nwould be from an intelligent\nsource.\u0091  (Elliott, 1999)SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":160,"situational_context":"An undergraduate student is looking for information about text analytics for his COMP2121 module and stumbles upon a peculiar article about language detection in radio-telescope signals.","topic":"Language Machine Development"}}
{"id":"64ce9b4e-e0e8-4214-adad-6ca011168c59","question":"As an education student, I'm quite curious about the integration of language machines in teaching practices. Could you shed some light on the potential benefits that computers could bring to language learning and its future implications for the teaching field?","reference_answer":"Computers allow learners to choose their own speed of learning, their own method, and their own vocabulary to reflect their own interests. They may also enable individualized learning, which has been successful in subjects like maths and physics. As language technology improves, more tasks could be delegated to computers, allowing students to learn some aspects of language outside the classroom. New ways of teaching using computers may also influence language teaching.","reference_context":"Document 44: Preface\nHow will computers be used for language learning in 2020?\nWill we still be learning languages at all? This book goes\nsome way towards answering those questions.\nPotentially, computers let you choose your own speed of\nlearning, your own method, and your own vocabulary to\nreflect your own interests. The concept of \u0090the classroom\u0091,\nwhere learning takes place in groups for economic reasons,\nis itself under threat. The success of individual computer-\nbased learning in subjects such as maths and physics has\nalready proved that.\nBut isn\u0091t language a social skill? Language, yes.\nLanguage learning, not necessarily. Teachers may soon be\nable to concentrate on productive tasks, while the donkey\nwork of practice takes place between individuals and their\ncomputers.\nSo language use will never be replaced by machines?\nWe can\u0091t be sure of that either. This book shows how close\nwe are to Douglas Adams\u0091 babelfish becoming reality.\nThere is no point in suggesting that diplomats will never\n\nDocument 157: Can problems be overcome?\nTaking a typical application \u0097 language teaching and\nlearning \u0097 can we imagine that the problems described in\nthis section will be overcome?\nClearly, full integration of the language machine is not\nforseeable in the immediate future. At the very least,\nlearners and teachers need to use computers confidently in\neveryday learning contexts. And, in its current state, the\nlanguage machine is not yet appropriate as a replacement\nfor some of the tasks undertaken by the language teacher. .\nYet as language technology improves, the boundary\nbetween tasks that can be delegated to the computer and\nthose that should be done only with a human language\nteacher will shift. The advent of widescale personal\ncomputing may also have an impact in terms of allowing\nstudents to use language machines to learn some aspects\nof language outside the classroom. It is likely that new\nways of teaching using computers will also spill into\nlanguage teaching from other areas of education.\n\nDocument 226: Having misgivings? \nClearly, there is great potential for the language machine to\nbecome a normal component in the personal computing\n\u0090kit\u0091 that is now so easily and widely adopted \u0097 and\nexpected \u0097 by new generations.\nBut along with such easy adoption of new technology lie\nold fears \u0097 will machines replace humans? With the\nlanguage machine to assist them, who will want to learn\nlanguages or use the services of a human interpreter or\ntranslator? Even if large numbers of people want to learn\nEnglish for example, will their human teachers be replaced\nby language machine based self-tutoring software?\nLearners prefer the human touch  Even if we can afford the\nlanguage machines of the future, that does not mean we\nwill necessarily choose to use them. Language students, for\nexample, may prefer human interaction: even when\nlanguage machine-based software offers comprehensive\nEnglish language self-tutoring facilities, many students will","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":44,"situational_context":"An education student is curiously exploring the integration of language machines in teaching practices and its future implications for the field.","topic":"Language Machine Development"}}
{"id":"bea41ce9-3248-430b-8ed7-7c7b87813683","question":"What is a concordance and how does it differ from a word sketch?","reference_answer":"A concordance is an example of a particular word, lemma or phrase that appears repeatedly in the corpus, showing examples of its use in context, while a word sketch can be seen as a draft dictionary entry, where the system organizes all the recurring patterns for the word, ready for the lexicographer to edit, elucidate, and publish.","reference_context":"Document 494: This is usually enough to show why a collocate occurred in a word sketch.\nThe concordance is the basic tool for anyone working with a corpus. It shows you\nwhat is in your corpus. It takes you to the raw data, underlying any analysis. Gettingthere from a word sketch is just one of the ways of getting to a concordance. Thebasic method is from the simple search form, as in Fig. 3.\nThis is modelled on the Google search form. Users like a simple input form,\nwhere they put in what they are looking for, and the tool \ufb01nds it for them. It is for\nFig. 2 Concordance for caught with pants10 Lexicography ASIALEX (2014) 1:7\u201336\n123\n\nDocument 493: tables show us what we might be caught in (the cross \ufb01re, a trap, the headlights), on\n(videotape, CCTV), by andwith (your pants down). The \ufb01nal column takes us back\nto the police, with people being caught red-handed andunprepared.\nThe word sketch can be seen as a draft dictionary entry. The system has worked\nits way through the corpus to \ufb01nd all the recurring patterns for the word and has\norganised them, ready for the lexicographer to edit, elucidate, and publish. This ishow word sketches have been used since they were \ufb01rst produced.\n2.2 Concordance\nWhen looking at a word sketch, a user often wants to \ufb01nd out more: where and how,\nfor example, was catch used with with andpant? They can do this by clicking on the\nnumber, and seeing the concordance, as in Fig. 2.\nThis is usually enough to show why a collocate occurred in a word sketch.\nThe concordance is the basic tool for anyone working with a corpus. It shows you\n\nDocument 456: It's paid for, but you have it free. And it could do various things such as a word sketch, a summary \nof a word's behavior in collocations. Collocations is what words appear next to.  \nA concordance is an example of a particular word or lemma or phrase that appears repeatedly in \nthe corpus, and it shows you some examples of its use in context. A distributional thesaurus \nshows comparing the concordance of this word with the concordance of other words or other \nwords have got similar concordances. In other words, what other words appear in the same sorts \nof context as this word? And if they appear in the same similar context, they probably have similar \nmeanings.  \nCan also have a parallel corpus. If you've got a bilingual corpus, a corpus and its translation i nto \nanother language, then you can line up a word and its translation in various examples. Then we're \ngoing to look at WebBootCaT, which is a special tool for creating a specialised corpus of your own","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is a concordance?","answer":"A concordance is an example of a particular word or lemma or phrase that appears repeatedly in the corpus, and it shows you some examples of its use in context."},{"question":"What is a word sketch?","answer":"The word sketch can be seen as a draft dictionary entry. The system has worked its way through the corpus to find all the recurring patterns for the word and has organised them, ready for the lexicographer to edit, elucidate, and publish."}],"seed_document_id":494,"topic":"Sketch Engine Software"}}
{"id":"feb73bb5-3f15-4f42-b073-1343ce645445","question":"What is the minimum edit distance and how does it relate to the Levenshtein distance?","reference_answer":"The minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another. The Levenshtein distance is a specific type of minimum edit distance where each operation has a cost of 1, except for the substitution of a letter for itself, which has zero cost. Levenshtein also proposed an alternative version where substitutions are not allowed.","reference_context":"Document 423: seems like useful evidence for deciding that they might be coreferent.\nEdit distance gives us a way to quantify both of these intuitions about string sim-\nilarity. More formally, the minimum edit distance between two strings is de\ufb01nedminimum edit\ndistance\nas the minimum number of editing operations (operations like insertion, deletion,\nsubstitution) needed to transform one string into another.\nThe gap between intention andexecution , for example, is 5 (delete an i, substi-\ntuteeforn, substitute xfort, insertc, substitute uforn). It\u2019s much easier to see\nthis by looking at the most important visualization for string distances, an alignment alignment\nbetween the two strings, shown in Fig. 2.14. Given two sequences, an alignment is\na correspondence between substrings of the two sequences. Thus, we say Ialigns\nwith the empty string, NwithE, and so on. Beneath the aligned strings is another\nrepresentation; a series of symbols expressing an operation list for converting the\n\nDocument 425: 22 CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\nINTE*NTION\n||||||||||\n*EXECUTION\nd s s i s\nFigure 2.14 Representing the minimum edit distance between two strings as an alignment .\nThe \ufb01nal row gives the operation list for converting the top string into the bottom string: d for\ndeletion, s for substitution, i for insertion.\nWe can also assign a particular cost or weight to each of these operations. The\nLevenshtein distance between two sequences is the simplest weighting factor in\nwhich each of the three operations has a cost of 1 (Levenshtein, 1966)\u2014we assume\nthat the substitution of a letter for itself, for example, tfort, has zero cost. The Lev-\nenshtein distance between intention andexecution is 5. Levenshtein also proposed\nan alternative version of his metric in which each insertion or deletion has a cost of\n1 and substitutions are not allowed. (This is equivalent to allowing substitution, but","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the minimum edit distance?","answer":"The minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another."},{"question":"What is the Levenshtein distance?","answer":"The Levenshtein distance between two sequences is the simplest weighting factor in which each of the three operations has a cost of 1. The substitution of a letter for itself, for example, t for t, has zero cost. Levenshtein also proposed an alternative version of his metric in which each insertion or deletion has a cost of 1 and substitutions are not allowed."}],"seed_document_id":423,"topic":"Minimum Edit Distance Algorithm"}}
{"id":"bcaf8a8b-d9d1-4f63-9e1e-b9fa14129fb7","question":"Who is the publisher and who is the author of 'The Language Machine'?","reference_answer":"The British Council is the publisher of 'The Language Machine' and Eric Atwell is the author.","reference_context":"Document 41: Copyright ' The British Council 1999\nAll rights reseved. No part of this publication may be\nreproduced, stored in a retrieval system or transmitted in\nany form or by any means, electronic, mechanical,\nphotocopying, recording, or otherwise, without the prior\npermission of the copyright holder.\nPublished by The British Council\nhttp:\/\/www.britishcouncil.org\n10 Spring Gardens\nLondon SW1A 2BN\nUnited Kingdom\nDigital book production by Catchline\nhttp:\/\/www.english.co.uk\nThe Catchline team:\nEditorial director: Margaret Keeton\nPublishing manager: Sjanoche Wakely\nDesign consultant: Carlton Larode\nOriginal cover design by Carlton Larode\nRecommended citation reference: Eric Atwell (1999) The\nLanguage Machine . London: British Council\nISBN 0 86355 439 3(This digital book is also available in conventional print\nformat ISBN 0 86355 438 5)production creditsSITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 42: Contents\nThe language machine 6\nResearch labs to desk-tops 14\nTurning theory into practice 18\nThe problems with machines 28UK advantage? 38Real-life situations 44\nFuture scenarios 50\nGlossary 58References 60Questions for debate 64This season\u0091s\nmust-have: thewristwatch translatorSee page 53\nLanguage machines\nhelping withdisabilities See page 54What are the benefits\nto the UK of makingthe language machinework? See page 43SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"Who is the publisher of 'The Language Machine'?","answer":"The British Council is the publisher of 'The Language Machine'."},{"question":"Who is the author of 'The Language Machine'?","answer":"Eric Atwell is the author of 'The Language Machine'."}],"seed_document_id":41,"topic":"Others"}}
{"id":"417cab42-a7f3-4175-9a91-4f0c5a069b98","question":"What are the CHILDES and Talkbank projects and how many languages does the CHILDES corpus in the Sketch Engine cover?","reference_answer":"Since 1984, the CHILDES and Talkbank projects, based at Carnegie Mellon University, have been gathering child\u2013adult conversations, largely between babies and young children and their carers, available as transcripts, and many also as audio or video. The CHILDES corpus in the Sketch Engine covers 22 languages, varying in size from a few thousand words to, for English, 23 million.","reference_context":"Document 532: 5.1.5 Learning to speak\nSince 1984, the CHILDES and Talkbank projects, based at Carnegie Mellon\nUniversity, have been gathering child\u2013adult conversations.\n24They are largely\nbetween babies and young children and their carers (with many of the carers beinglinguists, who have taken on the recording and transcription of the data). All areavailable as transcripts, and many also as audio or video. The data can be exploredon the Talkbank website as well as the Sketch Engine: the two websites arecomplementary, with Talkbank expecting the user to be a developmental or generallinguist, and the Sketch Engine expecting them to have a corpus orientation. There\nis a CHILDES corpus in the Sketch Engine for 22 languages, varying in size from a\nfew thousand words to, for English, 23 million.\n5.1.6 Learning to read and write\nEducators, children\u2019s authors and publishers, and linguists and psychologists","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What are the CHILDES and Talkbank projects?","answer":"Since 1984, the CHILDES and Talkbank projects, based at Carnegie Mellon University, have been gathering child\u2013adult conversations. They are largely between babies and young children and their carers. All are available as transcripts, and many also as audio or video."},{"question":"How many languages does the CHILDES corpus in the Sketch Engine cover?","answer":"There is a CHILDES corpus in the Sketch Engine for 22 languages, varying in size from a few thousand words to, for English, 23 million."}],"seed_document_id":532,"topic":"Others"}}
{"id":"a0f3a029-5349-4ae6-b18e-e8b32f88c34a","question":"What is the role of the '*' character in a regular expression and how are special characters referred to in these expressions?","reference_answer":"'*' represents zero or more occurrences of the previous character or expression in a regular expression. Special characters are referred to by special notation based on the backslash (\\), such as the newline character referred as '\\n' and the tab character as '\\t'.","reference_context":"Document 369: rences of the previous expression. REs for counting are summarized in Fig. 2.9.\nRE Match\n* zero or more occurrences of the previous char or expression\n+ one or more occurrences of the previous char or expression\n? exactly zero or one occurrence of the previous char or expression\n{n} noccurrences of the previous char or expression\n{n,m} from ntomoccurrences of the previous char or expression\n{n,} at least noccurrences of the previous char or expression\n{,m} up to moccurrences of the previous char or expression\nFigure 2.9 Regular expression operators for counting.\nFinally, certain special characters are referred to by special notation based on the\nbackslash ( \\) (see Fig. 2.10). The most common of these are the newline character newline\n\\nand the tabcharacter\\t. To refer to characters that are special themselves (like\n.,*,[, and\\), precede them with a backslash, (i.e., \/\\.\/ ,\/\\*\/ ,\/\\[\/ , and\/\\\\\/ ).","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the role of the '*' character in a regular expression?","answer":"'*' represents zero or more occurrences of the previous character or expression in a regular expression."},{"question":"How are special characters referred to in regular expressions?","answer":"Special characters are referred to by special notation based on the backslash (\\). For example, the newline character is referred as '\\n' and the tab character as '\\t'."}],"seed_document_id":369,"topic":"Regular Expressions"}}
{"id":"07fd9f51-3b30-4d79-8f14-41ea3444ff07","question":"What is the standard method for tokenization in language processing and what is an example of a tool that can be used for this process?","reference_answer":"The standard method for tokenization is to use deterministic algorithms based on regular expressions compiled into very efficient finite state automata, and an example of a tool that can be used for this process is the nltk.regexp_tokenize function of the Python-based Natural Language Toolkit (NLTK).","reference_context":"Document 400: 16 CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\nInput :\"The San Francisco-based restaurant,\" they said,\n\"doesn\u2019t charge $10\".\nOutput :\"TheSanFrancisco-based restaurant ,\"theysaid,\n\"doesn\u2019tcharge $10\".\nIn practice, since tokenization needs to be run before any other language pro-\ncessing, it needs to be very fast. The standard method for tokenization is therefore\nto use deterministic algorithms based on regular expressions compiled into very ef-\n\ufb01cient \ufb01nite state automata. For example, Fig. 2.12 shows an example of a basic\nregular expression that can be used to tokenize with the nltk.regexp tokenize\nfunction of the Python-based Natural Language Toolkit (NLTK) (Bird et al. 2009;\nhttp:\/\/www.nltk.org ).\n>>> text = 'That U.S.A. poster-print costs $12.40... '\n>>> pattern = r '''(?x) # set flag to allow verbose regexps\n... ([A-Z]\\.)+ # abbreviations, e.g. U.S.A.\n... | \\w+(-\\w+)* # words with optional internal hyphens","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the standard method for tokenization in language processing?","answer":"The standard method for tokenization is to use deterministic algorithms based on regular expressions compiled into very efficient finite state automata."},{"question":"What is an example of a tool that can be used for tokenization?","answer":"An example of a tool that can be used for tokenization is the nltk.regexp_tokenize function of the Python-based Natural Language Toolkit (NLTK)."}],"seed_document_id":400,"topic":"Text Processing and Regular Expressions"}}
{"id":"386a08b7-1371-4ec4-a05c-6ddc9e8c9a71","question":"How are accuracy and recall related in text analytics and what is the role of regular expressions in this field?","reference_answer":"Accuracy and recall are different metrics in text analytics that can pull in opposite directions, with accuracy focusing on minimizing false positives and recall on minimizing false negatives. Regular expressions play a crucial role in text analytics, as they can be used in sophisticated sequences for text processing, sometimes even replacing the need for machine learning.","reference_context":"Document 301: \u00a9 University of Leeds   4 of 14  And these two sorts of errors are antagonistic. That means they pull in opposite directions. If you \nwant to increase accuracy or precision, that means you want to minimi se the false positives. You \nwant to get a high accuracy -- anything you predict as being the, you do really want it to be the.  \nOn the other hand, you may want to increase recall. That is all the real examples of the, you want \nto capture them. So that's minimizing false negatives. So recall and precision are different metrics \nand they pull in opposite directions potentially.  \nOK, so in summary, regular expressions are surprisingly important in text analytics. You often \nhave quite sophisticated sequences of regular expressions, and they can be quite good at doing \nsome sort of text processing. You don't really need machine learning, except for more \nsophisticated problems.  \nYou can get away without doing any machine learning by doing quite complicated regular","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the relationship between accuracy and recall in text analytics?","answer":"Accuracy and recall are different metrics in text analytics that can pull in opposite directions. If you want to increase accuracy or precision, that means you want to minimize the false positives. On the other hand, if you want to increase recall, that means you want to minimize false negatives."},{"question":"What is the role of regular expressions in text analytics?","answer":"Regular expressions are surprisingly important in text analytics. They can be used in sophisticated sequences and can be quite good at doing some sort of text processing. In some cases, you can get away without doing any machine learning by doing quite complicated regular expressions."}],"seed_document_id":301,"topic":"Text Processing and Regular Expressions"}}
{"id":"c5023504-d9af-4f48-a257-97149e56d1c8","question":"What is the purpose of optical character recognition (OCR) in language machines and what is a 'lemmatiser' used for in language analysis?","reference_answer":"In language machines, optical character recognition (OCR) is used to recognize typed or printed text, interpret the image, and convert it into an Ascii text file. Meanwhile, a 'lemmatiser' is used in language analysis to compute the root (or lemma) for any input word.","reference_context":"Document 104: difficulties by highlighting specific phonemes where the\nlearner deviates from the model.\nWritten or printed language input  Another way to produce\nwritten text \u0097 or, rather, printed text \u0097 is to type it into a\nword processor, email or desktop publishing package. For\nmany people, however, a lack of keyboard skills can make\nusing a computer a daunting, slow or potentially\nembarrassing task. The text may also exist in typed or\nprinted form, but the \u0090electronic\u0091 copy may not be available\nor in a usable file format.\nTo address these scenarios, language machines need\ntechniques for recognising handwritten script and\nincorporating optical character recognition (OCR). In the\ncase of OCR, text is scanned and the image is then\ninterpreted and converted into an Ascii text file. Most OCR\npackages can be trained to recognise particular fonts or\ntypefaces to reduce errors in interpretion: applying a spell-\nchecker to the initial output will often further reduce\ntranscription errors.\n\nDocument 105: packages can be trained to recognise particular fonts or\ntypefaces to reduce errors in interpretion: applying a spell-\nchecker to the initial output will often further reduce\ntranscription errors. \nHandwritten text can present more daunting problems:\nfew people\u0091s handwriting is as consistent \u0097 or as clearly\nlegible \u0097 as a typeface, and the recognition techniques must\nalso take into account joining strokes and other variables.\nLanguage analysis and understanding  Whether language is\ninput as speech, by scanning, in writing or typed via a\nkeyboard, the next stage involves linguistic analysis of the\ncharacter-sequences. \nWords must be first identified in a computer dictionary\nusing a \u0090lemmatiser\u0091, which computes the root (or lemma)\nfor any input word. The dictionary may also be used by a\npart-of-speech tagger (see page 48) , which computes the\ngrammatical word-class of each word, and by a semantic\ntagger, which annotates each input word with a represen-","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the purpose of optical character recognition (OCR) in language machines?","answer":"In language machines, optical character recognition (OCR) is used to recognize typed or printed text. The text is scanned, and the image is then interpreted and converted into an Ascii text file."},{"question":"What is a 'lemmatiser' used for in language analysis?","answer":"A 'lemmatiser' is used in language analysis to compute the root (or lemma) for any input word."}],"seed_document_id":104,"topic":"Others"}}
{"id":"6538163c-6b39-4cc4-a874-179b0d197670","question":"What is the potential benefit of machine translation for visually impaired individuals and what is the future expectation for it?","reference_answer":"For the visually impaired, machine translation offers the greatest liberation since Braille and audio-cassettes by providing independent access to information. In the future, it is expected that machine translation will be used alongside good teaching and translation.","reference_context":"Document 236: to provide thought-provoking ideas.\u0091\nSimilarly, this book, The Language Machine , aims to\nprovide background information and fuel for ideas. How\nmight we develop the language machine? Can it be\nexploited for commercial benefit? What practical uses will it\nhave for people . whoever they are? Here we identify ways\nforward to continue the debate.leading the way\n56the next steps\nVerdicts on\nmachine translation\nSee page 37\n.Future development of language\nmachine technology must include\npeople who actively use the\nproducts for ordinary tasks \u0097 as\nhighlighted here by Derek Child,\nAssistant Director Equal Oppor-\ntunities, The Open University.\n\u0090For the visually impaired, indepen-\ndent access to information has\nalways been a barrier, and ICT\noffers the greatest liberation since\nBraille and audio-cassettes. But\ncompared to older text-based\nsystems, the visually-oriented\nGraphic User Interfaces can raise\nnew barriers.\nThe conventions set out by RNIB\nmight inform future software\n\nDocument 228: difficult to believe that its overall command of English will\nmatch (let alone exceed) that of an advanced learner of\nEnglish, even in 20 years\u0091 time. Translators and teachers \u0097\ncapable of judging social language, multiple meanings,\nnuance, subtle forms, and language complexities \u0097 do not\nneed therefore to fear they will be easily replaced!\nMore probably, machine translation will be used\nalongside good teaching and translation. It is used alreadyquestioning\n54the future\nThe digital\nhelping hand\nLanguage machines can help\ndisabled people to more easily\naccess technology: the following\nindicates some present activities.\nThe Royal National Institute for\nthe Blind (www.rnib.org.uk) offers\nextensive information on speech\nsynthesis packages and suppliers.\nThe EU\u0091s ISEAUS project aims to\nuse language engineering in\nspeech education and rehabil ita-\ntion for adults with lifelong or\nacquired deafness (see page 63).\nThe funding body EPSRC actively\nencourages researchers to work\n\nDocument 88: Machine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\nto plan and integrate the future use of language machines,\nwhether as a substitute for conventional human-to-human\ninteraction, or for the delivery of language teaching.the language machine\n17\n.Algorithms \u0087 Natural-language\nlearning \u0087 Hidden Markov Models\n\u0087 neural networks?\nSee Glossary, pages 58\u009759\nToo expensive\nto be useful? See page 28.English language teachers and\nlearners, according to a report on a\nsurvey of user requirements for\nthe ISLE project (ISLE, 1999)\ndesired, above all, a \u0090conversation\npractice machine\u0091 as an aid to\nlearning: with such a system a\nlearner could \u0090chat\u0091 in ordinary\nspoken English to practise every-\nday conversational language skills.\n.Natural-language learning\nsystems often use sophisticated\nstatistical pattern-matching models\n(for example Hidden Markov","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the potential benefit of machine translation for visually impaired individuals?","answer":"For the visually impaired, independent access to information has always been a barrier, and ICT offers the greatest liberation since Braille and audio-cassettes."},{"question":"What is the future expectation for machine translation?","answer":"More probably, machine translation will be used alongside good teaching and translation."}],"seed_document_id":236,"topic":"Language Machine Translation"}}
{"id":"31f4c8b9-8ef1-4bb8-b18a-bd8825d8dab7","question":"What is often used as input for most Chinese NLP tasks and what is the standard segmentation algorithms for Japanese and Thai languages?","reference_answer":"For most Chinese NLP tasks, it works better to take characters rather than words as input, while the standard segmentation algorithms for Japanese and Thai use neural sequence models trained via supervised machine learning on hand-segmented training sets.","reference_context":"Document 404: 2.4 \u2022 T EXT NORMALIZATION 17\n(2.7)\u59da\nYao\u660e\nMing\u8fdb\nenter\u5165\nenter\u603b\noverall\u51b3\ndecision\u8d5b\ngame\nIn fact, for most Chinese NLP tasks it turns out to work better to take characters\nrather than words as input, since characters are at a reasonable semantic level for\nmost applications, and since most word standards, by contrast, result in a huge vo-\ncabulary with large numbers of very rare words (Li et al., 2019).\nHowever, for Japanese and Thai the character is too small a unit, and so algo-\nrithms for word segmentation are required. These can also be useful for Chineseword\nsegmentation\nin the rare situations where word rather than character boundaries are required. The\nstandard segmentation algorithms for these languages use neural sequence mod-\nelstrained via supervised machine learning on hand-segmented training sets; we\u2019ll\nintroduce sequence models in Chapter 8 and Chapter 9.\n2.4.3 Byte-Pair Encoding for Tokenization\nThere is a third option to tokenizing text. Instead of de\ufb01ning tokens as words","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is often used as input for most Chinese NLP tasks?","answer":"For most Chinese NLP tasks it turns out to work better to take characters rather than words as input."},{"question":"What is the standard segmentation algorithms for Japanese and Thai languages?","answer":"The standard segmentation algorithms for these languages use neural sequence models trained via supervised machine learning on hand-segmented training sets."}],"seed_document_id":404,"topic":"Others"}}
{"id":"2dd8cdc9-d712-49d2-9d8f-098fb7b2784a","question":"What is a regular expression and what is the function of the Unix command-line tool grep that uses it?","reference_answer":"A regular expression is an algebraic notation for characterizing a set of strings, particularly useful for searching in texts. The Unix command-line tool grep utilizes regular expressions to return every line of the input document that matches the given expression.","reference_context":"Document 348: cessing tools like the Unix tools grep or Emacs. Formally, a regular expression is\nan algebraic notation for characterizing a set of strings. They are particularly use-\nful for searching in texts, when we have a pattern to search for and a corpus of corpus\ntexts to search through. A regular expression search function will search through the\ncorpus, returning all texts that match the pattern. The corpus can be a single docu-\nment or a collection. For example, the Unix command-line tool grep takes a regular\nexpression and returns every line of the input document that matches the expression.\nA search can be designed to return every match on a line, if there are more than\none, or just the \ufb01rst match. In the following examples we generally underline the\nexact part of the pattern that matches the regular expression and show only the \ufb01rst\nmatch. We\u2019ll show regular expressions delimited by slashes but note that slashes are\nnotpart of the regular expressions.","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is a regular expression?","answer":"A regular expression is an algebraic notation for characterizing a set of strings. They are particularly useful for searching in texts, when we have a pattern to search for and a corpus of texts to search through."},{"question":"What is the function of the Unix command-line tool grep?","answer":"The Unix command-line tool grep takes a regular expression and returns every line of the input document that matches the expression."}],"seed_document_id":348,"topic":"Regular Expressions"}}
{"id":"5000417c-d9b3-4c99-a140-9f4de815d6c1","question":"Who created the first 'talking head' and when, and what significant prediction about artificial intelligence did Alan Turing make in his 1950 paper 'Computing Machinery and Intelligence'?","reference_answer":"The British scientist Charles Wheatstone created an improved model of the Kempelen machine, which was later used by Alexander Graham Bell to produce his own 'talking head' in 1863. In his 1950 paper 'Computing Machinery and Intelligence', Alan Turing predicted that a program could imitate human conversation so well that an average human interrogator would not have more than a 70% chance of identifying it as a computer after five minutes of questioning.","reference_context":"Document 64: fraud, powered by a chess-playing dwarf.\nSome years later the British scientist Charles Wheatstone\ncreated an improved model of the Kempelen machine,\nwhich was later to capture the imagination of Alexander\nGraham Bell \u0097 the inventor of the telephone. In 1863 Bell\nproduced his own \u0090talking head\u0091. The device could articulate\nthe sound \u0090mama\u0091 sufficiently clearly to cause a neighbour\nto enquire after the baby\u0091s welfare.\nPerhaps it is unclear whether these experiments and\ndevelopments belong to the realm of science, technology,\nmusic, magic, or public entertainment (Bell\u0091s brother\nMelville once took to the Edinburgh stage with a false beard\nand foreign accent to demonstrate one machine), but all\nthese early attempts at speech synthesis arose from\nattempts to reproduce the articulatory apparatus of a\nhuman vocal tract, using bellows and resonating chambers.\nIt was not until after World War II, when the science of\nacoustic analysis was more developed, that an alternative\n\nDocument 61: produce mechanical \u0090talking heads\u0091. In 1791 for example,\nWolfgang von Kempelen \u0097 an inventor from Bratislava \u0097\ncreated a device with bellows which could create human-\nlike sounds. Although the device might now be called a\nrudimentary speech synthesiser, the machine was not taken\nas seriously as it might have been. Von Kempelen had\nearlier attempted to create an intelligent machine that could\noutplay a human at chess. The machine turned out to be atelling histories\n101791 \u0097 2020\nFrom Turing\u0091s child-machine to a 25 thousand dollar race\n\u0090In 1950, Computing Machinery and Intelligence, a famous paper by British pioneer Alan Turing, postulated a\nprogram that could imitate human conversation so well that \u0094an average human interrogator will not have\nmore than 70% chance of making the right identification [as between human and computer] after five minutes\nof questioning\u0095. He predicted this 70% level for around 2000. \u0087\n\nDocument 65: human vocal tract, using bellows and resonating chambers.\nIt was not until after World War II, when the science of\nacoustic analysis was more developed, that an alternative\napproach of synthesising speech sounds directly became\npossible. And it was not until the 1970s that synthesis of a\nfemale voice was successfully achieved.\nThe state of the art today, . which includes \u0090speech\nmorphing\u0091, allows the speaking and singing voices of\nparticular individuals to be mimicked by computers. Like\nthe discreet digital changes to photographs that can\nremove and add objects or body parts to the finished\npicture, the modern \u0090speaking machines\u0091 raise important\nethical questions: how much trust should we have in what\nwe hear? Do we have any rights to our own vocal\nidentity? .the language machine\n11\nWhen destiny calls, have the confidence to answer\n\u0090In 1876, Bell and Watson demonstrated their new device to Western Union, but the company\u0091s executives\n\nDocument 63: with basics\nSee pages 8 & 9\n1791 Kempelen\u0091s speaking machine\n1863 Bell\u0091s \u0090talking head\u0091\n1872 Edison invents electric typewriter\n1876 Bell patents telephone\n1887 Sound recording machines invented\n1939 Bell Telephones demonstrates Voder\nspeech synthesis machine\n1950 \u0090Turing test\u0091 proposed\n1970 Successful synthesis of female voice\n1976 EC begins development of Machine\nTranslation technology\n1977 Texas Instruments produce Speak &\nSpell toy with voice synthesis \n1984 Apricot computers in UK build\nspeech recognition into portable PC\n1993 Apple Newton Personal Digital\nAssistant uses handwritten input\n1994 British National Corpus compiled\n1997 Altavista\/Digital provide free web\ntranslation service\n2020 Maria Callas sings the Sex Pistols?SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"Who created the first 'talking head' and when?","answer":"The British scientist Charles Wheatstone created an improved model of the Kempelen machine, which was later used by Alexander Graham Bell to produce his own 'talking head' in 1863."},{"question":"What significant prediction did Alan Turing make in his 1950 paper 'Computing Machinery and Intelligence'?","answer":"Alan Turing predicted that a program could imitate human conversation so well that an average human interrogator would not have more than a 70% chance of identifying it as a computer after five minutes of questioning."}],"seed_document_id":64,"topic":"Others"}}
{"id":"b82277db-6c33-4e99-8a5d-9435a6b1f4aa","question":"What is a potential concern for language teachers and professionals regarding machine translation and what is the current limitation of these systems?","reference_answer":"A potential concern for language teachers and professionals is whether machine translation could make language-learning redundant, however, current systems remain imperfect and direct communication in a shared language is often preferable in many situations.","reference_context":"Document 113: language learners can clearly benefit from access to\n\u0090language-aware\u0091 functions in word processors, although\nthey do need to be aware of their possible fallibility. \nMultilinguality A machine translation (MT) system\ntranslates text from one language into another, and may\neven deal with spoken input or output. They may also\ninvolve language identification: determining which\nlanguage is being used given a printed or spoken signal.\nMost research has concentrated on English and, to a lesser\nextent, other European languages. For languages and\nlanguage-pairs that have no comprehensive machine-\ntranslation system, tools for machine-assisted translation \u0097\nsuch as bilingual dictionaries and term-banks \u0097 may be\nuseful. \nAn obvious potential concern for language teachers and\nlanguage professionals, such as interpreters and\ntranslators, is whether MT (and the language machine in a\nbroader sense) could make language-learning \u0097 and hence\nlanguage teachers \u0097 redundant. .\n\nDocument 114: language professionals, such as interpreters and\ntranslators, is whether MT (and the language machine in a\nbroader sense) could make language-learning \u0097 and hence\nlanguage teachers \u0097 redundant. .\nCurrent MT systems remain imperfect, and there are still\nmany social, business and political situations in which\nbeing able to communicate directly in a shared language is\ngreatly preferable to computer-mediated communication.talk back\n24and translate\n.Thinking computers?  The annual\nLoebner Prize, evolved in part from\nTuring\u0091s ideas, offers a prize for the\n\u0090most human computer\u0091.\nContestants are currently limited to\nkeyboard input and on-screen\nreplies, but the longer-term aim of\nthe contest is to progress to\nspoken dialogue input and replies \u0097\nin effect, an English language\nconversation.\n.Redundant?  MT \u0090only works well\nwith simplified source texts, or to\nproduce a \u0094gist\u0095 version ... of\ndocuments that, for economic\nreasons, would otherwise never be\ntranslated at all. There is certainly\n\nDocument 161: the language machine\n37\nMachine translation? Speech recognition? Do they work?\nThe ease with which it is possible to find fault with any new technology is a significant factor in its\ntake-up. Students of machine translation, for example, are often given examples of mistranslation,\nsuch as: \u0090The spirit is willing but the flesh is weak\u0091 translated first into Russian and then into\nEnglish: \u0090The vodka is good but the meat is bad.\u0091 Many such examples can be found, which\nperhaps distort the successes of language technologies. But what do the professionals say?\nBecause quality is so uneven, monolingual users are advised to resort to MT only for \u0090inbound\u0091\nwork \u0097 texts being translated into their own language. In this case, they can see what they are\ngetting, warts and all, and guess at the rest without offending potential clients\u0091 linguistic\nsensibilities. Unedited MT is simply not good enough for \u0090outbound\u0091 work such as promotional\n\nDocument 88: Machine translation systems are now widely used for gist\nor \u0090first-draft\u0091 translation.\nWhatever the application area, language practitioners\nand linguistic professionals should be involved in helping\nto plan and integrate the future use of language machines,\nwhether as a substitute for conventional human-to-human\ninteraction, or for the delivery of language teaching.the language machine\n17\n.Algorithms \u0087 Natural-language\nlearning \u0087 Hidden Markov Models\n\u0087 neural networks?\nSee Glossary, pages 58\u009759\nToo expensive\nto be useful? See page 28.English language teachers and\nlearners, according to a report on a\nsurvey of user requirements for\nthe ISLE project (ISLE, 1999)\ndesired, above all, a \u0090conversation\npractice machine\u0091 as an aid to\nlearning: with such a system a\nlearner could \u0090chat\u0091 in ordinary\nspoken English to practise every-\nday conversational language skills.\n.Natural-language learning\nsystems often use sophisticated\nstatistical pattern-matching models\n(for example Hidden Markov","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is a potential concern for language teachers and professionals regarding machine translation?","answer":"A potential concern for language teachers and professionals is whether machine translation could make language-learning and hence language teachers redundant."},{"question":"What is the current limitation of machine translation systems?","answer":"Current machine translation systems remain imperfect, and there are still many social, business and political situations in which being able to communicate directly in a shared language is greatly preferable to computer-mediated communication."}],"seed_document_id":113,"topic":"Language Processing Technology"}}
{"id":"0eef9775-9f72-4eb4-b162-5c6ba909409c","question":"Who wrote the paper on 'Neural machine translation of rare words with subword units' and what is the 'Regular expression search algorithm' paper about?","reference_answer":"The paper on 'Neural machine translation of rare words with subword units' was written by R. Sennrich, B. Haddow, and A. Birch in 2016, while the 'Regular expression search algorithm' paper, written by K. Thompson in 1968, presumably discusses an algorithm for searching using regular expressions.","reference_context":"Document 452: gram , 14(3):130\u2013137.\nSchuster, M. and K. Nakajima. 2012. Japanese and korean\nvoice search. ICASSP .\nSennrich, R., B. Haddow, and A. Birch. 2016. Neural ma-\nchine translation of rare words with subword units. ACL.\nSimons, G. F. and C. D. Fennig. 2018. Ethnologue: Lan-\nguages of the world, 21st edition. SIL International.\nSolorio, T., E. Blair, S. Maharjan, S. Bethard, M. Diab,\nM. Ghoneim, A. Hawwari, F. AlGhamdi, J. Hirschberg,\nA. Chang, and P. Fung. 2014. Overview for the \ufb01rst\nshared task on language identi\ufb01cation in code-switched\ndata. First Workshop on Computational Approaches to\nCode Switching .\nThompson, K. 1968. Regular expression search algorithm.\nCACM , 11(6):419\u2013422.","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"Who wrote the paper on 'Neural machine translation of rare words with subword units'?","answer":"The paper was written by R. Sennrich, B. Haddow, and A. Birch in 2016."},{"question":"What is the 'Regular expression search algorithm' paper about?","answer":"The 'Regular expression search algorithm' paper, written by K. Thompson in 1968, presumably discusses an algorithm for searching using regular expressions, but further details are not provided in the context."}],"seed_document_id":452,"topic":"Others"}}
{"id":"3baa92c8-430c-429f-bf8e-de4f1a68dc96","question":"What tasks are considered too complicated for robots to learn and why did the prediction of full voice interaction with machines by 2005 not fully come true?","reference_answer":"Tasks such as cleaning a house or cooking a meal are considered too complicated for robots to learn. As for voice interaction with machines, while it is possible, most of the time when people use a computer, they're using a touch screen or a keyboard, not talking to it.","reference_context":"Document 33: the easy things could be done by robots - was actually it's very complicated to clean a house or to \ncook a meal. And it's far too complicated for robots to learn. Robots can do things like building \ncars. I used to work in a car factory making V auxhall cars, and that job is now gone. The robots \nhave taken over. In fact, if by 2012 robots will be available for almost any job at home or in \nhospitals. Again hospital cleaners and hospital nurses, again that hasn't happened. Those are \nactually for AI,  the difficult things. They may be semi -skilled or not valued for human labor, but it's \nfar too difficult for robots to do this.  \nThey thought by 2018 AI would be imitating thinking process of the brain. Well, we know what that \nmeant. So we don't know if that's true or not. But certainly by 2025, they thought that thought \nrecognition would be useful for input output. You wouldn't need to type, or use a touch screen, or\n\nDocument 32: able to type in a document to get your CV, but there are jobs around where it's not necessary. By \n2005, they thought there'd be full voice interaction with machines. Well, OK, you can talk to \ncomputers for some purposes. But most of the time when you use the computer, you're actually \nprobably using a touch screen or a keyboard. You're not talking to it. So that didn't really take off.  \nThey said by 2007, there'd be domestic robots, small attractive robots everywhere in all homes. \nWell, OK, some homes have got a robot vacuum cleaner, but it tends to be not very good. I mean, \nit doesn't actually pick up much dust. It's not very intelligent. It's not very functional.  \nSo again, robots did not take off. And this is partly because domestic duties are-  they thought that \nthe easy things could be done by robots - was actually it's very complicated to clean a house or to \ncook a meal. And it's far too complicated for robots to learn. Robots can do things like building","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What tasks are considered too complicated for robots to learn?","answer":"Tasks such as cleaning a house or cooking a meal are considered too complicated for robots to learn."},{"question":"Why did the prediction of full voice interaction with machines by 2005 not fully come true?","answer":"While voice interaction with machines is possible, most of the time when people use a computer, they're using a touch screen or a keyboard, not talking to it."}],"seed_document_id":33,"topic":"Language and Speech Technology"}}
{"id":"280eacdd-3158-4c5f-a767-359f399a5047","question":"What is a possible way to interpret Chinese sentences and why can't the number of words in English translation be assumed for the Chinese text?","reference_answer":"In Chinese, it is possible to ignore words altogether and use characters as the basic elements, treating the sentence as a series of characters. You can't just take the English translation and assume that if the English translation is 5 words, or 3 words, then the Chinese has 5 words, because maybe conceptually Chinese thinks differently than English.","reference_context":"Document 403: segmentation):\n(2.5)\u59da\u660e\nYaoMing\u8fdb\u5165\nreaches\u603b\u51b3\u8d5b\n\ufb01nals\nor as 5 words (\u2018Peking University\u2019 segmentation):\n(2.6)\u59da\nYao\u660e\nMing\u8fdb\u5165\nreaches\u603b\noverall\u51b3\u8d5b\n\ufb01nals\nFinally, it is possible in Chinese simply to ignore words altogether and use characters\nas the basic elements, treating the sentence as a series of 7 characters:\n\nDocument 331: this character sequence must be 5 words.  \nBut actually you might say on the other hand that, this sequence of -- Yao Ming is one word, \nreaches is one word, the Chinese doesn't really have a word for the, it's just final. So that looks \nlike it's three words. Howev er you might say Yao Ming is two words, it's not just one word. And \nfinals is divided into overall finals, because overall finals means the overall last thing that you're \ndoing.  \nSo it depends on conceptually how you analyze the words. You can't just take t he English \ntranslation and assume that if the English translation is 5 words, or 3 words, then the Chinese has \n5 words. Because maybe conceptually Chinese thinks differently than English.","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the possible way to interpret Chinese sentences?","answer":"It is possible in Chinese simply to ignore words altogether and use characters as the basic elements, treating the sentence as a series of characters."},{"question":"Why can't the number of words in English translation be assumed for the Chinese text?","answer":"You can't just take the English translation and assume that if the English translation is 5 words, or 3 words, then the Chinese has 5 words. Because maybe conceptually Chinese thinks differently than English."}],"seed_document_id":403,"topic":"Text Analysis and Tokenization"}}
{"id":"f04f6e0a-0787-4f13-b0a7-2dc026dfe790","question":"What languages can AltaVista's machine translation service translate to and from, and what is the purpose of its world-wide index?","reference_answer":"AltaVista's machine translation service can translate Web pages from English to French, German, Spanish, Italian and Portuguese or vice versa, and its world-wide index allows users to search across the Web in their own language from one central location by translating the characters within documents into a standard encoding system, Unicode.","reference_context":"Document 196: World Wide Web translation  \u0090AltaVista, which is owned by\ncomputer giant Digital, launched a free machine translation\nservice on the Internet at the beginning of 1998. The service\nis able to translate Web pages from English to French,\nGerman, Spanish, Italian and Portuguese or vice versa\nalmost instantaneously. The results are far from perfect, but\ngood enough to give the gist of a Web page. In May,\nAltaVista followed this coup up with the launch of a single\nworld-wide index, which allows even Chinese, Japanese\nand Korean users to search across the Web in their own\nlanguage from one central location ... The index translates\nthe characters within documents into a standard encoding\nsystem, Unicode, so that it can identify words in languages\nas diverse as Chinese, Japanese, Korean, Cyrillic, Greek,\nHebrew, Arabic and Turkish, . as well as western European\nlanguages.\u0091 (Pringle, 1998) (See pages 31, 37)\nEmail translation  \u0090The most dramatic change of all has","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What languages can AltaVista's machine translation service translate to and from?","answer":"AltaVista's machine translation service can translate Web pages from English to French, German, Spanish, Italian and Portuguese or vice versa."},{"question":"What is the purpose of AltaVista's world-wide index?","answer":"AltaVista's world-wide index allows users to search across the Web in their own language from one central location. The index translates the characters within documents into a standard encoding system, Unicode."}],"seed_document_id":196,"topic":"Language Machine Translation"}}
{"id":"8573f18c-2c2c-42fc-945e-3a7f245c7cf5","question":"What is the operator used for a negative lookahead in pattern matching and what is a corpus in the context of text processing?","reference_answer":"The operator used for a negative lookahead in pattern matching is (?! pattern) and a corpus in the context of text processing is a computer-readable body of text.","reference_context":"Document 378: text to see if some pattern matches, but not advance the match cursor, so that we can\nthen deal with the pattern if it occurs.\nThese lookahead assertions make use of the (?syntax that we saw in the previ- lookahead\nous section for non-capture groups. The operator (?= pattern) is true ifpattern\noccurs, but is zero-width , i.e. the match pointer doesn\u2019t advance. The operator zero-width\n(?! pattern) only returns true if a pattern does not match, but again is zero-width\nand doesn\u2019t advance the cursor. Negative lookahead is commonly used when we\nare parsing some complex pattern but want to rule out a special case. For example\nsuppose we want to match, at the beginning of a line, any single word that doesn\u2019t\nstart with \u201cV olcano\u201d. We can use negative lookahead to do this:\n\/\u02c6(?!Volcano)[A-Za-z]+\/\n2.2 Words\nBefore we talk about processing words, we need to decide what counts as a word.\nLet\u2019s start by looking at one particular corpus (plural corpora ), a computer-readable corpus","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the operator used for a negative lookahead in pattern matching?","answer":"The operator used for a negative lookahead in pattern matching is (?! pattern)"},{"question":"What is a corpus in the context of text processing?","answer":"A corpus in the context of text processing is a computer-readable body of text."}],"seed_document_id":378,"topic":"Regular Expressions"}}
{"id":"0e92010f-4d47-409e-b60a-a0312def1413","question":"What is ConcGram 1.0 and what was the main focus of P. Hanks' work in 2008?","reference_answer":"ConcGram 1.0 is a phraseological search engine and P. Hanks in 2008 focused on mapping meaning onto use, specifically in a Pattern Dictionary of English Verbs.","reference_context":"Document 563: metaphors. Journal of Chinese Linguistics 38(2): 183\u2013223.\nCulpeper, J., and M. Kyto \u00a8. 2010. Early Modern English dialogues: spoken interaction as writing .\nCambridge: Cambridge University Press.\nDavies, M. 2009. The 385 +million word Corpus of Contemporary American English (1990\u20132008 +):\ndesign, architecture, and linguistic insights. International Journal of Corpus Linguistics 14(2): 159\u2013\n190.\nFrankenberg Garcia, A. 2014. The use of corpus examples for language comprehension and production.\nReCALL.\nGarrett, E., N.W. Hill, A. Kilgarriff, R. Vadlapudi, and A. Zadoks. 2014. The contribution of corpus\nlinguistics to lexicography and the future of Tibetan dictionaries. In The Third International\nConference on Tibetan Language , eds. Tuttle, Gya, Dare and Wilber, New York: Trace Foundation\n(forthcoming).\nGreaves, C. 2009. ConcGram 1.0: a phraseological search engine. John Benjamins.Hanks, P. 2008. Mapping meaning onto use: a Pattern Dictionary of English Verbs. In Proc AACL , Utah.\n\nDocument 564: (forthcoming).\nGreaves, C. 2009. ConcGram 1.0: a phraseological search engine. John Benjamins.Hanks, P. 2008. Mapping meaning onto use: a Pattern Dictionary of English Verbs. In Proc AACL , Utah.\nHanks, P. 2012. The corpus revolution in lexicography. International Journal of Lexicography 25(4):\n398\u2013436.\nHardie, A. 2012. CQPweb\u2014combining power, \ufb02exibility and usability in a corpus analysis tool.\nInternational journal of corpus linguistics 17(3): 380\u2013409.\nHa`, P.T., N.T.M. Huye \u02c6`n, L.H. Ph \u01b0\u01a1ng, and A. Kilgarriff. 2012. Nghie \u02c6nc\u1ee9ut\u1eebv\u1ef1ng tie \u02c6\u00b4ng Vie\u02d9\u02c6tv\u1edbih e\u02d9\u02c6\ntho\u02c6\u00b4ng sketch engine. T\u1ea1p ch\u00ed Tin h \u1ecdcv \u00e0\u0110i\u1ec1u khi \u1ec3nh\u1ecdc27(3): 206\u2013218.\nHuang, C.-R., K.-J. Chen, and Q.-X. Lai. 1997.\nMandarin Daily Dictionary of Chinese Classi \ufb01ers. Taipei: Mandarin Daily\nPress.\nHuang, C.-R., J.-F. Hong, W.-Y. Ma, and P. S \u02c7imon. 2014. From corpus to grammar: automatic extraction\nof grammatical relations from annotated corpus. In T\u2019sou and Kwong Eds. Linguistic Corpus and","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is ConcGram 1.0?","answer":"ConcGram 1.0 is a phraseological search engine."},{"question":"What is the main focus of the work by P. Hanks in 2008?","answer":"P. Hanks in 2008 worked on mapping meaning onto use, specifically in a Pattern Dictionary of English Verbs."}],"seed_document_id":563,"topic":"Corpus Linguistics and Lexicography"}}
{"id":"28a023f4-3777-47cb-b082-2a7abe9e1a09","question":"What is required to log in to the Leeds University account and until when is the university's license valid?","reference_answer":"You will have to type in your username and password for Leeds University to log in and the university's license is valid up until June 2022.","reference_context":"Document 469: universities in Leeds. We want University of Leeds. That's us. OK.  \nNow I'll then log me in via my university log in. Well, I've logged in already, so we won't go there. \nYou will have to type in your username and password for Leeds University to log in.  It's just \nwarning me all accounts that my institution will close down on June 25, 2022. So the university has \na license up until June 2022, so we're OK.  \nOK, here's various stuff. Here's a dashboard. I haven't selected a corpus yet. Let's go back to \nSelect  Corpus. Well, here's some corpora that I've done before or looked at recently. And let's \ncreate a new corpus. So our new corpus -- OK, I'm going to collect a corpus in the field of, let's say, \ndata mining. Why not? And we're going to call the corpora Datam ining. Datamining.","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is required to log in to the Leeds University account?","answer":"You will have to type in your username and password for Leeds University to log in."},{"question":"Until when is the university's license valid?","answer":"The university has a license up until June 2022."}],"seed_document_id":469,"topic":"Others"}}
{"id":"7fa56a67-b9cc-4976-860a-5df423b35bc5","question":"What is the purpose of normalizing words in text analytics and when is case folding, a type of normalization, generally not done?","reference_answer":"Normalizing words in text analytics is valuable as it provides a single form for words with multiple forms, facilitating information retrieval or extraction. Case folding, which maps everything to lower case, is generally avoided in sentiment analysis, text classification tasks, information extraction, and machine translation, where maintaining the difference between words can be more beneficial.","reference_context":"Document 414: ing a single normal form for words with multiple forms like USAandUSoruh-huh\nanduhhuh . This standardization may be valuable, despite the spelling information\nthat is lost in the normalization process. For information retrieval or information\nextraction about the US, we might want to see information from documents whether\nthey mention the USor theUSA.\nCase folding is another kind of normalization. Mapping everything to lower case folding\ncase means that Woodchuck andwoodchuck are represented identically, which is\nvery helpful for generalization in many tasks, such as information retrieval or speech\nrecognition. For sentiment analysis and other text classi\ufb01cation tasks, information\nextraction, and machine translation, by contrast, case can be quite helpful and case\nfolding is generally not done. This is because maintaining the difference between,\nfor example, USthe country and usthe pronoun can outweigh the advantage in","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the purpose of normalizing words in text analytics?","answer":"Normalizing words in text analytics is valuable as it provides a single form for words with multiple forms, making it easier for information retrieval or extraction."},{"question":"What is case folding and when is it generally not done?","answer":"Case folding is a type of normalization that maps everything to lower case, representing words identically regardless of their original case. It is generally not done for sentiment analysis, text classification tasks, information extraction, and machine translation, where maintaining the difference between words can be more beneficial."}],"seed_document_id":414,"topic":"Text Normalization and Tokenization"}}
{"id":"e9c69a53-2bb7-4656-8690-39659ee629e2","question":"Could customer services be further automated with personal interaction becoming a premium service, and could endangered languages be saved by a lesser need to learn a lingua franca or will software not be developed for languages with smaller, less profitable audiences in the 21st century?","reference_answer":"The text suggests a possibility of further automation in customer services with personal interaction potentially becoming a premium service, and raises a question about whether endangered languages could be saved due to a reduced need to learn a common language or whether software will not be developed for languages with smaller, less profitable audiences.","reference_context":"Document 281: hearing and sight-impaired stand to gain from these\ntechnologies, but will hardware and software costs or\ntechnophobia become new sources of division and\ninequality?\nHow will technology change our interactions? How will we\nadapt once technology shapes \u0097 and speaks \u0097 the actual\nwords we send and receive? Will speech recognition re-\nemphasise oral skills?\nHow will a greater transparency of information in other\nlanguages affect economies? \nWill customer services be automated further, with personal\ninteraction becoming a premium service in the 21st\ncentury?\nWill the UK be seen as a leader of language machine\ntechnology?\n\nDocument 280: questions\n70for debate\nHow will the language machine affect the language-based\nprofessions? \nHow can computer scientists and language professionals\ncollaborate to mutual benefit?\nHow will practitioners find ways of influencing and\ninforming \u0097 and of staying informed of \u0097 developments\nin technology and best practice? If discussion is needed,\nhow will it be facilitated? \nWill we stop learning languages? And, if we do, what will\nbe the cultural and social impact?\nWill endangered languages be saved by a lesser need to\nlearn a lingua franca, or will software not be developed\nfor languages with smaller, less profitable audiences? \nNot all languages are similarly alphabetic, phonetic or\ntonal. Will some languages benefit more than others?\nHow equally will we benefit? Linguistic minorities and the\nhearing and sight-impaired stand to gain from these\ntechnologies, but will hardware and software costs or\ntechnophobia become new sources of division and\ninequality?","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"Will customer services be automated further, with personal interaction becoming a premium service in the 21st century?","answer":"The text suggests that there is a possibility of customer services being further automated, with personal interaction potentially becoming a premium service in the 21st century."},{"question":"Will endangered languages be saved by a lesser need to learn a lingua franca, or will software not be developed for languages with smaller, less profitable audiences?","answer":"The text raises a question about whether endangered languages could be saved due to a reduced need to learn a common language, or whether software will not be developed for languages with smaller, less profitable audiences."}],"seed_document_id":281,"topic":"Others"}}
{"id":"05575716-4760-4285-a37a-770564bd4d35","question":"What are the British Academic Spoken English (BASE) and British Academic Written English (BAWE) corpora and what is the purpose of Historical corpora in linguistics?","reference_answer":"The British Academic Spoken English (BASE) and British Academic Written English (BAWE) corpora are samples of target varieties used in seminars and written in University-level essays, by accomplished English speakers. Historical corpora in linguistics, on the other hand, are used to look back over the history of a language, supporting research in language development and change.","reference_context":"Document 530: seminars and written in University-level essays, by accomplished English speakers.\nThe British Academic Spoken English (BASE) and British Academic WrittenEnglish (BAWE) corpora have been created as samples of these target varieties.\n22\n5.1.4 Historical\nA central topic for linguists is language development and change. Corpora looking\nback over the history of a language, and supporting this kind of research, includeLatinISE (of Latin from the third century B. C. to the twentieth century A.D.,McGillivray and Kilgarriff 2013 ), GermanC (of German from the seventeenth and\neighteenth centuries; Scheible et al. 2011 ) and English Dialogues Corpus\n(sixteenth\u2013eighteenth centuries; Culpeper and Kyto \u00a82010 ).\nFor the Arabic world and Islam, the language has a special role. It is the language","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What are the British Academic Spoken English (BASE) and British Academic Written English (BAWE) corpora?","answer":"The British Academic Spoken English (BASE) and British Academic Written English (BAWE) corpora have been created as samples of target varieties used in seminars and written in University-level essays, by accomplished English speakers."},{"question":"What is the purpose of Historical corpora in linguistics?","answer":"Historical corpora in linguistics are used to look back over the history of a language, supporting research in language development and change."}],"seed_document_id":530,"topic":"Corpus Linguistics and Lexicography"}}
{"id":"bb2990d4-2d07-4175-9b0c-54e4471785b2","question":"What does the long word in the text refer to and what is the complexity in dealing with long words in some languages?","reference_answer":"The long word in the text refers to behaving as you are among those whom we could not civilise, and in some languages like Turkish, Finnish, and Estonian, dealing with very long words can be quite complicated due to the complexity of chopping them up.","reference_context":"Document 339: So here's a very long word. I'm not going to even try to pronounce it. But it means something like \nbehaving as you are among those whom we could not civili se. This is a rather contrived example, \nbut it shows in some languages like Turkish, and Finnish, and Estonian, you can get very long \nwords. And chopping them up is quite complicated.","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What does the long word in the text refer to?","answer":"It refers to behaving as you are among those whom we could not civilise."},{"question":"What is the complexity in dealing with long words in some languages?","answer":"In some languages like Turkish, Finnish, and Estonian, you can get very long words and chopping them up is quite complicated."}],"seed_document_id":339,"topic":"Others"}}
{"id":"59490830-9b1e-40de-9cf8-9b879edad9d4","question":"What are the limitations of machine translation and how does it impact the demand for human-produced translations?","reference_answer":"Machine translation has uneven quality, making it only suitable for 'inbound' work - texts being translated into the user's own language, and not for 'outbound' work such as promotional materials. However, people using the crude output of machine translation systems will come to realise the added value of professionally produced translations, leading to a rise in the demand for human-produced translations.","reference_context":"Document 162: getting, warts and all, and guess at the rest without offending potential clients\u0091 linguistic\nsensibilities. Unedited MT is simply not good enough for \u0090outbound\u0091 work such as promotional\nmaterials, where input from professional human translators is essential.\n \u0097 Bulletin of the Institute of Translation and Interpreting, Feb-March 1999, page 29. \nIt becomes increasingly transparent that not only does machine translation not do away with the\nservices of a professional human translator, it positively demands such services, because MT can,\nat its least sophisticated, put a \u0090spin\u0091 on the original meaning which makes this meaning even\nmore difficult to tease out than from the foreign text source.\n \u0097 John Thorogood, Centre for Information on Language Teaching and Research.\nIn reply to the question, \u0094What effect will access to speech recognition technologies have on\npeople\u0091s willingness and ability to learn new languages?\u0095 The main thing I have noticed about\n\nDocument 161: the language machine\n37\nMachine translation? Speech recognition? Do they work?\nThe ease with which it is possible to find fault with any new technology is a significant factor in its\ntake-up. Students of machine translation, for example, are often given examples of mistranslation,\nsuch as: \u0090The spirit is willing but the flesh is weak\u0091 translated first into Russian and then into\nEnglish: \u0090The vodka is good but the meat is bad.\u0091 Many such examples can be found, which\nperhaps distort the successes of language technologies. But what do the professionals say?\nBecause quality is so uneven, monolingual users are advised to resort to MT only for \u0090inbound\u0091\nwork \u0097 texts being translated into their own language. In this case, they can see what they are\ngetting, warts and all, and guess at the rest without offending potential clients\u0091 linguistic\nsensibilities. Unedited MT is simply not good enough for \u0090outbound\u0091 work such as promotional\n\nDocument 232: receive a much higher profile than in the past. People using the crude output of MT systems will come to\nrealise the added value (i.e. higher quality) of professionally produced translations. As a result, the demand\nfor human produced translation will rise, and the translation profession will be busier than ever. Fortunately,\nprofessional translators will have the support of a wide range of computer-based translation tools, enabling\nthem to increase productivity and to improve consistency and quality. In brief, automation and MT will not be\na threat to the livelihood of the translator, but will be the source of even greater business and will be the\nmeans of achieving considerably improved working conditions.\u0091 (Hutchins, 1998).A seminal paper  on \u0090The proper\nplace of Men and Machines in\nlanguage translation\u0091 (Kay, 1980)\nargued that there were aspects of\nhigh-quality translation that called\nfor uniquely human knowledge and\nexperience. Nearly two decades","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What are the limitations of machine translation?","answer":"Because quality is so uneven, monolingual users are advised to resort to machine translation only for 'inbound' work - texts being translated into their own language. Unedited machine translation is not good enough for 'outbound' work such as promotional materials."},{"question":"What is the impact of machine translation on the demand for human-produced translations?","answer":"People using the crude output of machine translation systems will come to realise the added value of professionally produced translations. As a result, the demand for human produced translation will rise."}],"seed_document_id":162,"topic":"Language Technology and Machine Translation"}}
{"id":"508d5d3d-588d-4e07-961d-6f64ac2b316c","question":"Which language is mentioned as an exception where a certain concept doesn't apply, and what is the source of this information?","reference_answer":"Chinese is mentioned as an exception where a certain concept doesn't apply, and the source of this information is http:\/\/cjki.org .18 Lexicography ASIALEX (2014) 1:7\u201336.","reference_context":"Document 518: 13For all of the languages that have been considered except Chinese, where the concept does not apply.\n14http:\/\/cjki.org .18 Lexicography ASIALEX (2014) 1:7\u201336\n123","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"Which language is mentioned as an exception where a certain concept doesn't apply?","answer":"Chinese."},{"question":"What is the source of this information?","answer":"http:\/\/cjki.org .18 Lexicography ASIALEX (2014) 1:7\u201336"}],"seed_document_id":518,"topic":"Corpus Linguistics and Lexicography"}}
{"id":"351bb656-fd48-4b58-af3b-6b772c7f9eb7","question":"What are the different areas of language processing and what role does computer science play in it?","reference_answer":"The different areas of language processing include Phonetics, Lexis, Syntax, Semantics, Pragmatics, and Discourse modelling. Computer science plays a significant role as it provides theory on the use of formal simulations and mathematical models of computation, and natural-language processing which is now a specialist sub-field.","reference_context":"Document 83: technology to a wider public, so we can expect language\nmachines to become widespread. . creating popular\n16markets\nThe contribution\nof computing\nSee page 15The language of language processing \nPhonetics : the study of speech processes, including the\nproduction, perception, and analysis of speech sounds from both\nan acoustic and a physiological point of view.\nLexis : the study of words or vocabulary items in a language,\nincluding all forms having individual meaning or grammatical\nfunction.\nSyntax : the study of the grammatical arrangement of words and\nmorphemes in the sentences of a language or of languages in\ngeneral.\nSemantics : the study of meaning in language, and the principles\nthat govern the relationship between words and sentences and\ntheir meanings.\nPragmatics : the analysis of language in practice, taking account\nof the context of language use.\nDiscourse modelling : the analysis of linguistic phenomena that\n\nDocument 84: their meanings.\nPragmatics : the analysis of language in practice, taking account\nof the context of language use.\nDiscourse modelling : the analysis of linguistic phenomena that\nrange over more than one utterance or sentence..Developments  in speech and\nlanguage technology are much\nmore likely to be influenced by the\nspread of personal computing, the\nconsumer market, and take-up of\nthe Internet than by any academic\ndevelopments in theory, models or\nalgorithms in linguistics or\ncomputer science.\n.Widespread commodity product?\nThe language machine may have\nan academic heritage, but it is\npopular culture, SF , fashion, and\nvisionary product development that\nwill give the technology wide and\ntrendy appeal for a youth market:\n\u0090Instead of carrying your laptop,\nwear it \u0087 In the future, computer\ndisplays may be sold by the gallon\nand painted on, CD-ROMs may be\nedible, and parallel processors may\nbe applied like suntan lotion.\u0091\n(Negroponte, 1995)SITE LICENCE EDITION\n\nDocument 23: scientific approach. And it takes that language signal and analyzes it at various  levels. So as \nphonetics, the study of speech, production, and perception. Lexicography, or Lexis, is a study of \nwords or vocabulary items in a dictionary for example. And the words will have the way that they \nwritten, the way that they're spoken, the meaning, and the big grammatical function. And then the \nsyntax or grammar, the study of grammatical arrangements of words and morphemes. And \nmorpheme is a minimal unit. We'll see more of this later on.  \nSemantics is the study of meaning, the meanings of words, the meaning of sentences, and how \nthese are related to each other. How can you tell that marriage and wedding mean the same thing, \neven though they're different character sequences? Pragmatics is the analysis of language in \npractical use. Take into account  the context of use. Discourse modeling is about phenomena that\n\nDocument 78: linguistics and phonetics, modern languages, operationalresearch and information systems, philosophy, psychology,and transport studies. Each contributing disciplineunderpins the language machine in different ways. Brieflyhighlighted below are the contributions of just two:linguistics and computer science ..\nLinguistics The language machine needs a theoretical\nframework within which the components of a languagemodel and their interrelation can be defined, much of whichcan be derived from the field of linguistics .. One example\nis the division of language processing into a hierarchy oflevels \u0097 phonetics, lexis, syntax, semantics, pragmatics anddiscourse modelling (see box, page 16).Computer science  As a language machine is a software\nsystem running on a computer, it can draw on many areas:* theoretical computer science provides theory on the use\nof formal simulations and mathematical models ofcomputation;\n* natural-language processing is now a specialist sub-field,","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What are the different areas of language processing?","answer":"The different areas of language processing include Phonetics, Lexis, Syntax, Semantics, Pragmatics, and Discourse modelling."},{"question":"What is the role of computer science in language processing?","answer":"As a language machine is a software system running on a computer, it can draw on many areas of computer science including theoretical computer science which provides theory on the use of formal simulations and mathematical models of computation, and natural-language processing which is now a specialist sub-field."}],"seed_document_id":83,"topic":"Language Processing and Computational Linguistics"}}
{"id":"250bc70a-4326-486e-b1db-28be8ad3fdd3","question":"What is the main focus of the book and what is another theme it explores?","reference_answer":"This book primarily provides a survey of the current state of speech and language technology, focusing particularly on machine translation and speech recognition. It also explores how language machines may evolve from their present use in high-cost, high-specification systems, to practical, everyday contexts in education, industry, business and the home.","reference_context":"Document 274: Preface 5\nProgress and Prospects 5\nThe language machine 6\nSurveying the territory 6The impact? 6What\u0091s in a name? 7\nDescribing words: the technology 8What makes a language machine? 8Is it a language machine? 8\n... So is it SALT? 9\nTelling histories: 1791\u00972020 10Dreaming of speaking machines 10From Turing\u0091s child-machine to a 25 thousand dollar race 10\nWhen destiny calls, have the confidence to answer 11\nSeeing futures emerging 12To 2045: the BT Technology Calendar 12A widespread expectation 12* the wildcards? 13\nResearch labs to desk-tops 14\nAn academic heritage 14Where languages meet computer science 14Creating popular markets 16A use for everyone? 16The language of language processing 16\nTurning theory into practice 18\nWhy create language machines? 18What\u0091s involved: input to output 20Defining shared approaches 20Listen, analyse, understand 22full contents\n66click to goSITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 42: Contents\nThe language machine 6\nResearch labs to desk-tops 14\nTurning theory into practice 18\nThe problems with machines 28UK advantage? 38Real-life situations 44\nFuture scenarios 50\nGlossary 58References 60Questions for debate 64This season\u0091s\nmust-have: thewristwatch translatorSee page 53\nLanguage machines\nhelping withdisabilities See page 54What are the benefits\nto the UK of makingthe language machinework? See page 43SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 52: CALL Computer Assisted Language\nLearning\nHLT Human Languages Technology\nIT Information Technology\nMAT Machine Assisted Translation\nMT Machine Translation\nPC Personal Computer\nSLE Speech and Language Engineering\nSR Speech Recognition\nSALT \/ SLT Speech And Language\nTechnology\nWWW World Wide WebWhat\u0091s in a name?\nThis book is a survey of language\nmachines \u0097 what they are; where\nthey\u0091ve come from; the present-\nday research; implications for the\nlanguage industries; and the\nimpressive range of UK and EU\ncollaboration on speech and\nlanguage technology.\nThis book also explores another\ntheme \u0097 how language machines\nmay evolve from their present use\nin high-cost, high-specification\nsystems, to practical, everyday\ncontexts in education, industry,\nbusines and the home.\nGlossary?\nSee pages 58 & 59SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 47: Surveying the territory\nLanguage machines \u0097 machines that in some sense\nsimulate human language and human language behaviour\n\u0097 are used daily around us. Indeed, such machines already\nhave a long history, and have acquired a place in our\nculture and our expectations.\nThis book provides a survey of the current state of\nspeech and language technology, focusing particularly on\nmachine translation and speech recognition, highlighting\nthe histories and academic disciplines contributing to their\ndevelopment; it examines the components and tech-\nnologies; possible pitfalls; main developers; current and\npotential uses; predicted developments; and paints some\nlikely scenarios for the future impact of the language\nmachine. Finally, this book focuses on current and\nprospective developments that could have an impact on\ndemand in the marketplace for language teachers and\nlanguage-based professions in the foreseeable future.\nIt may help to define what constitutes \u0090the foreseeable","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the main focus of the book?","answer":"This book provides a survey of the current state of speech and language technology, focusing particularly on machine translation and speech recognition. It explores their histories, academic disciplines contributing to their development, components and technologies, possible pitfalls, main developers, current and potential uses, predicted developments, and future impact."},{"question":"What is another theme this book explores?","answer":"The book also explores how language machines may evolve from their present use in high-cost, high-specification systems, to practical, everyday contexts in education, industry, business and the home."}],"seed_document_id":274,"topic":"Language Machine Translation"}}
{"id":"f619f3d1-323b-4099-ac59-72e7128a7711","question":"What is the Chinese Sketch Engine and what is the TenTen corpus family?","reference_answer":"The Chinese Sketch Engine is a tool referenced in the work of Huang, C-R., A. Kilgarriff, Y. Wu, C.M. Chiu, S. Smith, P. Rychly, M.H. Bai, and K.-J. Chen. in 2005, used for the extraction of grammatical collocations. The TenTen corpus family is a concept discussed in the work of Jakub\u0131 \u00b4c\u02c7ek, M., A. Kilgarriff, V. Kova \u00b4r\u02c7, P. Rychly \u00b4, and V. Suchomel in 2013, though specific details of the concept are not provided in the given context.","reference_context":"Document 565: Huang, C.-R., J.-F. Hong, W.-Y. Ma, and P. S \u02c7imon. 2014. From corpus to grammar: automatic extraction\nof grammatical relations from annotated corpus. In T\u2019sou and Kwong Eds. Linguistic Corpus and\nCorpus Linguistics in the Chinese Context. Journal of Chinese Linguistics Monograph . Hong Kong:\nChinese University of Hong Kong Press, (forthcoming).\nHuang, C-R., A. Kilgarriff, Y. Wu, C.M. Chiu, S. Smith, P. Rychly, M.H. Bai, and K.-J. Chen. 2005.\nChinese Sketch Engine and the extraction of grammatical collocations. In Proc Fourth SIGHAN\nWorkshop on Chinese Language Processing , 48\u201355.\nJakub\u0131 \u00b4c\u02c7ek, M., A. Kilgarriff, D. McCarthy, and P. Rychly \u00b4. 2010. Fast syntactic searching in very large\ncorpora for many languages. In Proc P ACLIC , Vol. 24, 741\u2013747, Japan.\nJakub\u0131 \u00b4c\u02c7ek, M., A. Kilgarriff, V. Kova \u00b4r\u02c7, P. Rychly \u00b4, and V. Suchomel. 2013. The TenTen corpus family .\nLancaster: In Proc. Int. Conf. on Corpus Linguistics.","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the Chinese Sketch Engine?","answer":"The Chinese Sketch Engine is a tool referenced in the work of Huang, C-R., A. Kilgarriff, Y. Wu, C.M. Chiu, S. Smith, P. Rychly, M.H. Bai, and K.-J. Chen. in 2005. It is used for the extraction of grammatical collocations."},{"question":"What is the TenTen corpus family?","answer":"The TenTen corpus family is a concept discussed in the work of Jakub\u0131 \u00b4c\u02c7ek, M., A. Kilgarriff, V. Kova \u00b4r\u02c7, P. Rychly \u00b4, and V. Suchomel in 2013. The specific details of the concept are not provided in the given context."}],"seed_document_id":565,"topic":"Corpus Linguistics and Lexicography"}}
{"id":"39280df8-5312-49af-8353-374de2573306","question":"Which voice recognition software was preferred by Personal Computer World and what was included in the August 1998 PC Plus free CD?","reference_answer":"Personal Computer World preferred Dragon Systems Naturally-Speaking and the August 1998 PC Plus free CD included Globalink's English-Spanish Power Translator Deluxe.","reference_context":"Document 261: version of Dragon Naturally-\nSpeaking (Dragon 1998). \nReviews of language machines\nare also now appearing in\nmagazines beyond the PC shelf, as\nspecialist magazines recognise\nthis technology is relevant to their\nreaders: Management Services\n(May 1998) reviewed a number of\nspeech processing systems for\nmanagers (Tyler, 1998).SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 260: 61\nMagazines: the\nquickest route\nInformation on language machine\ndevelopments often appears in\npopular computing magazines.\nThe UK editions of Computer\nActive (July 1998), PC Direct (June\n1998), and Personal Computer\nWorld (October 1998) all reviewed\nPC speech recognition systems.\nComputer Active recommended\nIBM ViaVoice Gold as the best (at\nthe time). PC Direct did not\nnominate a favourite, but re-\nviewed each package in detail.\nPersonal Computer World pre-\nferred Dragon Systems Naturally-\nSpeaking, and provided a useful\nsummary of features to look for in\nvoice recognition software. \nMany magazines also include free\nCDs with sample software. The\nAugust 1998 PC Plus free CD\nincluded Globalink\u0091s English-\nSpanish Power Translator Deluxe\n(Globalink 1998); Computer Buyer\nMay 1998 free CD included a trial\nversion of Dragon Naturally-\nSpeaking (Dragon 1998). \nReviews of language machines\nare also now appearing in\nmagazines beyond the PC shelf, as\nspecialist magazines recognise","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What voice recognition software did Personal Computer World prefer?","answer":"Personal Computer World preferred Dragon Systems Naturally-Speaking."},{"question":"What was included in the August 1998 PC Plus free CD?","answer":"The August 1998 PC Plus free CD included Globalink's English-Spanish Power Translator Deluxe."}],"seed_document_id":261,"topic":"Language and Speech Technology"}}
{"id":"a8b37eae-4481-4064-b50a-6acd2b5f5b20","question":"What are the challenges schools might face when integrating language machine technology and what could be the potential impacts of widespread personal computing on language teaching?","reference_answer":"Integrating language machine technology in schools presents challenges such as the need for teachers to learn to use, integrate and exploit the technology, the need for schools to plan for funding, maintenance, and upgrades, and the limited resources in developing countries. On the other hand, widespread personal computing could impact language teaching by allowing students to learn some aspects of language outside the classroom and introducing new teaching methods from other areas of education.","reference_context":"Document 158: of language outside the classroom. It is likely that new\nways of teaching using computers will also spill into\nlanguage teaching from other areas of education.\nHowever the boundaries are redrawn, teachers will need\ntime to learn to use, integrate and exploit the language\nmachine. Schools will need time to see what\u0091s available,\nmake funding plans against staff availability and projected\nstudent numbers, and then plan for maintenance and\nupgrades. In developing countries all this may be an\nunrealistic luxury: teachers in the state sector may not have\nupdated equipment or software easily available to them or\neven offer the basic computer know-how. \nYet it is possibly easier for the state sector to provide\ncomputers than it is to provide smaller classes and trained\nteachers with the resources they need. For example this\nmay be the case in Mexico, where the state ministry \u0097 while\nworking with the British Council to upgrade the skills of its\nteachers \u0097 is keen to introduce new technology.\n\nDocument 145: professions. For example, language teachers who wish to\nuse CALL software incorporating speech recognition tech-\nnology may need to rethink approaches, and decide which\naspects of learning could be achieved more successfully by\nthe individual using the technology alone, and which\nlearning should remain within the classroom as a shared,\ngroup activity. Similarly, whole-school policies \u0097 of funding\nnew equipment, providing new learning spaces, and\nmanaging the politics of departmental resourcing \u0097 may\nneed to come under similar scrutiny if language machine\ntechnology is to be used more widely and successfuly in\neducation. \nProblem 6\nNewcomers need training and time to learn to\nuse the language machine \nOne supposed strength of the language machine is that\ncommunicating with a computer in spoken English is\n\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic\n\nDocument 157: Can problems be overcome?\nTaking a typical application \u0097 language teaching and\nlearning \u0097 can we imagine that the problems described in\nthis section will be overcome?\nClearly, full integration of the language machine is not\nforseeable in the immediate future. At the very least,\nlearners and teachers need to use computers confidently in\neveryday learning contexts. And, in its current state, the\nlanguage machine is not yet appropriate as a replacement\nfor some of the tasks undertaken by the language teacher. .\nYet as language technology improves, the boundary\nbetween tasks that can be delegated to the computer and\nthose that should be done only with a human language\nteacher will shift. The advent of widescale personal\ncomputing may also have an impact in terms of allowing\nstudents to use language machines to learn some aspects\nof language outside the classroom. It is likely that new\nways of teaching using computers will also spill into\nlanguage teaching from other areas of education.\n\nDocument 159: may be the case in Mexico, where the state ministry \u0097 while\nworking with the British Council to upgrade the skills of its\nteachers \u0097 is keen to introduce new technology. \nInterestingly for education, in applications such as\nmachine translation (the focus of the box opposite) and for\npeople working in other professions, . it is clear that the\nlanguage machine is making clear inroads.\nBut do inroads lead to a revolution?determination\n36to succeed\n.One scenario for the ELT\nbusiness is a radical one: what if\nthe language machine brought\nabout the large-scale abandonment\nof language learning? Many people\nlearn English so they can use it to\ncommunicate with native English\nspeakers or as a lingua franca; but\nwhat if, in the future, they find that\nit is possible to communicate via\nmachine translation devices?\nIs this scenario a realistic one?\nImplications for language\nprofessionals are explored on\npages 50\u009757.\nHal \u0097 the \ntalking computer\nmade evil\nSee page 35.Searching for Extra Terrestrials?","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What are some of the challenges faced by schools in integrating language machine technology?","answer":"Teachers will need time to learn to use, integrate and exploit the language machine. Schools will need time to see what's available, make funding plans against staff availability and projected student numbers, and then plan for maintenance and upgrades. In developing countries this may be an unrealistic luxury: teachers in the state sector may not have updated equipment or software easily available to them or even offer the basic computer know-how."},{"question":"What are some of the potential impacts of widespread personal computing on language teaching?","answer":"The advent of widescale personal computing may have an impact in terms of allowing students to use language machines to learn some aspects of language outside the classroom. It is likely that new ways of teaching using computers will also spill into language teaching from other areas of education."}],"seed_document_id":158,"topic":"Artificial Intelligence in Language Learning"}}
{"id":"25748a1d-11c0-4b55-a390-bf8b4c958aff","question":"What punctuation marks are used as cues for sentence segmentation, and what is the role of the Minimum Edit Distance in natural language processing?","reference_answer":"Periods, question marks, and exclamation points are used as cues for sentence segmentation, while Minimum Edit Distance is concerned with measuring how similar two strings are, for example in spelling correction.","reference_context":"Document 420: 2.5 \u2022 M INIMUM EDITDISTANCE 21\n2.4.5 Sentence Segmentation\nSentence segmentation is another important step in text processing. The most use-sentence\nsegmentation\nful cues for segmenting a text into sentences are punctuation, like periods, question\nmarks, and exclamation points. Question marks and exclamation points are rela-\ntively unambiguous markers of sentence boundaries. Periods, on the other hand, are\nmore ambiguous. The period character \u201c.\u201d is ambiguous between a sentence bound-\nary marker and a marker of abbreviations like Mr.orInc.The previous sentence that\nyou just read showed an even more complex case of this ambiguity, in which the \ufb01nal\nperiod of Inc. marked both an abbreviation and the sentence boundary marker. For\nthis reason, sentence tokenization and word tokenization may be addressed jointly.\nIn general, sentence tokenization methods work by \ufb01rst deciding (based on rules\nor machine learning) whether a period is part of the word or is a sentence-boundary\n\nDocument 421: In general, sentence tokenization methods work by \ufb01rst deciding (based on rules\nor machine learning) whether a period is part of the word or is a sentence-boundary\nmarker. An abbreviation dictionary can help determine whether the period is part\nof a commonly used abbreviation; the dictionaries can be hand-built or machine-\nlearned (Kiss and Strunk, 2006), as can the \ufb01nal sentence splitter. In the Stanford\nCoreNLP toolkit (Manning et al., 2014), for example sentence splitting is rule-based,\na deterministic consequence of tokenization; a sentence ends when a sentence-ending\npunctuation (., !, or ?) is not already grouped with other characters into a token (such\nas for an abbreviation or number), optionally followed by additional \ufb01nal quotes or\nbrackets.\n2.5 Minimum Edit Distance\nMuch of natural language processing is concerned with measuring how similar two\nstrings are. For example in spelling correction, the user typed some erroneous","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What punctuation marks are used as cues for sentence segmentation?","answer":"Periods, question marks, and exclamation points are used as cues for sentence segmentation."},{"question":"What is the role of the Minimum Edit Distance in natural language processing?","answer":"Minimum Edit Distance is concerned with measuring how similar two strings are, for example in spelling correction."}],"seed_document_id":420,"topic":"Others"}}
{"id":"af1f0af4-88c8-42e8-9430-d4efc60a2f8f","question":"What is the advised use of Machine Translation (MT) for monolingual users and what is its impact on the translation profession?","reference_answer":"Monolingual users are advised to resort to MT only for 'inbound' work, translating into their own language, as unedited MT is not good enough for 'outbound' work such as promotional materials. As for the impact on the translation profession, automation and MT are not threats, but sources of greater business and means of achieving considerably improved working conditions.","reference_context":"Document 162: getting, warts and all, and guess at the rest without offending potential clients\u0091 linguistic\nsensibilities. Unedited MT is simply not good enough for \u0090outbound\u0091 work such as promotional\nmaterials, where input from professional human translators is essential.\n \u0097 Bulletin of the Institute of Translation and Interpreting, Feb-March 1999, page 29. \nIt becomes increasingly transparent that not only does machine translation not do away with the\nservices of a professional human translator, it positively demands such services, because MT can,\nat its least sophisticated, put a \u0090spin\u0091 on the original meaning which makes this meaning even\nmore difficult to tease out than from the foreign text source.\n \u0097 John Thorogood, Centre for Information on Language Teaching and Research.\nIn reply to the question, \u0094What effect will access to speech recognition technologies have on\npeople\u0091s willingness and ability to learn new languages?\u0095 The main thing I have noticed about\n\nDocument 161: the language machine\n37\nMachine translation? Speech recognition? Do they work?\nThe ease with which it is possible to find fault with any new technology is a significant factor in its\ntake-up. Students of machine translation, for example, are often given examples of mistranslation,\nsuch as: \u0090The spirit is willing but the flesh is weak\u0091 translated first into Russian and then into\nEnglish: \u0090The vodka is good but the meat is bad.\u0091 Many such examples can be found, which\nperhaps distort the successes of language technologies. But what do the professionals say?\nBecause quality is so uneven, monolingual users are advised to resort to MT only for \u0090inbound\u0091\nwork \u0097 texts being translated into their own language. In this case, they can see what they are\ngetting, warts and all, and guess at the rest without offending potential clients\u0091 linguistic\nsensibilities. Unedited MT is simply not good enough for \u0090outbound\u0091 work such as promotional\n\nDocument 232: receive a much higher profile than in the past. People using the crude output of MT systems will come to\nrealise the added value (i.e. higher quality) of professionally produced translations. As a result, the demand\nfor human produced translation will rise, and the translation profession will be busier than ever. Fortunately,\nprofessional translators will have the support of a wide range of computer-based translation tools, enabling\nthem to increase productivity and to improve consistency and quality. In brief, automation and MT will not be\na threat to the livelihood of the translator, but will be the source of even greater business and will be the\nmeans of achieving considerably improved working conditions.\u0091 (Hutchins, 1998).A seminal paper  on \u0090The proper\nplace of Men and Machines in\nlanguage translation\u0091 (Kay, 1980)\nargued that there were aspects of\nhigh-quality translation that called\nfor uniquely human knowledge and\nexperience. Nearly two decades","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"What is the advised use of Machine Translation (MT) for monolingual users?","answer":"Monolingual users are advised to resort to MT only for 'inbound' work \u2014 texts being translated into their own language. In this case, they can see what they are getting, warts and all, and guess at the rest without offending potential clients' linguistic sensibilities. Unedited MT is simply not good enough for 'outbound' work such as promotional materials, where input from professional human translators is essential."},{"question":"What is the impact of automation and Machine Translation (MT) on the translation profession?","answer":"Automation and MT will not be a threat to the livelihood of the translator, but will be the source of even greater business and will be the means of achieving considerably improved working conditions."}],"seed_document_id":162,"topic":"Language Technology and Machine Translation"}}
{"id":"19c68d9e-a134-40ab-aca8-033f4fa55beb","question":"Can you tell me what they are and how often they are used?","reference_answer":"There are three forms of Arabic language: Modern Standard Arabic (MSA), Classical Arabic, and the dialects. Most Arabic speakers largely speak their own dialect and are only occasional users of MSA.","reference_context":"Document 520: \u25cfthere is modern standard Arabic (MSA: the language of the press, education,and of\ufb01cialdom, throughout the Arabic world), Classical Arabic, and thedialects. Most Arabic speakers speak largely their own dialect and are onlyoccasional users of MSA. It is far from obvious what should be included in acorpus;\nFig. 11 Word sketch for Chinese (attack)\n15The resources for Chinese have since been updated, and now the leading Chinese corpus in the Sketch\nEngine is zhtenTen, from the web, and is processed by Stanford tools. The collaboration with Prof. Huangcontinues.Lexicography ASIALEX (2014) 1:7\u201336 19\n123","conversation_history":[{"role":"user","content":"I'm interested in the different forms of Arabic language and their usage frequency."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":520,"topic":"Corpus Linguistics and Lexicography"}}
{"id":"b76d8787-c02e-4252-9ecc-a172fcf4c160","question":"What is its content?","reference_answer":"The Language Machine is a survey of the current state of speech and language technology, highlighting its history and the academic disciplines contributing to its development. It also discusses practical problems and pitfalls, current and potential uses, predicted developments, and scenarios for the future.","reference_context":"Document 21: \u00a9 University of Leeds   6 of 10  language teaching, and so on. So the offices there wanted to know about computational \nlinguistics. So the British Council decided it'd be nice to have a book about this.  \nA sort of magazine, if you look at it, you find there's diagrams and even jokes in it. It explores \nsome of the technological, social, and educational implications of language machines in the years \nto come. You couldn't call it computational linguistics because that would be too complicated. So \nthey called it  the language machine. It's a survey of the current state of speech and language \ntechnology, highlighting history and academic disciplines contributing to the development of the \ntechnologies.  \nAnd also some of the practical problems and pitfalls, current and potential uses, predicted \ndevelopments, and scenarios for the future. And notice this book is about 20 years old, but\n\nDocument 70: language processing. In the most recent UK university\nResearch Assessment Exercise (RAE), the journal\nComputational Linguistics  was one of the ten journals most\ncited by computer science researchers.\nTogether, these are clear indicators of the centrality of\nthe language machine in the UK computer science\nacademic community.seeing futures\n12emerging\n.Artificial Intelligence  researcher\nMinsky has warned: \u0090Do not be\nbullied by authoritative pronounce-\nments about what machines will\nnever do. Such statements are\nbased on pride, not fact.\u0091\n(Cochrane, 1997)\nThe pursuit of the\nspeaking machine\nSee pages 10 & 11.\u0090Speech-synthesis  chips which\nturn text into speech will soon be\npossible and could, for example, be\nincorporated into fax machines to\nread messages aloud to blind and\npartially-sighted recipients.\u0091\n(Philips Vision of the Future\nonline magazine, 1997).From first imaginings \u0087\ntechnological breakthrough;\nlowering of manufacturing costs;\neasy integration into equipment;","conversation_history":[{"role":"user","content":"I'm referring to the book 'The Language Machine'."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":21,"topic":"Language Technology Research and Development"}}
{"id":"ffb2f482-42df-4223-b361-948248e5d119","question":"What is its purpose?","reference_answer":"A morphological parser is used to parse the word into its root form and affixes. For example, it can parse the word 'cats' into 'cat' and 's'. It helps in understanding the underlying meaning of the word.","reference_context":"Document 337: future. We might say cats is really cat and plural, not just s.  \nStemming is the bother of chopping off the affixes and just leaving the stems. If we want to say \nthat cat and cats are both underlyingly cat, then you just want to throw away the suh. You don't \nwant to-- don't need to know it's plural, just chop it off and forget about it.  \nHere's an example. This is not the map we found in Billy Boness his chest, blah, blah, blah. If you \nstem it, that gives us, Thi wa, not the map we found in Billi bone, because if you take in whenever \nyou come across s, chop it off and throw it away. But unfortunately that will mean this becom es thi, \nand was becomes wa.  \nSo maybe we don't want to do that. Stemming seeming simplistically, is a bit too simple. We have \na more complicated stemmer available in NLTK and in Weka, as we'll see next week, and other \nthings like that. Many other tools use this. It basically has a whole lot of rules for patterns which \nmatch.\n\nDocument 336: \u00a9 University of Leeds   13 of 14  So he is reading detective stories. You want to normalise that into, he, be, read, detective, story. \nThat's the aim.  So these individual things, or routes, or morphemes, are the bits you want to get \nout of. The stem is the core meaning- bearing unit. And you can also have affixes added onto \nthese.  \nSo stem is the root, or the main core. And the affixes are things like s or plural, that you want to \nadd on. These are both morphemes. Stems are morphemes and affixes are morphemes. So a \nmorphological parser wants to parse the word cats into cat and s. Or for Spanish amaren wants to \nmorphologically analyze that into amar, and n,  but n is the plural and the future.  \nSo it gets a bit more complicated. It's not just n But what is the underlying meaning is plural and \nfuture. We might say cats is really cat and plural, not just s.  \nStemming is the bother of chopping off the affixes and just leaving the stems. If we want to say","conversation_history":[{"role":"user","content":"Let's consider a morphological parser in the context of text analysis."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":337,"topic":"Text Normalization and Stemming"}}
{"id":"997a093b-d044-418a-b51e-5724067e23c0","question":"What is its goal?","reference_answer":"The ISLE: Interactive Spoken Language Education project is integrating speech recognition and multimedia to develop an English language learner's pronunciation tutor.","reference_context":"Document 207: Educational projects in progress\nThe following projects focus on language engineering\napplied to language education and training \u0097 and may\nindeed have longer-term educational implications.\nRECALL: Repairing Errors in Computer-Aided Language\nLearning  developed a multimedia environment for lang-\nuage learning, with graphical, written, and speech output.\nISLE: Interactive Spoken Language Education is integrating\nspeech recognition and multimedia to develop an English\nlanguage learner\u0091s pronunciation tutor. (The ISLE project is\nreferenced throughout this book: see page 62 for a review.)\nLETRAC: Language Engineering for Translator Curricula  is\ndeveloping teaching resources and components to include\nin university courses for translators.\nSELECT: Strategies for European LE-Enhanced\nCommunication Training  is building a Language Learning\nWorkbench that combines a wide range of existing\nlanguage learner\u0091s aids within a user-friendly interface.","conversation_history":[{"role":"user","content":"Let's talk about the ISLE project in the field of language education."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":207,"topic":"Language Technology Research and Development"}}
{"id":"230ab6a5-3394-4996-a16d-c8e72c365315","question":"What is one of the key problems slowing this down?","reference_answer":"One key problem is that the language machine is expensive. It has a reputation for requiring computers with powerful processors and large amounts of memory and disk storage space, in addition to in-house research and development teams who develop and install language machines and integrate them into current systems.","reference_context":"Document 129: This move, from research laboratories to everyday use, .\nleaves some academic researchers feeling redundant.\nSpeech recognition is no longer a technology research\nissue, as the theoretical problems are (supposedly) largelyThe problems\n28with machines\nIf we have the\ncommon aims and\napproaches in place,\nwhy isn\u0091t the\nlanguage machine in\ncommon use?\nWhat problems are\nslowing\ndevelopment? What\nholds it all back?SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 127: What slows development?\nThere are several problems facing the researcher \u0097 and\nindeed the potential customer \u0097 for the language machine,\nsome of which may continue to hold back the development\nof the technology well into the future. This section\nexamines seven key problems.\nProblem 1\nThe language machine is expensive\nSpeech and language technology has, in the past, had areputation for requiring computers with powerful\nprocessors and large amounts of memory and disk storage\nspace, allied to in-house research and development teams\nwho develop and install language machines and integrate\nthem into current systems.\nThis situation is now changing, thanks to rapid increases\nin computing technology. Much like advanced graphics and\nInternet access, technologies previously restricted to\nuniversity research laboratories are increasingly available\non home and office computers. \nOne concrete example of this is speech recognition\ntechnology. IBM, like many others, have used the basic","conversation_history":[{"role":"user","content":"I'm interested in the development of the language machine."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":129,"topic":"Language Machine Development"}}
{"id":"65bb2267-e73e-4877-af8f-8f6ec927cd29","question":"Can you explain why it matters?","reference_answer":"The case of words is important in text analytics because it can affect the meaning of the word. For example, 'General Motors' is the name of a company, whereas 'general motors' in lowercase could refer to any cars at all. Similarly, 'SAIL' is a piece of software, whereas 'sail' in lowercase is a different word. 'US' in uppercase is different from 'us' in lowercase. Hence, for sentiment analysis, machine translation, information extraction, and most applications of text analytics, the case is important.","reference_context":"Document 334: you want to find matches for the word regardless if it's in lowercase or uppercase. But there are \nexceptions. The case can be important.  \nGeneral Motors is the name of a company, whereas general motors in lowercase could just be any \ncars at all. Or S -A-I-L, SAIL, is a piece of software, whereas the word sail, s -a-i-l in lowercase is a \ndifferent word. So for sentiment analysis for machine translation for information extraction, for \nmost of the applications of text analytics, the case is important.  \nU-S in upper case is different from the word us, in lower case. You also have to have a dictionary \nof words, and you want to represent the words by their lemma. So for example, am, are, and is, \nyou want to convert into be,  or car, cars, car's, and cars' into car.  \nIn some languages like Spanish, it gets more complicated. Quiero, and quieres, and querer, are \nthe same. They all are different forms of want. And they can have quite a lot of different variations.","conversation_history":[{"role":"user","content":"I'm thinking about the importance of the case of words in text analytics."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":334,"topic":"Text Analysis and Tokenization"}}
{"id":"b3a1f9cb-1b70-4b69-b822-f5b6227b80f1","question":"What are these?","reference_answer":"The different levels of language processing are phonetics, lexis, syntax, semantics, pragmatics and discourse modelling.","reference_context":"Document 78: linguistics and phonetics, modern languages, operationalresearch and information systems, philosophy, psychology,and transport studies. Each contributing disciplineunderpins the language machine in different ways. Brieflyhighlighted below are the contributions of just two:linguistics and computer science ..\nLinguistics The language machine needs a theoretical\nframework within which the components of a languagemodel and their interrelation can be defined, much of whichcan be derived from the field of linguistics .. One example\nis the division of language processing into a hierarchy oflevels \u0097 phonetics, lexis, syntax, semantics, pragmatics anddiscourse modelling (see box, page 16).Computer science  As a language machine is a software\nsystem running on a computer, it can draw on many areas:* theoretical computer science provides theory on the use\nof formal simulations and mathematical models ofcomputation;\n* natural-language processing is now a specialist sub-field,\n\nDocument 80: * Artificial Intelligence also makes an important\ncontribution. A robust language machine must have alarge-scale linguistic knowledge base, knowledge oflanguage processing encoded in data, and rules formanipulating and making inferences from that data. Itmust also be able to adapt or \u0090learn\u0091, improve its ownprocessing on the basis of \u0090training\u0091 or past behaviour.Knowledge-based systems and machine learning are keyArtificial Intelligence research topics (Atwell, 1993).the language machine\n15\n.Computer science  undergraduate\ncourses often include softwareengineering, theoretical computerscience, natural language pro-cessing, and Artificial Intelligence:students now encounter languagemachines as practical problems aswell as theoretical ideas. See forexample, courses at:http:\/\/www.leeds.ac.uk\/students\/ugmodules\/comp.htm\n.Language?  Not as we expect it:\n\nDocument 75: An academic heritage\nThe history of research within various academic disciplines\ninto speech and language technology is a long one. Within\nuniversity linguistics departments, for example, compu-\ntational linguistics is a growing sub-field. Some linguists\nuse computers \u0097 in either research or teaching \u0097 as\npowerful tools for analysing or modelling aspects of\nlanguage. The grammar of English, for example, can be\nmodelled by a set of formal rules; used by a computer\nprogram to generate new sentences or parse a corpus of\ntest sentences. This application is comparable to\ngeneticists\u0091 use of computer models of gene-sequences or\ngeographers\u0091 use of computer maps and databases. \nIn a computer science department, natural language pro-\ncessing is seen \u0097 similarly to Artificial Intelligence, human-\ncomputer interaction, and multimedia \u0097 as a sub-field of\ncomputer science. Speech and language technology is a\npotentially powerful way to give us \u0090natural\u0091 communi-\n\nDocument 83: technology to a wider public, so we can expect language\nmachines to become widespread. . creating popular\n16markets\nThe contribution\nof computing\nSee page 15The language of language processing \nPhonetics : the study of speech processes, including the\nproduction, perception, and analysis of speech sounds from both\nan acoustic and a physiological point of view.\nLexis : the study of words or vocabulary items in a language,\nincluding all forms having individual meaning or grammatical\nfunction.\nSyntax : the study of the grammatical arrangement of words and\nmorphemes in the sentences of a language or of languages in\ngeneral.\nSemantics : the study of meaning in language, and the principles\nthat govern the relationship between words and sentences and\ntheir meanings.\nPragmatics : the analysis of language in practice, taking account\nof the context of language use.\nDiscourse modelling : the analysis of linguistic phenomena that","conversation_history":[{"role":"user","content":"In the field of linguistics, there are different levels of language processing."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":78,"topic":"Language Machine Technology"}}
{"id":"466f5444-7053-4f37-8350-26687f56f4b1","question":"What are some challenges associated with this?","reference_answer":"Some challenges include the inability to convert tables into English sentences straightforwardly, the need to reconsider the use of devices like keyboards and touch screens, and the need for users to learn these new interactive methods. It can also be difficult for users to dictate their inputs in a manner that is both natural and correct the first time.","reference_context":"Document 28: tables.  You can't convert a table into English sentences very straightforwardly. And we also-  the \nway that we interact with computers uses devices like keyboards and touch screens - and if we're \ngoing to start using English language instead, then we have to think about that. A touch screen \nbecomes less useful if I'm talking to a computer. Also the people, the users, need training and time \nto learn these new interactive methods. If I'm used to using a keyboard, I'm now supposed to \ndictate my essays rather than type them. It's quite difficult to say things in a way which is natural \nand correct first time. And many applications have all of these problems to them.  \nOK. The language machine also looks, in some detail, UK and European Union research initiatives \nin text analytics. This is relevant to your coursework exercise because you have to come up with a \nresearch proposal. Bear in mind that these are-  first of all these are quite large scale research","conversation_history":[{"role":"user","content":"Let's discuss the use of English language in computer interactions."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":28,"topic":"Language Machine Technology"}}
{"id":"7f066258-408b-47cd-b24d-2a913b49c683","question":"Can you tell me what their purpose is?","reference_answer":"The British Academic Spoken English (BASE) and British Academic Written English (BAWE) corpora have been created as samples of target varieties used in academic lectures, seminars and written in University-level essays, by accomplished English speakers.","reference_context":"Document 530: seminars and written in University-level essays, by accomplished English speakers.\nThe British Academic Spoken English (BASE) and British Academic WrittenEnglish (BAWE) corpora have been created as samples of these target varieties.\n22\n5.1.4 Historical\nA central topic for linguists is language development and change. Corpora looking\nback over the history of a language, and supporting this kind of research, includeLatinISE (of Latin from the third century B. C. to the twentieth century A.D.,McGillivray and Kilgarriff 2013 ), GermanC (of German from the seventeenth and\neighteenth centuries; Scheible et al. 2011 ) and English Dialogues Corpus\n(sixteenth\u2013eighteenth centuries; Culpeper and Kyto \u00a82010 ).\nFor the Arabic world and Islam, the language has a special role. It is the language","conversation_history":[{"role":"user","content":"Let's discuss the British Academic Spoken English (BASE) and British Academic Written English (BAWE) corpora."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":530,"topic":"Corpus Linguistics and Lexicography"}}
{"id":"30bced2d-c3a1-4437-86ae-174aa12877b0","question":"What does this specify?","reference_answer":"The regular expression \/[1234567890]\/ specifies any single digit.","reference_context":"Document 349: match. We\u2019ll show regular expressions delimited by slashes but note that slashes are\nnotpart of the regular expressions.\nRegular expressions come in many variants. We\u2019ll be describing extended regu-\nlar expressions ; different regular expression parsers may only recognize subsets of\nthese, or treat some expressions slightly differently. Using an online regular expres-\nsion tester is a handy way to test out your expressions and explore these variations.\n2.1.1 Basic Regular Expression Patterns\nThe simplest kind of regular expression is a sequence of simple characters. To search\nforwoodchuck , we type\/woodchuck\/ . The expression \/Buttercup\/ matches any\nstring containing the substring Buttercup ;grep with that expression would return the\nlineI\u2019m called little Buttercup . The search string can consist of a single character\n(like\/!\/) or a sequence of characters (like \/urgl\/ ).\nRegular expressions are case sensitive ; lower case \/s\/ is distinct from upper\n\nDocument 351: 2.1 \u2022 R EGULAR EXPRESSIONS 3\nRE Example Patterns Matched\n\/woodchucks\/ \u201cinteresting links to woodchucks and lemurs\u201d\n\/a\/ \u201cMary Ann stopped by Mona\u2019s\u201d\n\/!\/ \u201cYou\u2019ve left the burglar behind again! \u201d said Nori\nFigure 2.1 Some simple regex searches.\nproblem with the use of the square braces [and]. The string of characters inside the\nbraces speci\ufb01es a disjunction of characters to match. For example, Fig. 2.2 shows\nthat the pattern \/[wW]\/ matches patterns containing either worW.\nRE Match Example Patterns\n\/[wW]oodchuck\/ Woodchuck or woodchuck \u201cWoodchuck \u201d\n\/[abc]\/ \u2018a\u2019, \u2018b\u2019, or\u2018c\u2019 \u201cIn uomini, in solda ti\u201d\n\/[1234567890]\/ any digit \u201cplenty of 7 to 5\u201d\nFigure 2.2 The use of the brackets []to specify a disjunction of characters.\nThe regular expression \/[1234567890]\/ speci\ufb01es any single digit. While such\nclasses of characters as digits or letters are important building blocks in expressions,\nthey can get awkward (e.g., it\u2019s inconvenient to specify\n\/[ABCDEFGHIJKLMNOPQRSTUVWXYZ]\/","conversation_history":[{"role":"user","content":"I am trying to understand a regular expression, specifically \/[1234567890]\/."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":349,"topic":"Regular Expressions"}}
{"id":"a167349e-21da-46bd-bdcc-e2395d900dcf","question":"Could you tell me what the difference is between these two?","reference_answer":"Lemmatization is the task of determining that two words have the same root, despite their surface differences. For example, the words sang, sung, and sings are forms of the verb sing. The word sing is the common lemma of these words, and a lemmatizer maps from all of these to sing. Stemming refers to a simpler version of lemmatization in which we mainly just strip suffixes from the end of the word.","reference_context":"Document 416: 20 CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\nbe; the words dinner anddinners both have the lemma dinner . Lemmatizing each of\nthese forms to the same lemma will let us \ufb01nd all mentions of words in Russian like\nMoscow . The lemmatized form of a sentence like He is reading detective stories\nwould thus be He be read detective story .\nHow is lemmatization done? The most sophisticated methods for lemmatization\ninvolve complete morphological parsing of the word. Morphology is the study of\nthe way words are built up from smaller meaning-bearing units called morphemes . morpheme\nTwo broad classes of morphemes can be distinguished: stems \u2014the central mor- stem\npheme of the word, supplying the main meaning\u2014 and af\ufb01xes \u2014adding \u201cadditional\u201d af\ufb01x\nmeanings of various kinds. So, for example, the word foxconsists of one morpheme\n(the morpheme fox) and the word cats consists of two: the morpheme catand the\n\nDocument 346: 2CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\nSome languages, like Japanese, don\u2019t have spaces between words, so word tokeniza-\ntion becomes more dif\ufb01cult.\nAnother part of text normalization is lemmatization , the task of determining lemmatization\nthat two words have the same root, despite their surface differences. For example,\nthe words sang ,sung , and sings are forms of the verb sing. The word sing is the\ncommon lemma of these words, and a lemmatizer maps from all of these to sing.\nLemmatization is essential for processing morphologically complex languages like\nArabic. Stemming refers to a simpler version of lemmatization in which we mainly stemming\njust strip suf\ufb01xes from the end of the word. Text normalization also includes sen-\ntence segmentation : breaking up a text into individual sentences, using cues likesentence\nsegmentation\nperiods or exclamation points.\nFinally, we\u2019ll need to compare words and other strings. We\u2019ll introduce a metric","conversation_history":[{"role":"user","content":"I'm trying to understand text normalization techniques, specifically lemmatization and stemming."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":416,"topic":"Text Normalization and Tokenization"}}
{"id":"5963dd51-3420-40cd-979b-95ff2347610f","question":"What could they be?","reference_answer":"Pursuing the language machine brings benefits and opportunities to the UK at every level - from competitiveness in markets across the world and collaboration with European-based agencies and researchers, to the practical, everyday situations in the home, service industry, office, and school. Machine translation systems already help people to communicate across language barriers, not only across continents but also within multilingual countries like the UK. Speech and language technology has significant commercial potential, which is actively promoted for take-up and commercial exploitation by the UK industry.","reference_context":"Document 185: One of the key questions many will ask, is how will these\nlanguage machine projects benefit people in the UK? .the language machine\n43\nWhat are the benefits to the UK?\nPursuing the language machine brings benefits and opportunities to the UK at every level \u0097 from\ncompetitiveness in markets across the world and collaboration with European-based agencies and\nresearchers, to the practical, everyday situations in the home, service industry, office, and school. \nEUROMAP suggests several potential markets \u0097 authoring tools as part of office automation and document\nmanagement systems; speaker identification and authentication, speech recognition and synthesis\nembedded in call centres and built into the telecommunications infrastructure for voice messaging and voice\ndelivery of email; information extraction embedded in knowledge management systems; semantic analysis in\ninformation retrieval services (including Web search engines); machine translation services supporting\n\nDocument 277: Machine translation? Speech recognition?\nDo they work? 37\nUK advantage? The key-players 38\nA global interest 38What\u0091s happening in the UK? 39What do EU projects aim to do? 39\nUK-Europe overview 40UK involvement across Europe 40Case Study: Lernout and Hauspie 40\nFor translation, security, medicine \u0087 41The ten EU rules for language machinesin telematics 41\nSupply & demand: the markets 42How are people encouraged to buy? 42What are the benefits to the UK? 43\nReal-life situations 44\nIs there a typical \u0090user profile\u0091? 44Labs, factories, outdoors, offices, homes 45How are people using language machines? 45\nEmployment, society, leisure 46The art of translation. Or the translation of art? 47\nEducational resources 48Focus: language education & teaching 48Have a go? Language technology by email 48\nEducational projects in progress 49\nFuture scenarios: the impact 50\n\nDocument 94: between people may be either spoken or based on written\ntext \u0097 and language machines can have a part to play in\nboth types of interaction. \nMachine translation systems already help people to\ncommunicate across language barriers. Yet the potential for\nthis use exists not only across continents: the language\nmachine also has a role to play within multilingual\ncountries. The UK internal market is one such opportunity\nhighlighted by The Engineering and Physical Science\nResearch Council (below). \nWealth creation  Speech and language technology has\nsignificant commercial potential. In the UK, the Department\nof Trade and Industry actively promotes its take-up and\ncommercial exploitation by UK industry. . It is a view\nshared by funding bodies. The EPSRC highlights the\neconomics of multilingualism: \nSupporting the languages of [the UK\u0091s] ethnic minorities\nin this way could have rich economic rewards \u0087 Thus\nUrdu, Gujurati, Punjabi and Cantonese become\n\nDocument 184: Engineering Standards), MATE (Multi-level Annotation\nTools Engineering), ELSE (Evaluation in Language and\nSpeech Engineering) and DIET (Diagnostic and Evaluation\nTools for Natural Language Applications) are developing\nstandards and guidelines for the development and\nevaluation of language engineering resources and systems.\nPAROLE (Preparatory Action for linguistic Resources\nOrganisation for Language Engineering), EUROWORDNET\n(Building a multilingual wordnet database with semantic\nrelations between words), SIMPLE (Semantic Information\nfor Multifunctional Plurilingual Lexica) and SPEECHDAT\n(Speech Databases for Creation of Voice Driven Teles-\nervices) are gathering corpora of text, speech, and dic-\ntionaries across the range of EU languages, to be re-used in\nEuropean language engineering research and products.\nOne of the key questions many will ask, is how will these\nlanguage machine projects benefit people in the UK? .the language machine\n43\nWhat are the benefits to the UK?","conversation_history":[{"role":"user","content":"Let's consider the potential benefits of language machine projects for the UK."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":185,"topic":"Language Machine Translation"}}
{"id":"ec17e67a-d0cd-4c41-8335-1991193d52a0","question":"Could you tell me what they are?","reference_answer":"The prerequisites for a high-level resource are a tokeniser, a lemmatiser, a part-of-speech tagger, a parser or 'sketch grammar', and a collaborator who speaks the language and ideally is a computational linguist.","reference_context":"Document 515: (Jakub\u0131 \u00b4c\u02c7ek et al. 2013 ) method.\nFor a high-level resource, further prerequisites are\n\u25cfa tokeniser (for Chinese and Japanese, usually called a segmenter) to identify thewords. In simple cases this might just use spaces between words but manylanguages have clitics and similar needing language-speci\ufb01c treatment. Englishis a very simple language in this regard but even there, the hyphen and\napostrophe characters, and mixtures of letters and non-letters, present\nchallenges.\n\u25cfa lemmatiser13\n\u25cfa part-of-speech tagger\n\u25cfa parser or \u2018sketch grammar\u2019.\nWhat is also required is a collaborator. This is a person who speaks the language,\n\nDocument 516: challenges.\n\u25cfa lemmatiser13\n\u25cfa part-of-speech tagger\n\u25cfa parser or \u2018sketch grammar\u2019.\nWhat is also required is a collaborator. This is a person who speaks the language,\nand is ideally a computational linguist, and who cares about the quality of theoutput. They might care because they want to use the corpus in their own (or theirgroup\u2019s) work, or because they developed some of the tools and this is anopportunity to thoroughly test them and to show them (via data processed by them)to the world. The collaboration is crucial: without input from people who speak thelanguage, the Sketch Engine team does not know if what it has done for a language\nis good. A collaborator is needed to point out mistakes and problems, which can\nthen be addressed.\nIn the following sections we provide details about the status of Sketch Engine\nintegration of various Asian languages.\n4.1 Chinese\nThe collaboration for Chinese began with Prof Huang Chu-Ren inviting the \ufb01rst","conversation_history":[{"role":"user","content":"I am interested in understanding the prerequisites for a high-level resource according to Jakub\u0131 \u00b4c\u02c7ek et al. 2013 method."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":515,"topic":"Corpus Linguistics Software"}}
{"id":"0e59b63e-6dac-4b7e-bf86-1c479077290a","question":"What is the relevance of this in that?","reference_answer":"The relevance of text analytics in the coursework exercise is that students have to come up with a research proposal.","reference_context":"Document 29: in text analytics. This is relevant to your coursework exercise because you have to come up with a \nresearch proposal. Bear in mind that these are-  first of all these are quite large scale research \nprojects - and they're only talking about mainly the book gives some of  the titles and topics without","conversation_history":[{"role":"user","content":"Let's consider the coursework exercise and text analytics."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":29,"topic":"Others"}}
{"id":"4bb84204-4fb2-4d32-952a-a946c6809779","question":"What is its purpose?","reference_answer":"The Nuffield Languages Inquiry has been set up to estimate the UK's needs for languages in the next 20 years.","reference_context":"Document 255: Haskel, L. (1999) The Accidental Artist. Mute , 13:71-73.\nHoward, T. (1998) Breeding like robots. Personal Computer World , October\n1998, p.238.\nHunt, M. (1998) Practical Automatic Dictation Systems. ELRA Newsletter,\n3,1:4-7.\nHutchins, J. (1996) Computer-based translation systems and tools. In ELRA\nNewsletter, 1,4:6-9.\nHutchins, J. (1998) Translation Technology and the Translator. Machinereferences\n60the books\nNaturallySpeaking; ViaVoice; and\nLego are trademarks of Dragon\nSystems, IBM and Lego\nrespectively.Thanks to The Nuffield Languages\nInquiry Online for the responses\nfrom Neil Langdon Inglis, John\nThorogood and Graham Davies on\npage 37. The Nuffield Languages\nInquiry has been set up to estimate\nthe UK\u0091s needs for languages in\nthe next 20 years. For information\nabout the Inquiry, see:\nhttp:\/\/www.nuffield.orgInterest in telematics?\nFor overviews of telematics\nprogrammes see Linglink, 1997;\nEuropean Commission, 1998;\nEUROMAP , 1999. See pages 62 &","conversation_history":[{"role":"user","content":"I'm referring to The Nuffield Languages Inquiry."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":255,"topic":"Others"}}
{"id":"6523dacb-b8f9-4fa0-a67d-2f204f39450f","question":"What are these?","reference_answer":"One common core aim is to build computer models of human language and speech, such as models of grammar, vocabulary, speech production and recognition, and language learning. Computer models do not have to use graphics to visualize aspects of language: they can be conceptual as well as visual. A set of formalised grammar rules defining the phrase-structure of part of the English language constitutes a model. Such models have applications in several disciplines and research areas. Building computerised language resources is another common interest among researchers.","reference_context":"Document 54: several languages (machine translation);\n* produce a draft of our words in another language for\nsubsequent refinement (machine-assisted translation);\n* read out loud screen-based text such as email, Web\npages or word-processed documents (speech synthesis);\n* search through databases of multilingual documents\nwithout needing the ability to speak, type or read all of\nthe languages involved;\n* issue commands to \u0090intelligent devices\u0091 \u0097 such as a car\nradio or a mobile phone \u0097 using only our voices;\n* speak to a computer and get feedback on the\n\u0090correctness\u0091 of pronunciation or the appropriateness of\nlexical choices and grammar style;\n* use computers interactively in the teaching of languages.\nAt the heart of each of these lies a model of language that\nunderstands not simply the vocabulary of one or more\nlanguages, but also grammar, syntax  and semantics . \nA language machine is therefore a computer that is\ncapable, in one way or another, of extracting and acting on\n\nDocument 55: languages, but also grammar, syntax  and semantics . \nA language machine is therefore a computer that is\ncapable, in one way or another, of extracting and acting on\nthe meaning of words.describing words\n8the technology\nIs it a language\nmachine?\nTo be called a language machine,\na language model must lie at the\nheart of a computer system,\nenabling natural language to be\nunderstood and processed in an\nintelligent way. The essential\ncomponents of a language\nmachine are outlined on page 20.\nPerhaps predictably, jargon and\nacronyms litter the field, making it\ndifficult for newcomers to find\ntheir way. To help, a glossary is\nincluded on pages 58\u009759, and for\nmore information, Web and book\nreferences are given on pages\n60\u009763.Imaginative ideas\nfrom the LinglinkReport to the EU\nSee page 7SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 53: What makes a language machine?\nThe term language machine is used throughout this book,\nbut it is really an umbrella term for several developments in\ncomputer technology. Such developments will provide us\nwith opportunities to carry out familiar tasks in new ways.\nFor example, we will be able to do the following:\n* talk to machines and have them transcribe accurately\nwhat we have said (speech recognition);\n* talk to machines and have them understand the basic\ncontent of what we have said, so they can respond\nappropriately to a question about information that they\ncontain, or to which they can provide access (speech\nunderstanding);\n* use machines that translate words automatically from\none language to another (whether we input words by\nspeech, handwriting, by scanning text or using a\nkeyboard), or use machines to translate our words to\nseveral languages (machine translation);\n* produce a draft of our words in another language for\nsubsequent refinement (machine-assisted translation);\n\nDocument 90: Why create language machines?\nSpeech and language technology researchers, like\npractitioners in many scientific disciplines, can find it\ndifficult to agree on a simple, comprehensive definition of\ntheir discipline and its boundaries. It is, however, possible\nto outline some of the objectives and interests that\nlanguage machine researchers have in common:\nCreating computer models of language  One common core\naim is to build computer models of human language and\nspeech, such as models of grammar, vocabulary, speech\nproduction and recognition, and language learning.\nComputer models do not have to use graphics to \u0090visualise\u0091\naspects of language: they can be conceptual as well as\nvisual. A set of formalised grammar rules defining the\nphrase-structure of part of the English language constitutes\na \u0090model\u0091. Such models have applications in several\ndisciplines and research areas.\nBuilding computerised language resources Researchers\ngenerally make use of computerised language resources in","conversation_history":[{"role":"user","content":"I'm interested in the common objectives and interests of language machine researchers."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":54,"topic":"Artificial Intelligence in Language Learning"}}
{"id":"aec2cae2-167c-4f79-b0af-c92c962b4e80","question":"Can you tell me two ways they do this?","reference_answer":"People are using language machines in two ways: as Database interfaces, which are front-ends to computer databases that allow people to ask for information by posing questions in ordinary English, and Dialogue interfaces, which are more sophisticated front-ends, allowing people to use computing resources by means of a natural English dialogue with an apparently intelligent program.","reference_context":"Document 192: which of these \u0097 at this stage in language machine\ndevelopment \u0097 are \u0090typical\u0091 remains open for debate. \nPeace-keeping  \u0090Soldiers in Bosnia ... wear a small computer\non their chests and say to it \u0094Hands up\u0095 or \u0094Get out of the\ncar\u0095 or other things that soldiers have cause to order\nBosnian civilians to do. The computer speaks the command\nin the local language. (Soldiers can get it to speak back to\nthem in English if they want to be sure it is going to\ninterpret the correct command.) ... Dragon Systems\ndeveloped the Bosnian tool.\u0091 (Tyler, 1998) the language machine\n45\nHow are people using language machines?\nDatabase interfaces : front-ends to computer databases that allow people to ask for information by posing\nquestions in ordinary English. Dialogue interfaces : more sophisticated front-ends, allowing people to use\ncomputing resources by means of a natural English dialogue with an apparently intelligent program (a","conversation_history":[{"role":"user","content":"I am interested in the different methods people use language machines."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":192,"topic":"Language Machine Development"}}
{"id":"0e81fe6c-4179-47d6-b29a-9f1f2c9cf7b5","question":"What is its function?","reference_answer":"The 'uniq' command collapses and counts adjacent identical lines.","reference_context":"Document 393: put;sort , which sorts input lines in alphabetical order; and uniq , which collapses\nand counts adjacent identical lines.\nFor example let\u2019s begin with the \u2018complete words\u2019 of Shakespeare in one \ufb01le,\nsh.txt . We can use trto tokenize the words by changing every sequence of non-\nalphabetic characters to a newline (\u2019A-Za-z\u2019 means alphabetic, the -c option com-\nplements to non-alphabet, and the -s option squeezes all sequences into a single\ncharacter):","conversation_history":[{"role":"user","content":"I am referring to the 'uniq' command in a specific context."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":393,"topic":"Others"}}
{"id":"cdc8171f-3338-4f2b-8d65-65591c03b73b","question":"Why is this considered significant?","reference_answer":"Choosing a large corpus as your reference corpus is important because if you take a small corpus, you won't get very significant meanings statistically. This is due to the fact that there might be words which occur not very commonly at all, even in the data mining corpus, but they don't occur at all or maybe only have one occurrence in the small corpus.","reference_context":"Document 476: 2010s.  \nAnd we see that there are quite a few words like mining, funny words like doi. Well, what do these \nwords mean? Well, you have to figure it out. Disproportionality. I'm not quite sure t hese are \nparticularly data mining words. And you might want to look these up.  \nThese are probably words which occur not very commonly at all, even in the data mining corpus, \nbut they don't occur at all or maybe only one occurrence in the Brown corpus. So if  you're taking \nyour reference corpus, a small corpus, then you won't get a very good example. Statistically, not \nvery significant meanings. This is the reason for choosing a large corpus as your reference \ncorpus. But we've done this to make it work faster.  \nWhat about multi -word terms? Well, here, we're better. Data mining, data mine, adverse event, \nsafety report, text mining. So more of the multi -word terms. So typically, in a domain, in a","conversation_history":[{"role":"user","content":"We're discussing the importance of choosing a large corpus as a reference in data mining."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":476,"topic":"Corpus Linguistics Software"}}
{"id":"23051359-adfe-4397-ae98-2738ba668bb6","question":"What could be a potential concern for them?","reference_answer":"A potential concern for language teachers is whether Machine Translation (MT) could make language-learning, and hence, language teachers redundant.","reference_context":"Document 114: language professionals, such as interpreters and\ntranslators, is whether MT (and the language machine in a\nbroader sense) could make language-learning \u0097 and hence\nlanguage teachers \u0097 redundant. .\nCurrent MT systems remain imperfect, and there are still\nmany social, business and political situations in which\nbeing able to communicate directly in a shared language is\ngreatly preferable to computer-mediated communication.talk back\n24and translate\n.Thinking computers?  The annual\nLoebner Prize, evolved in part from\nTuring\u0091s ideas, offers a prize for the\n\u0090most human computer\u0091.\nContestants are currently limited to\nkeyboard input and on-screen\nreplies, but the longer-term aim of\nthe contest is to progress to\nspoken dialogue input and replies \u0097\nin effect, an English language\nconversation.\n.Redundant?  MT \u0090only works well\nwith simplified source texts, or to\nproduce a \u0094gist\u0095 version ... of\ndocuments that, for economic\nreasons, would otherwise never be\ntranslated at all. There is certainly\n\nDocument 113: language learners can clearly benefit from access to\n\u0090language-aware\u0091 functions in word processors, although\nthey do need to be aware of their possible fallibility. \nMultilinguality A machine translation (MT) system\ntranslates text from one language into another, and may\neven deal with spoken input or output. They may also\ninvolve language identification: determining which\nlanguage is being used given a printed or spoken signal.\nMost research has concentrated on English and, to a lesser\nextent, other European languages. For languages and\nlanguage-pairs that have no comprehensive machine-\ntranslation system, tools for machine-assisted translation \u0097\nsuch as bilingual dictionaries and term-banks \u0097 may be\nuseful. \nAn obvious potential concern for language teachers and\nlanguage professionals, such as interpreters and\ntranslators, is whether MT (and the language machine in a\nbroader sense) could make language-learning \u0097 and hence\nlanguage teachers \u0097 redundant. .","conversation_history":[{"role":"user","content":"Let's discuss the topic of Machine Translation (MT) and its impact on language teachers."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":114,"topic":"Artificial Intelligence in Language Learning"}}
{"id":"800fd36f-2b71-420f-ac50-61d6a979796b","question":"What is the rule concerning this?","reference_answer":"If you take n as the number of tokens and v or the vocabulary of a dictionary might extract from that as a set of types, then the size of the vocabulary is different.","reference_context":"Document 313: \u00a9 University of Leeds   7 of 14  maybe you have a dictionary of all the words and the dictionary has San Francisco dow n as one \nword.  \nHowever there are repeats of the and-- any other thing that's repeated-- and is repeated twice. \nTherefore there's not 15, but 13 is two less, because the and, and are repeated. Therefore there's \n13 types. Except you might say there's San Francisco's one word, so that makes 12 types.  \nOr well there may be other things. Maybe you might say they and there are basically the same \nword, but different grammatical -- that they and there are-- they're both the same pronoun, but \ndifferent forms. So maybe there's only 11. So it depends on how you divide up words and group \nwords together.  \nIn general, there's a sort of rule that if you take n as the number of tokens and v or the vocabulary \nof a dictionary might extract from that as a set of types, then the s ize of the vocabulary is different","conversation_history":[{"role":"user","content":"I am curious about the relationship between the number of tokens and the size of the vocabulary in a dictionary."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":313,"topic":"Text Analysis and Tokenization"}}
{"id":"bc53cbe4-e817-452a-8f64-e3ce7c859ad9","question":"What is its purpose?","reference_answer":"MIETTA is a project for Multilingual Information Extraction for Tourism and Travel Assistance.","reference_context":"Document 263: http:\/\/www.linglink.lu\/le\/projects\/select\nSPEAK (Supported Prototype Easy-Access Authoring Keys): http:\/\/www.linglink.lu\/le\/projects\/speak\nPublic Interest Projects\nAVENTINUS (Advanced Information System for Multilingual Drug Enforcement):\nhttp:\/\/www.linglink.lu\/le\/projects\/aventinus\nLINGUANET (Communicating Through the Language Barrier):\nhttp:\/\/www.linglink.lu\/le\/projects\/linguanet\nMIETTA (Multilingual Information Extraction for Tourism and Travel Assistance):\nhttp:\/\/www.linglink.lu\/le\/projects\/mietta\nSENSUS (LE for police and emergency service communications and information systems):\nhttp:\/\/www.linglink.lu\/le\/projects\/sensus\nInternational Business Support Projects\nDOCSTEP (Product DOCumentation Creation and Management using STEP):\nhttp:\/\/www.linglink.lu\/le\/projects\/docstep\nMABLE (Multilingual Authoring of Business Letters): http:\/\/www.linglink.lu\/le\/projects\/mable\nOTELO (Common Access to Translation Systems): http:\/\/www.linglink.lu\/le\/projects\/otelo\n\nDocument 262: Web information\n62cyber-sites\nEU Telematics Applications programmes\nGeneral information: http:\/\/www.echo.lu\/telematics\/\nInformation Services Projects\nEUROSEARCH (Multilingual European Federated Search Service):\nhttp:\/\/www.linglink.lu\/le\/projects\/access \nMAY (Multilingual Access to Yellow Pages): http:\/\/www.linglink.lu\/le\/projects\/may \nMULINEX (Multilingual Indexing Navigation and Editing Extensions for the World Wide Web):\nhttp:\/\/www.linglink.lu\/le\/projects\/mulinex\nEducation and Training Projects\nISLE (Interactive Spoken Language Education): http:\/\/www.linglink.lu\/le\/projects\/isle\nLETRAC (Language Engineering for Translator Curricula): http:\/\/www.linglink.lu\/le\/projects\/letrac\nRECALL (Repairing Errors in Computer-Aided Language Learning):\nhttp:\/\/www.linglink.lu\/le\/projects\/recall\nSELECT (Strategies for European LE-Enhanced Communication Training):\nhttp:\/\/www.linglink.lu\/le\/projects\/select\nSPEAK (Supported Prototype Easy-Access Authoring Keys): http:\/\/www.linglink.lu\/le\/projects\/speak\n\nDocument 266: Infrastructure and Support Projects\nDIET (Diagnostic and Evaluation Tools for Natural Language Applications):http:\/\/www.linglink.lu\/le\/projects\/dietEAGLES Expert Advisory Group on Language Engineering Standards):http:\/\/www.linglink.lu\/le\/projects\/eaglesELRA (European Language Resources Association): http:\/\/www.linglink.lu\/le\/projects\/elraELSE (Evaluation in Language and Speech Engineering): http:\/\/www.linglink.lu\/le\/projects\/else\/ELSNET (European Speech Language and Speech Network of excellence): www.elsnet.orgEUROMAP\/EUROMAP II (European Opportunity Mapping):http:\/\/www.linglink.lu\/le\/projects\/euromap\/LINGLINK (Promotion and Support for Language Engineering in Europe):http:\/\/www.linglink.lu\/le\/projects\/linglink\/MATE (Multi-Level Annotation Tools Engineering): http:\/\/www.linglink.lu\/le\/projects\/mate\/\nNews, Technology Culture\n\nDocument 265: the language machine\n63\nLanguage Resources Projects\nEUROWORDNET (Building a multilingual wordnet database with semantic relations between words): http:\/\/www.linglink.lu\/le\/projects\/eurowordnetPAROLE (Preparatory Action for linguistic Resources Organisation for Language Engineering):http:\/\/www.linglink.lu\/le\/projects\/le-paroleSIMPLE (Semantic Information for Multifunctional Plurilingual Lexica):http:\/\/www.linglink.lu\/le\/projects\/simpleSPEECHDAT (Speech Databases for Creation of Voice Driven Teleservices):http:\/\/www.linglink.lu\/le\/projects\/speechdat\nInfrastructure and Support Projects","conversation_history":[{"role":"user","content":"I am referring to the MIETTA project on the linglink.lu website."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":263,"topic":"European Language Technology Projects"}}
{"id":"c7bbe387-f82b-4148-b3a0-6fe772e77613","question":"What does this stand for and what is its purpose?","reference_answer":"CALL stands for Computer Assisted Language Learning. It refers to software that presents activities designed to help language learners. Many of the activities are based on conventional approaches, such as cloze.","reference_context":"Document 242: AI \u0097 Artificial Intelligence, first conceived by Alan Turing in 1950 as a term for\ncomputer or machine intelligence: machines that can think and learn likepeople. AI usually involves the use of knowledge bases in which largenumbers of rules are generated to govern the application\u0091s behaviour. \nalgorithm \u0097 a formula or set of ordered steps for solving a (typically\ncomplex) problem: the instructions in a computer program.\nAscii \u0097 American Standard Code for Information Interchange. Any roman\ncharacter, from A to Z, plus numbers and punctuation marks, can betranslated into Ascii code to be sent and received by computers.\nbrowser \u0097 a computer program that can read Web pages. Many browsers\nare now multifunctional and can retrieve files, send mail and readnewsgroups.\nCALL \u0097 Computer Assisted Language Learning. Software that presents\nactivities designed to help language learners. Many of the activities arebased on conventional approaches, such as cloze.","conversation_history":[{"role":"user","content":"I'm referring to the acronym 'CALL'."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":242,"topic":"Artificial Intelligence in Language Learning"}}
{"id":"be2b5f00-00c0-441a-9564-3448658db3b9","question":"When will these close down?","reference_answer":"The institution's accounts for Leeds University will close down on June 25, 2022.","reference_context":"Document 469: universities in Leeds. We want University of Leeds. That's us. OK.  \nNow I'll then log me in via my university log in. Well, I've logged in already, so we won't go there. \nYou will have to type in your username and password for Leeds University to log in.  It's just \nwarning me all accounts that my institution will close down on June 25, 2022. So the university has \na license up until June 2022, so we're OK.  \nOK, here's various stuff. Here's a dashboard. I haven't selected a corpus yet. Let's go back to \nSelect  Corpus. Well, here's some corpora that I've done before or looked at recently. And let's \ncreate a new corpus. So our new corpus -- OK, I'm going to collect a corpus in the field of, let's say, \ndata mining. Why not? And we're going to call the corpora Datam ining. Datamining.","conversation_history":[{"role":"user","content":"I'm referring to the institution's accounts for Leeds University."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":469,"topic":"Others"}}
{"id":"cee72289-56dc-4709-a729-bf9487c08fe2","question":"Do you know which one it was?","reference_answer":"Personal Computer World recommended Dragon Systems Naturally-Speaking as the best voice recognition software in October 1998.","reference_context":"Document 261: version of Dragon Naturally-\nSpeaking (Dragon 1998). \nReviews of language machines\nare also now appearing in\nmagazines beyond the PC shelf, as\nspecialist magazines recognise\nthis technology is relevant to their\nreaders: Management Services\n(May 1998) reviewed a number of\nspeech processing systems for\nmanagers (Tyler, 1998).SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 260: 61\nMagazines: the\nquickest route\nInformation on language machine\ndevelopments often appears in\npopular computing magazines.\nThe UK editions of Computer\nActive (July 1998), PC Direct (June\n1998), and Personal Computer\nWorld (October 1998) all reviewed\nPC speech recognition systems.\nComputer Active recommended\nIBM ViaVoice Gold as the best (at\nthe time). PC Direct did not\nnominate a favourite, but re-\nviewed each package in detail.\nPersonal Computer World pre-\nferred Dragon Systems Naturally-\nSpeaking, and provided a useful\nsummary of features to look for in\nvoice recognition software. \nMany magazines also include free\nCDs with sample software. The\nAugust 1998 PC Plus free CD\nincluded Globalink\u0091s English-\nSpanish Power Translator Deluxe\n(Globalink 1998); Computer Buyer\nMay 1998 free CD included a trial\nversion of Dragon Naturally-\nSpeaking (Dragon 1998). \nReviews of language machines\nare also now appearing in\nmagazines beyond the PC shelf, as\nspecialist magazines recognise","conversation_history":[{"role":"user","content":"I'm looking for the voice recognition software that was recommended by Personal Computer World in October 1998."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":261,"topic":"Language and Speech Technology"}}
{"id":"5e25238b-e1b0-4853-9e41-f40ee9da9b7a","question":"Who is the creator of this?","reference_answer":"The British scientist Charles Wheatstone created an improved model of the Kempelen machine.","reference_context":"Document 63: with basics\nSee pages 8 & 9\n1791 Kempelen\u0091s speaking machine\n1863 Bell\u0091s \u0090talking head\u0091\n1872 Edison invents electric typewriter\n1876 Bell patents telephone\n1887 Sound recording machines invented\n1939 Bell Telephones demonstrates Voder\nspeech synthesis machine\n1950 \u0090Turing test\u0091 proposed\n1970 Successful synthesis of female voice\n1976 EC begins development of Machine\nTranslation technology\n1977 Texas Instruments produce Speak &\nSpell toy with voice synthesis \n1984 Apricot computers in UK build\nspeech recognition into portable PC\n1993 Apple Newton Personal Digital\nAssistant uses handwritten input\n1994 British National Corpus compiled\n1997 Altavista\/Digital provide free web\ntranslation service\n2020 Maria Callas sings the Sex Pistols?SITE LICENCE EDITION\nCopyright, 1999 The British Council. All rights reserved.\n\nDocument 64: fraud, powered by a chess-playing dwarf.\nSome years later the British scientist Charles Wheatstone\ncreated an improved model of the Kempelen machine,\nwhich was later to capture the imagination of Alexander\nGraham Bell \u0097 the inventor of the telephone. In 1863 Bell\nproduced his own \u0090talking head\u0091. The device could articulate\nthe sound \u0090mama\u0091 sufficiently clearly to cause a neighbour\nto enquire after the baby\u0091s welfare.\nPerhaps it is unclear whether these experiments and\ndevelopments belong to the realm of science, technology,\nmusic, magic, or public entertainment (Bell\u0091s brother\nMelville once took to the Edinburgh stage with a false beard\nand foreign accent to demonstrate one machine), but all\nthese early attempts at speech synthesis arose from\nattempts to reproduce the articulatory apparatus of a\nhuman vocal tract, using bellows and resonating chambers.\nIt was not until after World War II, when the science of\nacoustic analysis was more developed, that an alternative","conversation_history":[{"role":"user","content":"I'm referring to an improved model of the Kempelen machine."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":63,"topic":"Others"}}
{"id":"528bb626-6bfe-4edd-8378-ddd1bf79f6f8","question":"Could you tell me their purpose?","reference_answer":"Parentheses have a double function in regular expressions; they are used to group terms for specifying the order in which operators should apply, and they are used to capture something in a register.","reference_context":"Document 375: we ate . Similarly, the third capture group is stored in \\3, the fourth is \\4, and so on.\nParentheses thus have a double function in regular expressions; they are used to\ngroup terms for specifying the order in which operators should apply, and they are\nused to capture something in a register. Occasionally we might want to use parenthe-\nses for grouping, but don\u2019t want to capture the resulting pattern in a register. In that\ncase we use a non-capturing group , which is speci\ufb01ed by putting the commandsnon-capturing\ngroup\n?:after the open paren, in the form (?: pattern ) .\n\/(?:some|a few) (people|cats) like some \\1\/\nwill match some cats like some cats but not some cats like some a few .\nSubstitutions and capture groups are very useful in implementing simple chat-\nbots like ELIZA (Weizenbaum, 1966). Recall that ELIZA simulates a Rogerian\npsychologist by carrying on conversations like the following:\nUser 1: Men are all alike.\nELIZA 1:IN WHAT WAY","conversation_history":[{"role":"user","content":"I'm trying to understand the use of parentheses in regular expressions."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":375,"topic":"Regular Expressions"}}
{"id":"88e66199-c4fd-4715-b22b-f251992f1568","question":"Who authored it?","reference_answer":"The book 'Computer Power and Human Reason: From Judgement to Calculation' was authored by J. Weizenbaum.","reference_context":"Document 453: Exercises 29\nWagner, R. A. and M. J. Fischer. 1974. The string-to-string\ncorrection problem. Journal of the ACM , 21:168\u2013173.\nWeizenbaum, J. 1966. ELIZA \u2013 A computer program for the\nstudy of natural language communication between man\nand machine. CACM , 9(1):36\u201345.\nWeizenbaum, J. 1976. Computer Power and Human Rea-\nson: From Judgement to Calculation . W.H. Freeman and\nCompany.\nYasseri, T., A. Kornai, and J. Kert \u00b4esz. 2012. A practical ap-\nproach to language complexity: a Wikipedia case study.\nPloS one , 7(11).","conversation_history":[{"role":"user","content":"I'm thinking about the book 'Computer Power and Human Reason: From Judgement to Calculation'."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":453,"topic":"Others"}}
{"id":"24cc8903-ae4d-4c33-a9d8-eed45bf742b9","question":"What does it stand for?","reference_answer":"Parsnips stands for Politics, Alcohol, Religion, Sex, Narcotics, Isms, Pork (as a stand-in for various foods which are taboo in various cultures).","reference_context":"Document 544: sometimes makes it past all other \ufb01lters and makes bad dictionary examples.\nSecond: parsnips. Parsnips is an acronym for the potentially offensive topics\nwhich teaching materials, which will be seen across the globe, by all communitiesand cultures, might be wise to avoid. It stands for Politics Alcohol Religion SexNarcotics Isms Pork (as a stand-in for various foods which are taboo in variouscultures). A second current challenge is to scrub the data clean of parsnips.Lexicography ASIALEX (2014) 1:7\u201336 29\n123","conversation_history":[{"role":"user","content":"In the context of potentially offensive topics to avoid in teaching materials, there's an acronym 'parsnips'."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":544,"topic":"Others"}}
{"id":"f82b0ed3-2b51-4b0d-94d9-39b5f0b12e45","question":"What are the challenges associated with this?","reference_answer":"Language machines are usually designed for an individual, a speech recogniser, for example, is limited to a single headset-microphone and using it in classroom situations is difficult beyond occasional demonstrations. Inequality of home PC access may also become a problem. Language teachers who wish to use CALL software incorporating speech recognition technology may need to rethink approaches, and decide which aspects of learning could be achieved more successfully by the individual using the technology alone, and which learning should remain within the classroom as a shared, group activity.","reference_context":"Document 131: often a luxury. Even in Western schools, where computers\nare more commonly available, speech and language\ntechnology remains difficult to use in whole classroom\nteaching. Language machines are usually designed for an\nindividual: a speech recogniser, for example, is limited to a\nsingle headset-microphone and using it in classroom\nsituations is difficult beyond occasional demonstrations.\nManufacturers of CALL software that incorporates\nspeech recognition \u0097 for example, Talk To Me (Auralog\n1996), ISLE Interactive Spoken Language Education (ISLE,\n1999) \u0097 recognise these difficulties and deliberately target\nindividual language learners with home PCs rather than\nclassroom groups. This development, alongside moves to\ngreater learner autonomy and the increase in open learning\napproaches, may in time offer new ways of constructing the\nlearning experience, while fundamentally changing the\nbalance between classroom and individual learning.\nInequality of home PC access may however become a\n\nDocument 145: professions. For example, language teachers who wish to\nuse CALL software incorporating speech recognition tech-\nnology may need to rethink approaches, and decide which\naspects of learning could be achieved more successfully by\nthe individual using the technology alone, and which\nlearning should remain within the classroom as a shared,\ngroup activity. Similarly, whole-school policies \u0097 of funding\nnew equipment, providing new learning spaces, and\nmanaging the politics of departmental resourcing \u0097 may\nneed to come under similar scrutiny if language machine\ntechnology is to be used more widely and successfuly in\neducation. \nProblem 6\nNewcomers need training and time to learn to\nuse the language machine \nOne supposed strength of the language machine is that\ncommunicating with a computer in spoken English is\n\u0090natural\u0091 and straightforward. However, current language\nmachines are far from reaching the distant goal of\nproviding a general-purpose system with linguistic\n\nDocument 223: learning \u0090taught\u0091 in a classroom environment and those\n\u0090learnt\u0091 autonomously by students equipped with their own\npersonal language machines may also prove significant to\ncurricula and educational decisions. The teaching\nprofessions need to ensure that they are in a position to\nexploit the language machine to best advantage.the language machine\n53\n.Ownership of personal\ncomputers continues to rise in the\nUK \u0097 but will access to new\ntechnology become a new form of\ndiscrimination, social stratification,\nor inequality? Questions to help\nforward the debate on the impact\nof the language machine are listed\non page 64.\nScenario 1: the must-haves \u0097 handbag, lippy, wristwatch translator\nAlready, thanks to discreet ear-pieces that allow mobile-phone users to converse on the phone hands-free \u0097often with the phone out of sight \u0097 we are becoming used to seeing solitary speaking. The future begins:","conversation_history":[{"role":"user","content":"Let's consider the use of speech and language technology in classroom teaching."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":131,"topic":"Others"}}
{"id":"949a2375-97f5-4671-90c9-ec4e38d9ddca","question":"What does it do?","reference_answer":"The -n option to sort means to sort numerically rather than alphabetically.","reference_context":"Document 395: to sort numerically rather than alphabetically, and the -roption means to sort in\nreverse order (highest-to-lowest):\ntr -sc 'A-Za-z ' '\\n'< sh.txt | tr A-Z a-z | sort | uniq -c | sort -n -r\nThe results show that the most frequent words in Shakespeare, as in any other\ncorpus, are the short function words like articles, pronouns, prepositions:\n\nDocument 394: 14 CHAPTER 2 \u2022 R EGULAR EXPRESSIONS , TEXT NORMALIZATION , EDITDISTANCE\ntr -sc 'A-Za-z ' '\\n'< sh.txt\nThe output of this command will be:\nTHE\nSONNETS\nby\nWilliam\nShakespeare\nFrom\nfairest\ncreatures\nWe\n...\nNow that there is one word per line, we can sort the lines, and pass them to uniq\n-cwhich will collapse and count them:\ntr -sc \u2019A-Za-z\u2019 \u2019\\n\u2019 < sh.txt | sort | uniq -c\nwith the following output:\n1945 A\n72 AARON\n19 ABBESS\n25 Aaron\n6 Abate\n1 Abates\n5 Abbess\n6 Abbey\n3 Abbot\n...\nAlternatively, we can collapse all the upper case to lower case:\ntr -sc 'A-Za-z ' '\\n'< sh.txt | tr A-Z a-z | sort | uniq -c\nwhose output is\n14725 a\n97 aaron\n1 abaissiez\n10 abandon\n2 abandoned\n2 abase\n1 abash\n14 abate\n3 abated\n3 abatement\n...\nNow we can sort again to \ufb01nd the frequent words. The -noption tosort means\nto sort numerically rather than alphabetically, and the -roption means to sort in\nreverse order (highest-to-lowest):\ntr -sc 'A-Za-z ' '\\n'< sh.txt | tr A-Z a-z | sort | uniq -c | sort -n -r","conversation_history":[{"role":"user","content":"I am curious about the -n option in the sort command."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":395,"topic":"Others"}}
{"id":"612d9a45-3fcd-4338-83cf-1932a0d55647","question":"What could they be?","reference_answer":"One scenario is that the language machine could lead to the large-scale abandonment of language learning. Many people learn English to communicate with native English speakers or as a lingua franca; but in the future, they might find that it is possible to communicate via machine translation devices.","reference_context":"Document 45: We can\u0091t be sure of that either. This book shows how close\nwe are to Douglas Adams\u0091 babelfish becoming reality.\nThere is no point in suggesting that diplomats will never\nnegotiate via a translation machine, or that politicians will\nnever rouse a crowd of people with translation machines\nstuck to their ears. If the technology is available, people will\nuse it.\nThe technology of the language machine may have\nbegun crudely, perhaps even comically. But if one day, I\nfind myself speaking Welsh while my wife answers in\nSlovak, who will need a world language? \nWatch this space: this is how the motor car began.\nRhodri Jones\nManager, English 2000\nThe British CouncilProgress and\nProspects\n\u0090The success of language\nengineering research and tech-\nnological development is bound to\nhave an impact on our economic\nfuture because it can be applied\nacross such a wide range of\ninformation systems and services\nwith such significant benefits.\n\u0087 The information society will\npermeate virtually every area of\n\nDocument 159: may be the case in Mexico, where the state ministry \u0097 while\nworking with the British Council to upgrade the skills of its\nteachers \u0097 is keen to introduce new technology. \nInterestingly for education, in applications such as\nmachine translation (the focus of the box opposite) and for\npeople working in other professions, . it is clear that the\nlanguage machine is making clear inroads.\nBut do inroads lead to a revolution?determination\n36to succeed\n.One scenario for the ELT\nbusiness is a radical one: what if\nthe language machine brought\nabout the large-scale abandonment\nof language learning? Many people\nlearn English so they can use it to\ncommunicate with native English\nspeakers or as a lingua franca; but\nwhat if, in the future, they find that\nit is possible to communicate via\nmachine translation devices?\nIs this scenario a realistic one?\nImplications for language\nprofessionals are explored on\npages 50\u009757.\nHal \u0097 the \ntalking computer\nmade evil\nSee page 35.Searching for Extra Terrestrials?\n\nDocument 228: difficult to believe that its overall command of English will\nmatch (let alone exceed) that of an advanced learner of\nEnglish, even in 20 years\u0091 time. Translators and teachers \u0097\ncapable of judging social language, multiple meanings,\nnuance, subtle forms, and language complexities \u0097 do not\nneed therefore to fear they will be easily replaced!\nMore probably, machine translation will be used\nalongside good teaching and translation. It is used alreadyquestioning\n54the future\nThe digital\nhelping hand\nLanguage machines can help\ndisabled people to more easily\naccess technology: the following\nindicates some present activities.\nThe Royal National Institute for\nthe Blind (www.rnib.org.uk) offers\nextensive information on speech\nsynthesis packages and suppliers.\nThe EU\u0091s ISEAUS project aims to\nuse language engineering in\nspeech education and rehabil ita-\ntion for adults with lifelong or\nacquired deafness (see page 63).\nThe funding body EPSRC actively\nencourages researchers to work","conversation_history":[{"role":"user","content":"I'm thinking about the implications of machine translation on language learning."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":45,"topic":"Others"}}
{"id":"b187c764-b399-4c82-816e-92480aecb335","question":"Could you tell me what the difference is between these two?","reference_answer":"Machine translation, often abbreviated to MT, is the process of automatically translating from one language to another by a computer. Machine aided translation, on the other hand, is the process of assisting a human in translating from one language to another using computer software tools.","reference_context":"Document 246: machine learning  \u0097 the area of AI concerned with algorithms for finding rules\nand patterns  that describe sets of data: building abstract representationsof what has been experienced.\nmachine translation  \u0097 often abbreviated to MT, the process of automatically\ntranslating from one language to another by a computer.\nMAT \u0097 machine aided translation: the process of assisting a human in\ntranslating from one language to another using computer software tools.\nmultilingual \u0097 refers either to something existing in a form that can handle\nseveral languages or to something that exists in several languages.\nnatural language  \u0097 English or any other human language when used in\ninteraction with a computer; a natural language query application, forexample, allows users to type \u0090how much is that doggie in the window\u0091rather than \u0090dog AND window AND (cost OR price)\u0091.\nnatural language learning  \u0097 machine learning applied to natural language\ncorpora to extract computable language models.\n\nDocument 113: language learners can clearly benefit from access to\n\u0090language-aware\u0091 functions in word processors, although\nthey do need to be aware of their possible fallibility. \nMultilinguality A machine translation (MT) system\ntranslates text from one language into another, and may\neven deal with spoken input or output. They may also\ninvolve language identification: determining which\nlanguage is being used given a printed or spoken signal.\nMost research has concentrated on English and, to a lesser\nextent, other European languages. For languages and\nlanguage-pairs that have no comprehensive machine-\ntranslation system, tools for machine-assisted translation \u0097\nsuch as bilingual dictionaries and term-banks \u0097 may be\nuseful. \nAn obvious potential concern for language teachers and\nlanguage professionals, such as interpreters and\ntranslators, is whether MT (and the language machine in a\nbroader sense) could make language-learning \u0097 and hence\nlanguage teachers \u0097 redundant. .","conversation_history":[{"role":"user","content":"I'm trying to understand the concepts of machine translation and machine aided translation."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":246,"topic":"Language Machine Technology"}}